{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00104a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 09:16:32.432938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095052bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('wine_reviews_with_sentiment.csv',index_col= 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf21eb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "      <td>2.240741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "      <td>3.316667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "      <td>1.375000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "      <td>1.051948e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "      <td>8.888889e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281809</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
       "      <td>Brauneberger Juffer-Sonnenuhr Spätlese</td>\n",
       "      <td>90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Mosel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>Dr. H. Thanisch (Erben Müller-Burggraef)</td>\n",
       "      <td>6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281810</th>\n",
       "      <td>US</td>\n",
       "      <td>Citation is given as much as a decade of bottl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Oregon Other</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Citation</td>\n",
       "      <td>1.387779e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281811</th>\n",
       "      <td>France</td>\n",
       "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
       "      <td>Kritt</td>\n",
       "      <td>90</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Domaine Gresser</td>\n",
       "      <td>8.750000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281812</th>\n",
       "      <td>France</td>\n",
       "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Domaine Marcel Deiss</td>\n",
       "      <td>1.208333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281813</th>\n",
       "      <td>France</td>\n",
       "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
       "      <td>Lieu-dit Harth Cuvée Caroline</td>\n",
       "      <td>90</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Domaine Schoffit</td>\n",
       "      <td>1.916667e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281814 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            country                                        description  \\\n",
       "Unnamed: 0                                                               \n",
       "0                US  This tremendous 100% varietal wine hails from ...   \n",
       "1             Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2                US  Mac Watson honors the memory of a wine once ma...   \n",
       "3                US  This spent 20 months in 30% new French oak, an...   \n",
       "4            France  This is the top wine from La Bégude, named aft...   \n",
       "...             ...                                                ...   \n",
       "281809      Germany  Notes of honeysuckle and cantaloupe sweeten th...   \n",
       "281810           US  Citation is given as much as a decade of bottl...   \n",
       "281811       France  Well-drained gravel soil gives this wine its c...   \n",
       "281812       France  A dry style of Pinot Gris, this is crisp with ...   \n",
       "281813       France  Big, rich and off-dry, this is powered by inte...   \n",
       "\n",
       "                                       designation  points  price  \\\n",
       "Unnamed: 0                                                          \n",
       "0                                Martha's Vineyard      96  235.0   \n",
       "1             Carodorum Selección Especial Reserva      96  110.0   \n",
       "2                    Special Selected Late Harvest      96   90.0   \n",
       "3                                          Reserve      96   65.0   \n",
       "4                                       La Brûlade      95   66.0   \n",
       "...                                            ...     ...    ...   \n",
       "281809      Brauneberger Juffer-Sonnenuhr Spätlese      90   28.0   \n",
       "281810                                         NaN      90   75.0   \n",
       "281811                                       Kritt      90   30.0   \n",
       "281812                                         NaN      90   32.0   \n",
       "281813               Lieu-dit Harth Cuvée Caroline      90   21.0   \n",
       "\n",
       "                  province           region_1           region_2  \\\n",
       "Unnamed: 0                                                         \n",
       "0               California        Napa Valley               Napa   \n",
       "1           Northern Spain               Toro                NaN   \n",
       "2               California     Knights Valley             Sonoma   \n",
       "3                   Oregon  Willamette Valley  Willamette Valley   \n",
       "4                 Provence             Bandol                NaN   \n",
       "...                    ...                ...                ...   \n",
       "281809               Mosel                NaN                NaN   \n",
       "281810              Oregon             Oregon       Oregon Other   \n",
       "281811              Alsace             Alsace                NaN   \n",
       "281812              Alsace             Alsace                NaN   \n",
       "281813              Alsace             Alsace                NaN   \n",
       "\n",
       "                       variety                                    winery  \\\n",
       "Unnamed: 0                                                                 \n",
       "0           Cabernet Sauvignon                                     Heitz   \n",
       "1                Tinta de Toro                   Bodega Carmen Rodríguez   \n",
       "2              Sauvignon Blanc                                  Macauley   \n",
       "3                   Pinot Noir                                     Ponzi   \n",
       "4           Provence red blend                      Domaine de la Bégude   \n",
       "...                        ...                                       ...   \n",
       "281809                Riesling  Dr. H. Thanisch (Erben Müller-Burggraef)   \n",
       "281810              Pinot Noir                                  Citation   \n",
       "281811          Gewürztraminer                           Domaine Gresser   \n",
       "281812              Pinot Gris                      Domaine Marcel Deiss   \n",
       "281813          Gewürztraminer                          Domaine Schoffit   \n",
       "\n",
       "               sentiment  \n",
       "Unnamed: 0                \n",
       "0           2.240741e-01  \n",
       "1           3.316667e-01  \n",
       "2           1.375000e-01  \n",
       "3           1.051948e-01  \n",
       "4           8.888889e-02  \n",
       "...                  ...  \n",
       "281809      6.000000e-01  \n",
       "281810      1.387779e-17  \n",
       "281811      8.750000e-02  \n",
       "281812      1.208333e-01  \n",
       "281813      1.916667e-01  \n",
       "\n",
       "[281814 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8cfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['region_2'] = wine_df['region_2'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4a2929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Napa Valley                       10726\n",
       "Columbia Valley (WA)               9118\n",
       "Russian River Valley               6679\n",
       "California                         6101\n",
       "Mendoza                            5898\n",
       "                                  ...  \n",
       "Benaco Bresciano                      1\n",
       "Paso Robles Highlands District        1\n",
       "Vin Pétillant                         1\n",
       "Vin de Pays de Côtes du Tarn          1\n",
       "Monterey County-Napa County           1\n",
       "Name: region_1, Length: 1332, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_counts = wine_df.region_1.value_counts()\n",
    "region_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0a5b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e3f272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1332.000000\n",
       "mean       176.691441\n",
       "std        637.903257\n",
       "min          1.000000\n",
       "25%          5.000000\n",
       "50%         22.000000\n",
       "75%         99.250000\n",
       "max      10726.000000\n",
       "Name: region_1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d9dc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Barbera d'Alba\",\n",
       " 'Toro',\n",
       " 'Pouilly-Fuissé',\n",
       " 'Arroyo Seco',\n",
       " 'Eola-Amity Hills',\n",
       " 'Pomerol',\n",
       " 'Côtes du Rhône',\n",
       " 'Barossa',\n",
       " 'Vino Nobile di Montepulciano',\n",
       " 'Luján de Cuyo',\n",
       " 'Saint-Estèphe',\n",
       " 'Howell Mountain',\n",
       " 'St. Helena',\n",
       " 'Etna',\n",
       " 'Tupungato',\n",
       " 'Sauternes',\n",
       " 'Umpqua Valley',\n",
       " 'Green Valley',\n",
       " 'Valpolicella Classico Superiore Ripasso',\n",
       " 'Margaret River',\n",
       " 'Blaye Côtes de Bordeaux',\n",
       " 'Saint-Julien',\n",
       " 'Meursault',\n",
       " 'Amarone della Valpolicella',\n",
       " \"Barbera d'Asti\",\n",
       " 'Soave Classico',\n",
       " \"Montepulciano d'Abruzzo\",\n",
       " 'Jumilla',\n",
       " \"Vin de Pays d'Oc\",\n",
       " 'Clare Valley',\n",
       " 'Arroyo Grande Valley',\n",
       " 'Mount Veeder',\n",
       " \"Crémant d'Alsace\",\n",
       " 'Beaune',\n",
       " 'Chianti',\n",
       " 'Salento',\n",
       " 'Shenandoah Valley (CA)',\n",
       " 'Pouilly-Fumé',\n",
       " 'Veneto',\n",
       " 'Diamond Mountain District',\n",
       " 'Valpolicella Superiore Ripasso',\n",
       " 'Bierzo',\n",
       " 'Stags Leap District',\n",
       " 'Prosecco',\n",
       " 'Cariñena',\n",
       " 'Campo de Borja',\n",
       " 'Yarra Valley',\n",
       " 'Muscadet Sèvre et Maine',\n",
       " 'Graves',\n",
       " 'Vin de France',\n",
       " 'Beaujolais-Villages',\n",
       " 'Prosecco di Valdobbiadene',\n",
       " 'Delle Venezie',\n",
       " 'Morellino di Scansano',\n",
       " 'Châteauneuf-du-Pape',\n",
       " 'Vouvray',\n",
       " 'Bordeaux Rosé',\n",
       " 'Knights Valley',\n",
       " 'Côtes de Gascogne',\n",
       " 'Terre Siciliane',\n",
       " 'Vino de la Tierra de Castilla y León',\n",
       " 'Bolgheri Superiore',\n",
       " \"Barbera d'Asti Superiore\",\n",
       " 'New York',\n",
       " 'Sonoma Mountain',\n",
       " 'Chassagne-Montrachet',\n",
       " 'Langhe',\n",
       " 'Nuits-St.-Georges',\n",
       " 'Oak Knoll District',\n",
       " 'Lugana',\n",
       " 'Jerez',\n",
       " \"Dolcetto d'Alba\",\n",
       " 'Maremma',\n",
       " \"Moscato d'Asti\",\n",
       " 'Calaveras County',\n",
       " 'Cafayate',\n",
       " 'Puglia',\n",
       " 'Umbria',\n",
       " 'Coonawarra',\n",
       " 'Puligny-Montrachet',\n",
       " 'Monticello',\n",
       " 'Happy Canyon of Santa Barbara',\n",
       " 'Penedès',\n",
       " 'Okanagan Valley',\n",
       " \"Coteaux d'Aix-en-Provence\",\n",
       " 'La Mancha',\n",
       " 'Gevrey-Chambertin',\n",
       " 'Adelaide Hills',\n",
       " 'Roero',\n",
       " 'San Luis Obispo County',\n",
       " 'Savigny-lès-Beaune',\n",
       " 'Temecula Valley',\n",
       " 'Venezia Giulia',\n",
       " 'Southern Oregon',\n",
       " 'Calistoga',\n",
       " 'Morgon',\n",
       " 'Applegate Valley',\n",
       " 'San Juan',\n",
       " 'Isola dei Nuraghi',\n",
       " 'Soave',\n",
       " 'Vernaccia di San Gimignano',\n",
       " 'Mercurey',\n",
       " 'Napa',\n",
       " 'Mâcon-Villages',\n",
       " 'Madiran',\n",
       " 'Fiano di Avellino',\n",
       " 'Beaujolais',\n",
       " 'Montsant',\n",
       " 'McMinnville',\n",
       " 'Castillon Côtes de Bordeaux',\n",
       " 'Walla Walla Valley (OR)',\n",
       " 'Saint-Véran',\n",
       " 'Gaillac',\n",
       " 'Seneca Lake',\n",
       " 'Clarksburg',\n",
       " 'Pommard',\n",
       " 'Ribbon Ridge',\n",
       " \"Pays d'Oc\",\n",
       " 'Victoria',\n",
       " 'Trentino',\n",
       " 'Western Australia',\n",
       " 'Prosecco di Conegliano e Valdobbiadene',\n",
       " 'Rattlesnake Hills',\n",
       " 'Chalk Hill',\n",
       " 'Taurasi',\n",
       " 'Red Hills Lake County',\n",
       " 'Yountville',\n",
       " 'Calatayud',\n",
       " 'Hermitage',\n",
       " 'Carmel Valley',\n",
       " 'Hunter Valley',\n",
       " 'Valdobbiadene Prosecco Superiore',\n",
       " 'Los Carneros',\n",
       " 'Columbia Valley (OR)',\n",
       " 'Maremma Toscana',\n",
       " 'Campania',\n",
       " 'Côtes de Bourg',\n",
       " 'Greco di Tufo',\n",
       " 'Aglianico del Vulture',\n",
       " 'Mendocino Ridge',\n",
       " 'Costières de Nîmes',\n",
       " 'Trento',\n",
       " 'Rosso di Montepulciano',\n",
       " 'Crémant de Bourgogne',\n",
       " 'Santa Clara Valley',\n",
       " 'Bandol',\n",
       " 'Neuquén',\n",
       " 'Volnay',\n",
       " 'Irpinia',\n",
       " 'Valpolicella Classico Superiore',\n",
       " 'Mt. Harlan',\n",
       " 'Contra Costa County',\n",
       " 'Chianti Rufina',\n",
       " 'Salta',\n",
       " 'Barsac',\n",
       " 'Valencia',\n",
       " 'Vin Mousseux',\n",
       " 'Napa County',\n",
       " 'Chambolle-Musigny',\n",
       " 'Chalone',\n",
       " 'Chinon',\n",
       " 'Long Island',\n",
       " 'Côtes du Rhône Villages',\n",
       " 'Eden Valley',\n",
       " 'Friuli Grave',\n",
       " 'Yorkville Highlands',\n",
       " 'Bennett Valley',\n",
       " 'Moulin-à-Vent',\n",
       " 'Cadillac Côtes de Bordeaux',\n",
       " 'Atlas Peak',\n",
       " 'Fleurie',\n",
       " 'Coteaux du Languedoc',\n",
       " 'Spring Mountain District',\n",
       " 'Vigneti delle Dolomiti',\n",
       " 'Minervois',\n",
       " 'Listrac-Médoc',\n",
       " 'Rockpile',\n",
       " 'Alicante',\n",
       " 'Crozes-Hermitage',\n",
       " 'Somontano',\n",
       " 'New Mexico',\n",
       " 'Vosne-Romanée',\n",
       " 'Colli della Toscana Centrale',\n",
       " 'Bergerac',\n",
       " 'Cornas',\n",
       " 'Cayuga Lake',\n",
       " 'Moulis-en-Médoc',\n",
       " 'Adelaida District',\n",
       " 'Santenay',\n",
       " 'Corbières',\n",
       " 'Utiel-Requena',\n",
       " 'Redwood Valley',\n",
       " 'Piedmont',\n",
       " 'Vin de Pays des Côtes de Gascogne',\n",
       " 'Touraine',\n",
       " 'Bergerac Sec',\n",
       " \"Barbera d'Alba Superiore\",\n",
       " 'Côtes de Provence Sainte-Victoire',\n",
       " 'Prosecco del Veneto',\n",
       " 'Brouilly',\n",
       " 'Columbia Gorge (OR)',\n",
       " 'Marche',\n",
       " 'Lalande de Pomerol',\n",
       " 'Valdepeñas',\n",
       " 'Langhorne Creek',\n",
       " 'Anjou',\n",
       " 'Menetou-Salon',\n",
       " 'Columbia Gorge (WA)',\n",
       " 'Snipes Mountain',\n",
       " \"Sant'Antimo\",\n",
       " 'Sagrantino di Montefalco',\n",
       " 'Niagara Peninsula',\n",
       " 'Vermentino di Sardegna',\n",
       " 'Valpolicella Classico',\n",
       " 'Gavi',\n",
       " 'Patagonia',\n",
       " 'Terra Alta',\n",
       " 'Montefalco Rosso',\n",
       " 'Saint-Joseph',\n",
       " 'Chianti Colli Senesi',\n",
       " 'Valpolicella Superiore',\n",
       " 'Fronton',\n",
       " 'Texas',\n",
       " 'Marin County',\n",
       " 'Saint-Aubin',\n",
       " 'Calchaquí Valley',\n",
       " 'Valle de Uco',\n",
       " 'Valdeorras',\n",
       " \"Barbera d'Asti Superiore Nizza\",\n",
       " 'Montecucco',\n",
       " 'Lazio',\n",
       " 'Crémant de Loire',\n",
       " 'Vino Spumante',\n",
       " 'Saumur',\n",
       " 'High Valley',\n",
       " 'Friuli Isonzo',\n",
       " 'San Rafael',\n",
       " 'Fiddletown',\n",
       " 'Spain',\n",
       " 'Marsannay',\n",
       " 'Corton-Charlemagne',\n",
       " 'Verdicchio dei Castelli di Jesi Classico Superiore',\n",
       " 'Salice Salentino',\n",
       " 'Catalunya',\n",
       " 'Rully',\n",
       " 'Yamhill-Carlton District',\n",
       " 'Agrelo',\n",
       " 'Prosecco Superiore di Cartizze',\n",
       " 'Clos de Vougeot',\n",
       " 'Gigondas',\n",
       " 'Ballard Canyon',\n",
       " 'San Benito County',\n",
       " 'Côte Rôtie',\n",
       " 'Juliénas',\n",
       " 'Potter Valley',\n",
       " 'Fort Ross-Seaview',\n",
       " 'Hudson River Region',\n",
       " 'Lake Chelan',\n",
       " 'Rutherglen',\n",
       " 'Recioto della Valpolicella Classico',\n",
       " 'Tasmania',\n",
       " 'Piave',\n",
       " 'Argentina',\n",
       " 'Primitivo di Manduria',\n",
       " 'Montefalco Sagrantino',\n",
       " 'Cortona',\n",
       " 'Temecula',\n",
       " 'Fronsac',\n",
       " 'Valdobbiadene Superiore di Cartizze',\n",
       " 'La Consulta',\n",
       " 'Jurançon',\n",
       " 'Condrieu',\n",
       " 'Dunnigan Hills',\n",
       " 'South Coast',\n",
       " 'Pernand-Vergelesses',\n",
       " 'Castel del Monte',\n",
       " 'Clarendon',\n",
       " 'Maipú',\n",
       " 'Montagny',\n",
       " \"Nebbiolo d'Alba\",\n",
       " 'Côtes de Bordeaux',\n",
       " 'Coteaux Varois en Provence',\n",
       " 'Australia',\n",
       " 'Veronese',\n",
       " 'Padthaway',\n",
       " 'Yolo County',\n",
       " 'Premieres Côtes de Bordeaux',\n",
       " 'Tavel',\n",
       " 'Clear Lake',\n",
       " 'Romagna',\n",
       " 'Ancient Lakes',\n",
       " 'Heathcote',\n",
       " 'Cannonau di Sardegna',\n",
       " 'Ribeiro',\n",
       " 'Verdicchio dei Castelli di Jesi Classico',\n",
       " 'Cienega Valley',\n",
       " 'Valpolicella',\n",
       " 'Savennières',\n",
       " 'Corton',\n",
       " 'Terre di Chieti',\n",
       " 'Sonoma-Napa',\n",
       " 'Jurançon Sec',\n",
       " 'Entre-Deux-Mers',\n",
       " 'Paso Robles Willow Creek District',\n",
       " 'Río Negro Valley',\n",
       " 'Montagne-Saint-Émilion',\n",
       " 'Adelaide',\n",
       " 'Perdriel',\n",
       " 'Coombsville',\n",
       " 'Chiroubles',\n",
       " 'Fair Play',\n",
       " 'Viré-Clessé',\n",
       " 'Pennsylvania',\n",
       " 'Aloxe-Corton',\n",
       " 'Missouri',\n",
       " 'Famatina Valley',\n",
       " 'Côtes de Bergerac',\n",
       " 'Yecla',\n",
       " 'Terre del Volturno',\n",
       " 'Sangiovese di Romagna Superiore',\n",
       " 'Tierra de Castilla',\n",
       " 'Dolcetto di Dogliani',\n",
       " 'Napa-Sonoma',\n",
       " 'Grand Valley',\n",
       " 'Languedoc',\n",
       " 'Echézeaux',\n",
       " 'Chianti Superiore',\n",
       " 'Barbera del Monferrato',\n",
       " 'Suisun Valley',\n",
       " 'Prosecco di Conegliano',\n",
       " 'Val de Loire',\n",
       " 'Monferrato',\n",
       " 'Alto Adige Valle Isarco',\n",
       " 'Côtes du Tarn',\n",
       " 'Paicines',\n",
       " \"Trebbiano d'Abruzzo\",\n",
       " 'Valpolicella Ripasso',\n",
       " 'Dominio de Valdepusa',\n",
       " 'Bourgogne Hautes Côtes de Nuits',\n",
       " 'The Hamptons, Long Island',\n",
       " 'Ribeira Sacra',\n",
       " 'Sannio',\n",
       " 'Idaho',\n",
       " 'Faugères',\n",
       " 'Sangiovese di Romagna',\n",
       " 'Corse',\n",
       " 'Italy',\n",
       " 'El Dorado County',\n",
       " 'Valtellina Superiore',\n",
       " 'Saint-Amour',\n",
       " 'Rosso del Veronese',\n",
       " 'Lacryma Christi del Vesuvio',\n",
       " 'Chianti Colli Fiorentini',\n",
       " 'Isonzo del Friuli',\n",
       " 'Cigales',\n",
       " 'Old Mission Peninsula',\n",
       " 'Getariako Txakolina',\n",
       " 'Vin Santo del Chianti Classico',\n",
       " 'Petit Chablis',\n",
       " 'Premieres Côtes de Blaye',\n",
       " 'Tulum Valley',\n",
       " 'Côtes du Lot',\n",
       " 'Carmignano',\n",
       " 'Barbera del Monferrato Superiore',\n",
       " 'Mornington Peninsula',\n",
       " 'Saint-Chinian',\n",
       " 'Cochise County',\n",
       " 'Frankland River',\n",
       " 'Carignano del Sulcis',\n",
       " 'Coteaux Varois',\n",
       " 'Lambrusco Grasparossa di Castelvetro',\n",
       " 'Almansa',\n",
       " 'Shenandoah Valley',\n",
       " 'Gattinara',\n",
       " 'Cerasuolo di Vittoria',\n",
       " 'Coteaux du Giennois',\n",
       " 'Pemberton',\n",
       " 'Côte de Brouilly',\n",
       " 'Limestone Coast',\n",
       " 'Colline Pescaresi',\n",
       " 'Chorey-lès-Beaune',\n",
       " 'La Rioja',\n",
       " 'Napa County-Sonoma County',\n",
       " 'Lirac',\n",
       " 'Orange',\n",
       " 'Great Southern',\n",
       " 'Limoux',\n",
       " 'Prosecco Treviso',\n",
       " 'Quincy',\n",
       " \"Rosé d'Anjou\",\n",
       " 'Basilicata',\n",
       " 'Buzet',\n",
       " 'Côtes du Roussillon Villages',\n",
       " 'Torgiano',\n",
       " 'Vacqueyras',\n",
       " 'Costers del Segre',\n",
       " 'Northern Sonoma',\n",
       " 'Málaga',\n",
       " 'Templeton Gap District',\n",
       " 'Bourgueil',\n",
       " 'Bendigo',\n",
       " 'Reuilly',\n",
       " 'Friuli Colli Orientali',\n",
       " 'Orvieto Classico Superiore',\n",
       " 'Monbazillac',\n",
       " 'Lussac Saint-Émilion',\n",
       " 'Mediterranée',\n",
       " 'Côtes du Marmandais',\n",
       " 'Rosso Piceno',\n",
       " 'Vista Flores',\n",
       " 'Coteaux Bourguignons',\n",
       " 'York Mountain',\n",
       " 'Clements Hills',\n",
       " 'Les Baux de Provence',\n",
       " 'Vittoria',\n",
       " 'Francs Côtes de Bordeaux',\n",
       " 'Forlì',\n",
       " 'Côte de Nuits-Villages',\n",
       " 'Asti',\n",
       " 'Solano County',\n",
       " 'Falerno del Massico',\n",
       " 'Beaujolais Blanc',\n",
       " 'Arbois',\n",
       " 'Givry',\n",
       " 'Passito di Pantelleria',\n",
       " 'Pla de Bages',\n",
       " 'Val di Cornia Suvereto',\n",
       " 'Nagambie Lakes',\n",
       " 'Morey-Saint-Denis',\n",
       " 'Santa Barbara',\n",
       " 'Ben Lomond Mountain',\n",
       " 'Soave Classico Superiore',\n",
       " 'Ventoux',\n",
       " 'Saint-Mont',\n",
       " 'Leelanau Peninsula',\n",
       " 'San Francisco Bay',\n",
       " 'Pacherenc du Vic Bilh',\n",
       " 'Côtes du Roussillon',\n",
       " 'Guenoc Valley',\n",
       " 'Lambrusco di Sorbara',\n",
       " 'Saumur-Champigny',\n",
       " 'Ile de Beauté',\n",
       " 'Rosso Conero',\n",
       " 'Charmes-Chambertin',\n",
       " 'Empordà',\n",
       " 'Bourgogne Hautes Côtes de Beaune',\n",
       " 'Bardolino',\n",
       " 'Vin de Pays Var',\n",
       " 'Coteaux du Layon',\n",
       " 'Bardolino Chiaretto',\n",
       " 'Calabria',\n",
       " 'Tuscany',\n",
       " 'Minervois La Liviniere',\n",
       " 'Roero Arneis',\n",
       " 'Taburno',\n",
       " 'Montilla-Moriles',\n",
       " 'Colorado',\n",
       " \"Montepulciano d'Abruzzo Colline Teramane\",\n",
       " 'Elkton Oregon',\n",
       " 'Molise',\n",
       " 'Friuli',\n",
       " 'Lake Michigan Shore',\n",
       " 'Alella',\n",
       " 'Sonoma County-Napa County',\n",
       " 'Bâtard-Montrachet',\n",
       " 'Chevalier-Montrachet',\n",
       " 'Vin de Savoie',\n",
       " 'Orcia',\n",
       " 'Mâcon-Lugny',\n",
       " 'Muscat de Beaumes de Venise',\n",
       " 'Saint-Nicolas-de-Bourgueil',\n",
       " 'Cerasuolo di Vittoria Classico',\n",
       " 'Middleburg',\n",
       " 'Bordeaux Clairet',\n",
       " 'Vermentino di Gallura',\n",
       " 'Patrimonio',\n",
       " 'Emilia-Romagna',\n",
       " 'Puisseguin Saint-Émilion',\n",
       " 'Régnié',\n",
       " 'Alta Langa',\n",
       " 'Conero',\n",
       " 'Alto Valle del Río Negro',\n",
       " 'Offida Pecorino',\n",
       " 'Oltrepò Pavese',\n",
       " 'Friuli Aquileia',\n",
       " 'Rosso Piceno Superiore',\n",
       " 'Pyrenees',\n",
       " 'Carneros-Napa Valley',\n",
       " 'Vi de la Terra Illes Balears',\n",
       " 'Verdicchio dei Castelli di Jesi',\n",
       " 'Orvieto Classico',\n",
       " 'Beneventano',\n",
       " 'Chiles Valley',\n",
       " 'Bourgogne Aligoté',\n",
       " 'Terra degli Osci',\n",
       " 'Fixin',\n",
       " 'Central Ranges',\n",
       " 'New Jersey',\n",
       " 'Mokelumne River',\n",
       " 'Vin de Pays du Comté Tolosan',\n",
       " 'Muscadet Côtes de Grandlieu',\n",
       " 'Vin de Table Francais',\n",
       " 'Côtes de Castillon',\n",
       " 'Mâcon-Chardonnay',\n",
       " 'Chambertin Clos de Bèze',\n",
       " 'Beaujolais Rosé',\n",
       " 'Venezie',\n",
       " 'Côtes du Jura',\n",
       " 'Marsala',\n",
       " 'Auxey-Duresses',\n",
       " 'Contessa Entellina',\n",
       " 'Chambertin',\n",
       " 'Campi Flegrei',\n",
       " 'Côte Chalonnaise',\n",
       " 'Pouilly-Vinzelles',\n",
       " 'Vino da Tavola',\n",
       " \"Montepulciano d'Abruzzo Cerasuolo\",\n",
       " 'Montescudaio',\n",
       " 'Augusta',\n",
       " 'Frascati Superiore',\n",
       " 'Vin de Pays du Val de Loire',\n",
       " 'Chénas',\n",
       " 'Saint-Bris',\n",
       " 'Grand River Valley',\n",
       " 'Côtes de Provence La Londe',\n",
       " 'Vinos de Madrid',\n",
       " 'Arizona',\n",
       " 'Savoie',\n",
       " 'Valpolicella Ripasso Classico',\n",
       " 'Montravel',\n",
       " \"Brachetto d'Acqui\",\n",
       " 'Valli di Porto Pino',\n",
       " 'Aglianico del Taburno',\n",
       " 'Wrattonbully',\n",
       " 'Pine Mountain-Cloverdale Peak',\n",
       " 'Moon Mountain District Sonoma County',\n",
       " 'Ribera del Guadiana',\n",
       " 'Conca de Barberà',\n",
       " 'Rubicone',\n",
       " 'Bardolino Classico',\n",
       " 'Val di Neto',\n",
       " 'Hautes Côtes de Nuits',\n",
       " 'Cirò',\n",
       " 'Riverina',\n",
       " 'Naches Heights',\n",
       " 'Uclés',\n",
       " 'New South Wales',\n",
       " 'Soave Superiore',\n",
       " 'Corbières-Boutenac',\n",
       " 'Cucamonga Valley',\n",
       " 'Monterrei',\n",
       " 'Rosso di Toscana',\n",
       " 'Luberon',\n",
       " 'Vin de Pays des Côtes Catalanes',\n",
       " 'King Valley',\n",
       " 'Pomino',\n",
       " 'Marca Trevigiana',\n",
       " 'Veneto Orientale',\n",
       " 'Vin de Liqueur',\n",
       " 'Madera',\n",
       " 'Colline Novaresi',\n",
       " 'Humboldt County',\n",
       " 'Quarts de Chaume',\n",
       " 'Recioto di Soave',\n",
       " 'Moscadello di Montalcino',\n",
       " 'Marcillac',\n",
       " 'Ruché di Castagnole Monferrato',\n",
       " 'Valdadige',\n",
       " 'Coteaux du Languedoc Pic Saint Loup',\n",
       " 'Saint-Péray',\n",
       " 'Pécharmant',\n",
       " 'Beamsville Bench',\n",
       " 'Savennières-Roche-Aux-Moines',\n",
       " 'San Luis Obispo',\n",
       " 'Ghemme',\n",
       " 'Monthélie',\n",
       " 'Pouilly-Loché',\n",
       " 'Albana di Romagna',\n",
       " 'Vin de Pays Vignobles de France',\n",
       " 'Sardinia',\n",
       " 'Mount Harlan',\n",
       " 'Alcamo',\n",
       " 'Swan Creek',\n",
       " 'Chelan County',\n",
       " 'Recioto della Valpolicella',\n",
       " 'Emilia',\n",
       " 'Texas High Plains',\n",
       " 'Amarone della Valpolicella Valpantena',\n",
       " 'Vi de la Terra Mallorca',\n",
       " 'Montrachet',\n",
       " 'Niagara-On-The-Lake',\n",
       " 'Coste della Sesia',\n",
       " 'Cole Ranch',\n",
       " 'Abruzzo',\n",
       " 'Alta Mesa',\n",
       " 'Vougeot',\n",
       " 'Cheverny',\n",
       " 'San Carlos',\n",
       " 'Vin de Pays de la Méditerranée',\n",
       " 'Colline Teatine',\n",
       " 'Extremadura',\n",
       " 'Crémant de Jura',\n",
       " 'Primitivo del Salento',\n",
       " 'Montlouis-sur-Loire',\n",
       " 'Colli Piacentini',\n",
       " 'Côte de Beaune',\n",
       " 'Falanghina del Sannio',\n",
       " 'Manchuela',\n",
       " 'Banyuls',\n",
       " 'France',\n",
       " 'San Francisco Bay-Livermore Valley',\n",
       " 'Napa-Mendocino-Sonoma-Marin',\n",
       " 'Tierra de León',\n",
       " 'Côte de Beaune-Villages',\n",
       " 'Grands-Echezeaux',\n",
       " 'Orvieto',\n",
       " 'Bolgheri Sassicaia',\n",
       " 'Rivesaltes',\n",
       " 'Vin de Pays du Jardin de la France',\n",
       " 'Contea di Sclafani',\n",
       " 'Sonoma County-Monterey County-Santa Barbara County',\n",
       " 'Colli Aprutini',\n",
       " 'Côtes du Luberon',\n",
       " 'Lago di Corbara',\n",
       " 'Alghero',\n",
       " 'Ladoix',\n",
       " 'Vin Santo di Montepulciano',\n",
       " 'Friuli Venezia Giulia',\n",
       " 'Puget Sound',\n",
       " 'Mudgee',\n",
       " 'Cesanese del Piglio',\n",
       " 'Canon-Fronsac',\n",
       " 'Monica di Sardegna',\n",
       " 'Erice',\n",
       " 'Mazis-Chambertin',\n",
       " 'Lot',\n",
       " 'Tierra del Viños de Zamora',\n",
       " 'Mâcon La Roche Vineuse',\n",
       " 'Mâcon-Fuissé',\n",
       " 'Côtes de Duras',\n",
       " 'Cabardes',\n",
       " 'Malibu-Newton Canyon',\n",
       " 'Vin de Pays du Lot',\n",
       " 'Chapelle-Chambertin',\n",
       " 'Corton Vergennes',\n",
       " 'Clos de la Roche',\n",
       " 'Saint-Romain',\n",
       " \"Cerasuolo d'Abruzzo\",\n",
       " 'Pompeiano',\n",
       " 'Asolo Prosecco Superiore',\n",
       " 'Sforzato di Valtellina',\n",
       " 'Verdicchio di Matelica',\n",
       " 'Teroldego Rotaliano',\n",
       " 'Vin Santo del Chianti Rufina',\n",
       " 'Gavi di Gavi',\n",
       " 'Piccadilly Valley',\n",
       " 'Côtes-du-Ventoux',\n",
       " 'Lake Erie North Shore',\n",
       " 'Ohio',\n",
       " 'Faro',\n",
       " 'Touraine Mesland',\n",
       " 'Recioto di Soave Classico',\n",
       " 'Fitou',\n",
       " 'Dogliani Superiore',\n",
       " 'McLaren Vale-Adelaide Hills',\n",
       " 'Vin Santo del Chianti',\n",
       " 'Michigan',\n",
       " 'Southeastern New England',\n",
       " 'Salina',\n",
       " 'Lambrusco Reggiano',\n",
       " 'Custoza',\n",
       " 'Murgia',\n",
       " 'Lison-Pramaggiore',\n",
       " 'Côtes Catalanes',\n",
       " 'Napa-Mendocino-Sonoma',\n",
       " \"Costa d'Amalfi\",\n",
       " 'Valpolicella Ripasso Valpantena Superiore',\n",
       " 'Alto Adige Terlano',\n",
       " 'Bonnes-Mares',\n",
       " 'San Pasqual',\n",
       " \"Dolcetto di Diano d'Alba\",\n",
       " 'Anjou Villages',\n",
       " 'Dogliani',\n",
       " 'Colli Trevigiani',\n",
       " 'Noto',\n",
       " 'Fleurieu Peninsula',\n",
       " 'Mâcon-Milly Lamartine',\n",
       " 'Soave Colli Scaligeri',\n",
       " \"Cabernet d'Anjou\",\n",
       " 'Var',\n",
       " 'Central Victoria',\n",
       " 'Sable de Camargue',\n",
       " \"Dolcetto d'Asti\",\n",
       " 'Vin de Pays du Gard',\n",
       " 'Placer County',\n",
       " 'Lambrusco di Modena',\n",
       " 'Trinity County',\n",
       " 'Nuragus di Cagliari',\n",
       " 'Cadillac',\n",
       " 'Bergerac Rosé',\n",
       " 'Monteregio di Massa Marittima',\n",
       " 'Bizkaiko Txakolina',\n",
       " 'River Junction',\n",
       " 'Coteaux du Vendômois',\n",
       " 'Vin de Pays de Vaucluse',\n",
       " 'San Antonio Valley',\n",
       " 'Lenswood',\n",
       " 'Catalonia',\n",
       " 'Vino de la Tierra Contraviesa Alpujarra',\n",
       " 'Bienvenues Bâtard-Montrachet',\n",
       " 'Madrid',\n",
       " 'North Carolina',\n",
       " 'Châteaumeillant',\n",
       " 'Moscato di Noto',\n",
       " 'Monterey-Santa Barbara',\n",
       " 'Pavia',\n",
       " 'Mâcon',\n",
       " 'Vino de la Tierra del Bajo Aragón',\n",
       " 'Crémant de Limoux',\n",
       " 'La Clape',\n",
       " 'San Bernabe',\n",
       " 'Colli Bolognesi',\n",
       " 'Colli di Conegliano',\n",
       " 'Lake County-Mendocino County',\n",
       " 'Santa Margarita Ranch',\n",
       " 'San Lucas',\n",
       " 'Muscadet',\n",
       " 'Mâcon-Cruzille',\n",
       " 'Clos Saint-Denis',\n",
       " 'Roccamonfina',\n",
       " 'Tarragona',\n",
       " 'Nevada County',\n",
       " 'Controguerra',\n",
       " 'Bramaterra',\n",
       " 'Romangia',\n",
       " 'Mount Barker',\n",
       " 'Coteaux du Layon Saint Aubin',\n",
       " 'Venezia',\n",
       " 'Southern Flinders Ranges',\n",
       " 'Rosé de Loire',\n",
       " 'Côtes de Nuits Villages',\n",
       " 'San Gimignano',\n",
       " 'Vittoria Frappato',\n",
       " 'Garda',\n",
       " 'Gers',\n",
       " 'Vino de la Tierra de Cádiz',\n",
       " 'Sainte-Foy Bordeaux',\n",
       " 'St.-Romain',\n",
       " 'Gioia del Colle',\n",
       " 'Muscat de Rivesaltes',\n",
       " 'Mâcon-Verze',\n",
       " 'Dolcetto di Monferrato',\n",
       " 'Ribera del Queiles',\n",
       " 'Bonnezeaux',\n",
       " 'Mendocino-Lake',\n",
       " 'Collines Rhôdaniennes',\n",
       " 'Crémant de Bordeaux',\n",
       " 'Vino de la Tierra de Castelló',\n",
       " 'Yadkin Valley',\n",
       " 'Saddle Rock-Malibu',\n",
       " 'Vin de Pays Cité de Carcassonne',\n",
       " \"Vin de Pays de L'Herault\",\n",
       " 'Picpoul de Pinet',\n",
       " 'Tarantino',\n",
       " 'Mentrida',\n",
       " 'Lessona',\n",
       " 'Valpolicella Ripasso Valpantena',\n",
       " 'Hilltops',\n",
       " 'Kangaroo Island',\n",
       " 'Malvasia delle Lipari',\n",
       " 'Manzanilla-Sanlúcar de Barrameda',\n",
       " 'Garda Classico',\n",
       " \"Sant' Agata dei Goti\",\n",
       " 'Chianti Montalbano',\n",
       " 'Chianti Colli Aretini',\n",
       " 'Western Plains',\n",
       " 'Curtefranca',\n",
       " 'Conero Riserva',\n",
       " 'Maranges',\n",
       " \"Vin de Pays de L'Aude\",\n",
       " 'Eloro',\n",
       " 'Zonda Valley',\n",
       " 'Prosecco di Valdobbiadene Superiore',\n",
       " 'Sonoma-Napa-Mendocino',\n",
       " 'Vin de Pays des Collines Rhodaniennes',\n",
       " 'Anjou Villages Brissac',\n",
       " 'Corse Porto Vecchio',\n",
       " 'Vino Tierra de León',\n",
       " 'Latricières-Chambertin',\n",
       " 'Menfi',\n",
       " 'Falerio dei Colli Ascolani',\n",
       " 'Vin de Pays des Cévennes',\n",
       " 'Columbia Valley-Walla Walla Valley',\n",
       " 'Colli di Faenza',\n",
       " 'Colli Tortonesi',\n",
       " 'Offida Passerina',\n",
       " 'Falanghina del Beneventano',\n",
       " 'Mâcon-Vinzelles',\n",
       " \"Lambrusco dell'Emilia\",\n",
       " 'El Pomar District',\n",
       " 'Mâcon-Azé',\n",
       " 'Custoza Superiore',\n",
       " 'Vin Santo di Carmignano',\n",
       " 'Piemonte',\n",
       " 'Colli Perugini',\n",
       " 'Iowa',\n",
       " 'Castilla La Mancha',\n",
       " 'Mâcon-Loché',\n",
       " 'Lake Erie',\n",
       " 'Adelaide Plains',\n",
       " 'Blanquette de Limoux',\n",
       " 'Santa Cruz County',\n",
       " 'Côtes de Thongue',\n",
       " 'Falerio',\n",
       " 'Colli di Luni',\n",
       " 'Hames Valley',\n",
       " 'Cilento',\n",
       " 'Vino de Mesa',\n",
       " 'Romanée-St.-Vivant',\n",
       " 'Colli Martani',\n",
       " 'Meursault-Blagny',\n",
       " 'Colli di Rimini',\n",
       " 'Sonoma',\n",
       " 'Copertino',\n",
       " 'Gaillac Doux',\n",
       " 'Provincia di Pavia',\n",
       " 'Côtes du Roussillon Villages Tautavel',\n",
       " 'Donnici',\n",
       " 'Mâcon Chaintré',\n",
       " 'Bardolino Classico Superiore',\n",
       " 'Vin de Pays du Val de Cesse',\n",
       " 'Grampians',\n",
       " 'Colli di Salerno',\n",
       " 'Barco Reale di Carmignano',\n",
       " 'Costa Toscana',\n",
       " 'Corton Les Renardes',\n",
       " 'Monti Lessini',\n",
       " 'Bourgogne Epineuil',\n",
       " \"Valle d'Aosta\",\n",
       " 'Goulburn Valley',\n",
       " 'Colli Etruria Centrale',\n",
       " 'Lanzarote',\n",
       " 'Rosazzo',\n",
       " 'Napa-Carneros',\n",
       " 'Sonoma County-Monterey County-Napa County',\n",
       " 'Bordeaux Côtes de Francs ',\n",
       " 'Terre di Franciacorta',\n",
       " 'Riverland',\n",
       " 'Yamhill County',\n",
       " 'Maury',\n",
       " 'Corton-Bressandes',\n",
       " 'Vin de Pays des Portes de Méditerranée',\n",
       " 'Bourgogne Côtes d’Auxerre',\n",
       " 'Cortese di Gavi',\n",
       " 'Périgord',\n",
       " 'Cirò Classico',\n",
       " 'Lessini Durello',\n",
       " 'Castelli Romani',\n",
       " 'Terrazze Retiche di Sondrio',\n",
       " 'Niagara Escarpment',\n",
       " 'Burgundy',\n",
       " 'Chianti Montespertoli',\n",
       " 'Muscadet Coteaux de la Loire',\n",
       " 'Capay Valley',\n",
       " 'Est! Est!! Est!!! di Montefiascone',\n",
       " \"Virginia's Eastern Shore\",\n",
       " 'Montello e Colli Asolani',\n",
       " 'Nardò',\n",
       " 'Pago de Arínzano',\n",
       " 'Riviera Ligure di Ponente',\n",
       " 'Antelope Valley of the California High Desert',\n",
       " 'Mendocino-Amador',\n",
       " 'Breganze',\n",
       " 'Olevano Romano',\n",
       " 'Sierra de Salamanca',\n",
       " 'Monterey-Santa Barbara-Sonoma',\n",
       " 'Boca',\n",
       " 'Illinois',\n",
       " 'Gundagai',\n",
       " 'Saint-Georges-Saint-Émilion',\n",
       " 'Lake County-Sonoma County',\n",
       " 'Montefalco',\n",
       " 'Penisola Sorrentina',\n",
       " 'Saint-Croix-du-Mont',\n",
       " 'Comté Toulosan',\n",
       " 'Roussette de Savoie',\n",
       " 'Lombardy',\n",
       " 'Santa Clara County',\n",
       " 'Mâcon Solutré',\n",
       " 'Sebino',\n",
       " 'Sonoma County-Santa Barbara County',\n",
       " 'Galatina',\n",
       " 'Napa-Amador',\n",
       " 'Mâcon-Davayé',\n",
       " 'Casorzo',\n",
       " 'Vino de la Tierra Ribera del Gállego-Cinco Villas',\n",
       " 'Ribera del Júcar',\n",
       " 'Montecarlo',\n",
       " 'Aude Hauterive',\n",
       " 'Irrouléguy',\n",
       " 'Aglianico del Beneventano',\n",
       " 'Emporadà-Costa Brava',\n",
       " 'Pouilly-sur-Loire',\n",
       " 'Dolcetto di Dogliani Superiore',\n",
       " 'Laudun',\n",
       " 'Valtellina',\n",
       " 'Gambellara Classico',\n",
       " 'Tuolumne County',\n",
       " 'Napa County-Sonoma County-Lake County',\n",
       " 'Kentucky',\n",
       " 'Irancy',\n",
       " 'Lugana Superiore',\n",
       " \"Dolcetto d'Acqui\",\n",
       " 'Atlantique',\n",
       " 'Clos de Lambrays',\n",
       " 'Solano County Green Valley',\n",
       " 'California Other',\n",
       " 'Offida Rosso',\n",
       " 'Vin Doux Naturel Rasteau',\n",
       " 'Vermont',\n",
       " 'Western Connecticut Highlands',\n",
       " 'Short Hills Bench',\n",
       " 'Torgiano Rosso Riserva',\n",
       " 'Mendocino-Sonoma-Amador',\n",
       " 'Aminga Valley',\n",
       " 'Nevada',\n",
       " 'San Marino',\n",
       " 'Mâcon-Charnay',\n",
       " 'Ischia',\n",
       " 'Alto Valle de Uco',\n",
       " 'Chianti Colli Pisani',\n",
       " 'Biferno Rosso',\n",
       " 'Alta Valle della Greve',\n",
       " 'Napa County-Sonoma County-San Joaquin County',\n",
       " 'Central Valley',\n",
       " 'Sonoma County-San Joaquin County',\n",
       " 'Saussignac',\n",
       " 'Cérons',\n",
       " 'Mâcon-Uchizy',\n",
       " 'Arcole',\n",
       " 'Ramona Valley',\n",
       " 'Malibu Coast',\n",
       " 'Oregon Other',\n",
       " 'Sonoma County-Monterey County',\n",
       " 'Strathbogie Ranges',\n",
       " 'Coteaux du Layon Beaulieu',\n",
       " 'Clos de Tart',\n",
       " 'Corton-Rognet',\n",
       " \"St. David's Bench\",\n",
       " 'Touraine Amboise',\n",
       " 'Criots-Bâtard-Montrachet',\n",
       " 'Barbera di Piemonte',\n",
       " 'Murray-Darling',\n",
       " 'Monreale',\n",
       " 'Tumbarumba',\n",
       " 'Colli Euganei',\n",
       " \"Lacrima di Morro d'Alba\",\n",
       " 'Vin de Pays de France',\n",
       " 'Charentais',\n",
       " 'Leverano',\n",
       " 'Muscadet Sèvre et Maine Clisson',\n",
       " 'Currency Creek',\n",
       " 'Santa Barbara-Monterey',\n",
       " 'Epomeo',\n",
       " 'Colline Lucchesi',\n",
       " 'Rasteau',\n",
       " 'Candia Dei Colli Apuani',\n",
       " 'Muscat de Saint-Jean de Minervois',\n",
       " 'Bardolino Superiore',\n",
       " 'Beaujolais-Leynes',\n",
       " 'Mâcon-Prissé',\n",
       " 'Macon-Bussières',\n",
       " 'McDowell Valley',\n",
       " 'Mount Benson',\n",
       " 'Ardèche',\n",
       " 'Colli Pesaresi',\n",
       " 'Passito di Noto',\n",
       " 'Mâcon-Vergisson',\n",
       " 'Coteaux du Layon Chaume',\n",
       " 'Savennières-Coulée de Serrant',\n",
       " \"Diano d'Alba\",\n",
       " 'Ventura County',\n",
       " 'Bullas',\n",
       " 'Monterey-Santa Cruz',\n",
       " 'Moscato di Pantelleria',\n",
       " 'Vino de la Tierra de Zamora',\n",
       " 'North Yuba',\n",
       " 'Vin de Pays des Coteaux de Peyriac',\n",
       " 'Corton-Pougets',\n",
       " 'Similkameen Valley',\n",
       " 'Gard',\n",
       " 'Amador-Napa',\n",
       " 'St.-Véran',\n",
       " 'Southern Fleurieu',\n",
       " 'Côte Roannaise',\n",
       " 'Côtes de Thau',\n",
       " 'Terrasses du Larzac',\n",
       " 'Moscato di Trani',\n",
       " 'Coteaux du Layon La Faye',\n",
       " \"Dolcetto d'Alba Superiore\",\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_region = list(region_counts[region_counts < 500].index)\n",
    "replace_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0554b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in replace_region:\n",
    "    wine_df.region_1 = wine_df.region_1.replace(i,\"Other\")\n",
    "\n",
    "region_counts = wine_df.region_1.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acabaf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af8117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Williams Selyem          585\n",
       "Testarossa               495\n",
       "DFJ Vinhos               473\n",
       "Chateau Ste. Michelle    420\n",
       "Wines & Winemakers       392\n",
       "                        ... \n",
       "Namasté Vineyards          1\n",
       "Finnegan's Lake            1\n",
       "Villa Yustina              1\n",
       "Sexual Chocolate           1\n",
       "Penedo Borges              1\n",
       "Name: winery, Length: 19186, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery_counts=wine_df.winery.value_counts()\n",
    "winery_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a986bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "winery_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd4bfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19186.000000\n",
       "mean        14.688523\n",
       "std         27.001841\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          5.000000\n",
       "75%         15.000000\n",
       "max        585.000000\n",
       "Name: winery, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfca1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Caldora Vini',\n",
       " 'Château Kirwan',\n",
       " 'Château Pichon Longueville Comtesse de Lalande',\n",
       " 'Château Rahoul',\n",
       " 'Kaesler',\n",
       " 'Morgante',\n",
       " 'Dominio de Atauta',\n",
       " 'Campelo',\n",
       " 'Lost Angel',\n",
       " 'Château Lynch-Bages',\n",
       " 'Wayfarer',\n",
       " 'Anne Amie',\n",
       " 'Belasco de Baquedano',\n",
       " 'Pope Valley Winery',\n",
       " 'Tangley Oaks',\n",
       " 'Nora',\n",
       " 'Vilafonté',\n",
       " 'Delamotte',\n",
       " 'Verbena',\n",
       " 'Liparita',\n",
       " 'Calistoga Cellars',\n",
       " 'Bourassa Vineyards',\n",
       " 'Langmeil',\n",
       " 'The Colonial Estate',\n",
       " 'Heidsieck & Co Monopole',\n",
       " 'Inception',\n",
       " 'Cescon Italo Storia e Vini',\n",
       " 'Château la Gaffelière',\n",
       " 'Araldica',\n",
       " 'Estate Constantin Gofas',\n",
       " 'Vino Con Brio',\n",
       " 'Brugnano',\n",
       " 'Carrick',\n",
       " 'Buitenverwachting',\n",
       " 'Sacred Hill',\n",
       " 'Rockroom Winemaking Cooperative',\n",
       " 'Manzanita Creek',\n",
       " 'La Valle',\n",
       " 'Kings Ridge',\n",
       " 'Musella',\n",
       " 'Ottimino Vineyards',\n",
       " 'J. Wilkes',\n",
       " 'Viñedos y Bodegas Pablo',\n",
       " 'Cerro Prieto',\n",
       " 'Huntington',\n",
       " 'Lanson',\n",
       " 'Domaine Pommier',\n",
       " 'Two Angels',\n",
       " 'Luigi Righetti',\n",
       " 'Alberti 154',\n",
       " 'Schwarzböck',\n",
       " 'Robert Ramsay',\n",
       " 'Villa Rubini',\n",
       " 'Domaine de la Sauveuse',\n",
       " 'Tapeña',\n",
       " 'Monteci',\n",
       " 'Cascina Bongiovanni',\n",
       " 'Château Léoville Poyferré',\n",
       " 'Wohlmuth',\n",
       " 'Ricossa',\n",
       " 'Mossback',\n",
       " 'Korbin Kameron',\n",
       " 'Abad Dom Bueno',\n",
       " 'VML',\n",
       " 'Col Solare',\n",
       " 'Sawyer',\n",
       " 'Piazzo Armando',\n",
       " 'Riglos',\n",
       " 'Paul Cheneau',\n",
       " 'Baker & Brain',\n",
       " 'Domaine des Terrisses',\n",
       " 'Rocche Costamagna',\n",
       " 'Marziano Abbona',\n",
       " 'Jeff Gordon',\n",
       " 'Long Meadow Ranch',\n",
       " 'Poggio Verrano',\n",
       " 'Inspire Moore',\n",
       " 'Almquist',\n",
       " 'Bodegas Peñafiel',\n",
       " 'El Huique',\n",
       " 'Nasiakos',\n",
       " 'Tenuta San Giorgio',\n",
       " 'Lang & Reed',\n",
       " 'Château Talbot',\n",
       " 'Ciabot Berton',\n",
       " 'Château Clerc Milon',\n",
       " 'Atlas Peak',\n",
       " 'Maximo',\n",
       " 'Fattoria Fibbiano',\n",
       " 'Gaia Wines',\n",
       " 'Ricci Curbastro',\n",
       " 'Cantine Rallo',\n",
       " 'Cascina Luisin',\n",
       " 'Santa Margherita',\n",
       " 'Pinhal da Torre',\n",
       " 'Sumarroca',\n",
       " 'Three Fox',\n",
       " 'Breggo',\n",
       " 'Château Gassier',\n",
       " 'Gunn Estate',\n",
       " 'Stinson',\n",
       " 'Feliz Noche',\n",
       " 'Atmosphere',\n",
       " 'Comelli',\n",
       " 'Corte Moschina',\n",
       " 'Heinz Eifel',\n",
       " 'Maipe',\n",
       " 'Bertrand Ambroise',\n",
       " 'Porcupine Ridge',\n",
       " 'Château Lagrange',\n",
       " 'Sandrone',\n",
       " 'Hess Select',\n",
       " 'Château des Karantes',\n",
       " 'Costaripa',\n",
       " 'Big Table Farm',\n",
       " 'Château Lascombes',\n",
       " 'Oberon',\n",
       " 'Millésimé',\n",
       " 'Château Rauzan-Ségla',\n",
       " 'Unger',\n",
       " 'Huia',\n",
       " 'Montgó',\n",
       " 'Fattoria di Grignano',\n",
       " 'Lusco',\n",
       " 'Vite Colte',\n",
       " 'Vermeil',\n",
       " 'Carpe Diem',\n",
       " 'Napa Family Vineyards',\n",
       " 'Primus',\n",
       " 'Ara',\n",
       " 'Weszeli',\n",
       " 'Gesellmann',\n",
       " 'Écluse',\n",
       " 'Yorba',\n",
       " 'Ardor',\n",
       " 'Thirsty Owl Wine Company',\n",
       " 'Cave de Saumur',\n",
       " 'Drusian',\n",
       " 'Pikes',\n",
       " 'Peconic Bay Winery',\n",
       " 'Bel Colle',\n",
       " 'Tenuta di Sesta',\n",
       " 'Cambiata',\n",
       " 'Mascota',\n",
       " 'Vignerons de Buzet',\n",
       " 'Poeira',\n",
       " 'Ayoub',\n",
       " 'La Valentina',\n",
       " 'Acrobat',\n",
       " 'Château de Chambert',\n",
       " 'Calicaro',\n",
       " 'Comm. G. B. Burlotto',\n",
       " 'Pascal Doquet',\n",
       " 'Scala Dei',\n",
       " 'Weixelbaum',\n",
       " 'Ancient Oak Cellars',\n",
       " 'Mud House',\n",
       " 'Condes de Albarei',\n",
       " 'Château Léoville Barton',\n",
       " 'Palazzo',\n",
       " 'Domaine de Nizas',\n",
       " 'Cramele Halewood',\n",
       " 'Targovishte',\n",
       " 'Manfred Tement',\n",
       " 'Alvear',\n",
       " 'Canneta',\n",
       " 'Remírez de Ganuza',\n",
       " 'Bodegas Iranzo',\n",
       " 'Borgo Scopeto',\n",
       " 'Casa Montes',\n",
       " 'Producta Vignobles',\n",
       " 'Powers',\n",
       " 'Montenisa',\n",
       " 'Mount Eden',\n",
       " 'Felipe Rutini',\n",
       " 'Di Majo Norante',\n",
       " 'Giuseppe Campagnola',\n",
       " 'Fall Line',\n",
       " 'Marqués de Riscal',\n",
       " 'Château Bellevue la Forêt',\n",
       " 'Santa Luz',\n",
       " 'Domaine Sorin',\n",
       " 'Blakeslee',\n",
       " 'Château Saint-Pierre',\n",
       " 'Frankland Estate',\n",
       " 'Brophy Clark',\n",
       " \"Segal's\",\n",
       " 'Vineyard 7&8',\n",
       " 'Eola Hills',\n",
       " 'Madroña',\n",
       " 'Antonelli',\n",
       " 'Rutherford Grove',\n",
       " 'Saint Gregory',\n",
       " 'Le Grascete',\n",
       " 'Hilltown',\n",
       " 'Casal Paço Padreiro',\n",
       " 'André Brunel',\n",
       " 'Château de Lancyre',\n",
       " 'Volteo',\n",
       " 'Thorn Clarke',\n",
       " 'Castello di Verrazzano',\n",
       " 'Pietrafitta',\n",
       " 'Domaine Michel Fonne',\n",
       " 'Dashwood',\n",
       " 'Leaping Horse',\n",
       " 'VinArte',\n",
       " 'Foxen 7200',\n",
       " 'Cascina La Ghersa',\n",
       " 'Portalupi',\n",
       " 'Whidbey Island Winery',\n",
       " 'Katnook Estate',\n",
       " 'Martinez & Martinez',\n",
       " 'The Four Graces',\n",
       " 'Vigilance',\n",
       " 'Cape Mentelle',\n",
       " 'Castello Monaci',\n",
       " 'Perticaia',\n",
       " 'Hestan',\n",
       " 'Domaine Vincent Carême',\n",
       " 'Marco Abella',\n",
       " 'Jordan',\n",
       " 'Buttonwood',\n",
       " 'Château de Nages',\n",
       " 'San Huberto',\n",
       " 'Olson Ogden',\n",
       " 'Quinta dos Roques',\n",
       " 'Boheme',\n",
       " 'Lobo',\n",
       " 'Donelan',\n",
       " 'Green Point',\n",
       " 'Gino Fasoli',\n",
       " 'Château La Rame',\n",
       " 'Principe Corsini Fattoria Le Corti',\n",
       " 'Mil Piedras',\n",
       " 'Drei Donà Tenuta La Palazza',\n",
       " 'Yealands',\n",
       " 'David Girard',\n",
       " 'Corliss Estates',\n",
       " 'Château la Louvière',\n",
       " 'Fattoria Petrolo',\n",
       " 'Felsina',\n",
       " 'Château Ferrière',\n",
       " 'Wedell Cellars',\n",
       " 'Domaine Dupré',\n",
       " 'Braida di Giacomo Bologna',\n",
       " 'Brewer-Clifton',\n",
       " 'Boroli',\n",
       " 'Alice White',\n",
       " 'Debonné',\n",
       " 'Scharffenberger',\n",
       " 'Renteria',\n",
       " 'Punset',\n",
       " 'Bodega Cuarto Dominio',\n",
       " 'Haut Marin',\n",
       " 'Fossacolle',\n",
       " 'Salvestrin',\n",
       " 'Prinsi',\n",
       " 'Domaine Sipp-Mack',\n",
       " 'Maison Bouey',\n",
       " 'Cave de Cleebourg',\n",
       " 'Château Gruaud Larose',\n",
       " 'Heart & Hands',\n",
       " 'Kobler',\n",
       " 'DeMorgenzon',\n",
       " 'Radford Dale',\n",
       " 'Nefarious',\n",
       " 'Belle Vallée',\n",
       " \"Domaine l'Ancienne Cure\",\n",
       " 'Jorian Hill',\n",
       " 'Hopper Creek',\n",
       " 'Cambridge & Sunset',\n",
       " 'Staete Landt',\n",
       " 'Franz Haas',\n",
       " 'La Clarine Farm',\n",
       " 'La Colombina',\n",
       " 'Crossroads',\n",
       " 'Bouchard Finlayson',\n",
       " 'Esser',\n",
       " 'R Wines',\n",
       " 'Germano Ettore',\n",
       " 'Dalton',\n",
       " 'CarlindePaolo',\n",
       " 'Dr. Bürklin-Wolf',\n",
       " 'Ferrero',\n",
       " 'Harmony Cellars',\n",
       " 'Henriot',\n",
       " 'Bock',\n",
       " 'Saxum',\n",
       " 'Türk',\n",
       " 'Eugenio Collavini',\n",
       " 'Botter',\n",
       " 'Fattoria Zerbina',\n",
       " 'Adriano Marco & Vittorio',\n",
       " 'Grimaldi Bruna',\n",
       " 'Château Labégorce Margaux',\n",
       " 'Terrapura',\n",
       " 'Or Haganuz',\n",
       " 'Dancing Bull',\n",
       " 'Asuncion Ridge',\n",
       " 'Domaine Matthias et Emile Roblin',\n",
       " 'Matthews',\n",
       " 'Mills Reef',\n",
       " 'Bortolin',\n",
       " 'Martinborough Vineyard',\n",
       " 'French Hill',\n",
       " 'Juslyn Vineyards',\n",
       " 'Echelon',\n",
       " 'Bella Piazza',\n",
       " 'Perrin & Fils',\n",
       " 'Sequana',\n",
       " 'Page Springs',\n",
       " 'Montemaggiore',\n",
       " 'Oriel',\n",
       " 'Dunning Vineyards',\n",
       " 'Quinta de Foz de Arouce',\n",
       " 'Locati Cellars',\n",
       " 'Bink',\n",
       " 'Château Coussin',\n",
       " 'Jules Taylor',\n",
       " 'Illahe',\n",
       " 'Brooklyn Oenology',\n",
       " 'Canalicchio di Sopra',\n",
       " 'Schmitt Söhne',\n",
       " 'San Lorenzo',\n",
       " 'Rosenhof',\n",
       " \"Cantine Sant'Agata\",\n",
       " 'Stonehedge',\n",
       " 'Castillo De Feliciana',\n",
       " 'Château de Fontenille',\n",
       " 'Dobbes Family Estate',\n",
       " 'Château Larroque',\n",
       " 'Shiloh Road',\n",
       " 'Giacomo Grimaldi',\n",
       " 'C.H. Berres',\n",
       " 'Morro Bay',\n",
       " 'St. Innocent',\n",
       " 'Parallel',\n",
       " 'Cormòns',\n",
       " 'De Toren',\n",
       " 'Wine Guerrilla',\n",
       " 'Turkey Flat',\n",
       " 'Stuart Cellars',\n",
       " 'Surh Luchtel',\n",
       " 'Tenuta Carretta',\n",
       " 'Lagar de Bezana',\n",
       " 'Fratelli Casetta',\n",
       " 'Fullerton',\n",
       " 'Quinta da Raza',\n",
       " 'Monte Rossa',\n",
       " 'Barra of Mendocino',\n",
       " 'Château Lafon-Rochet',\n",
       " 'Domaine Bousquet',\n",
       " \"Monte dall'Ora\",\n",
       " 'Caccia al Piano 1868',\n",
       " 'Corvus',\n",
       " 'Waterford',\n",
       " 'Vignobles Brumont',\n",
       " 'Bonaccorsi',\n",
       " 'Schmitges',\n",
       " 'Morse',\n",
       " 'El Nido',\n",
       " 'Dante Robere',\n",
       " 'Vision Cellars',\n",
       " 'Domaine Drouhin Oregon',\n",
       " 'Meadowcroft',\n",
       " 'Rancho Arroyo Grande',\n",
       " 'Martella',\n",
       " 'Vavasour',\n",
       " 'Cavallotto',\n",
       " 'Styring',\n",
       " 'Petra',\n",
       " 'Daniel Gehrs',\n",
       " 'Adegas Gran Vinum',\n",
       " 'Cederberg',\n",
       " 'Castillo Clavijo',\n",
       " 'La Spinetta',\n",
       " 'Podere La Vigna',\n",
       " 'Crane Brothers',\n",
       " 'Ronco del Gelso',\n",
       " 'Sottimano',\n",
       " 'Meyer Family Vineyards',\n",
       " 'San Polino',\n",
       " 'Tenuta Friggiali',\n",
       " 'Ernie Els',\n",
       " 'Rietvallei Estate Wine',\n",
       " 'Francesco Rinaldi',\n",
       " 'Pezzi King',\n",
       " 'MCV',\n",
       " 'The Federalist',\n",
       " 'Stoneleigh',\n",
       " 'Bodega Chacra',\n",
       " 'JC Cellars',\n",
       " 'Cordero di Montezemolo',\n",
       " 'Hiedler',\n",
       " 'Sonoma-Loeb',\n",
       " 'Carter',\n",
       " 'Château Brane-Cantenac',\n",
       " 'Scott Family',\n",
       " 'Chapel Hill',\n",
       " 'Stroppiana',\n",
       " 'Buglioni',\n",
       " 'Château Grand-Puy Ducasse',\n",
       " 'Broadbent',\n",
       " 'Portal del Montsant',\n",
       " 'Bortoluzzi',\n",
       " 'Antonio Cesar Cavalli',\n",
       " 'Il Marroneto',\n",
       " 'Fornacelle',\n",
       " 'Pillitteri',\n",
       " 'Tenuta Valdipiatta',\n",
       " 'Fattoi',\n",
       " 'Bindella',\n",
       " 'Bacio Divino',\n",
       " 'Leasingham',\n",
       " 'Château Doisy-Daëne',\n",
       " 'Casa de Vila Verde',\n",
       " 'Château de Malle',\n",
       " 'Terra Silvestre',\n",
       " 'Maison Nicolas Perrin',\n",
       " 'Maycas del Limari',\n",
       " 'Ferraton Pere et Fils',\n",
       " 'Casa Ferreirinha',\n",
       " 'Tenuta Villa Trasqua',\n",
       " 'Paoletti',\n",
       " 'Langlois-Chateau',\n",
       " \"L'Antica Quercia\",\n",
       " 'Bighorn',\n",
       " 'Château Picque Caillou',\n",
       " 'Fernwood',\n",
       " 'Honig',\n",
       " 'Tabarrini',\n",
       " 'Château Cabredon',\n",
       " 'Borgo di Colloredo',\n",
       " 'Pradorey',\n",
       " 'Flocchini',\n",
       " 'Torre Rosazza',\n",
       " 'Château de Rayne Vigneau',\n",
       " 'El Circulo',\n",
       " 'Pietro Beconcini',\n",
       " 'Clos du Lac',\n",
       " 'Domaine Sainte-Marie',\n",
       " 'Gemtree',\n",
       " 'Château La Joya',\n",
       " 'Dr. Nägler',\n",
       " 'Standish',\n",
       " 'Brovia',\n",
       " 'Revelry',\n",
       " 'Lucia',\n",
       " 'Casa de Vilacetinho',\n",
       " 'Malibràn',\n",
       " 'Domaine du Moulin',\n",
       " 'Château de Lavernette',\n",
       " 'Fiddlehead',\n",
       " 'Mutt Lynch',\n",
       " 'Wildhurst',\n",
       " 'XYZin',\n",
       " 'Tohu',\n",
       " 'Mount Eden Vineyards',\n",
       " 'Rocca di Montemassi',\n",
       " 'Alloro',\n",
       " 'Schloss Halbturn',\n",
       " 'Domaine de Vaugondy',\n",
       " 'Straight Line',\n",
       " 'Anglim',\n",
       " 'Rappahannock Cellars',\n",
       " 'Yamhill Valley',\n",
       " 'Il Borro',\n",
       " 'Bastianich',\n",
       " 'Camelot',\n",
       " 'Straccali',\n",
       " 'Norman',\n",
       " 'The Grapes of Roth',\n",
       " 'Castelgiocondo',\n",
       " 'Meli',\n",
       " 'Rockburn',\n",
       " 'Lallier',\n",
       " 'Maculan',\n",
       " 'Delicato',\n",
       " 'Turley',\n",
       " 'Herdade das Servas',\n",
       " 'Omero',\n",
       " 'Château du Tertre',\n",
       " 'Château Haut-Bailly',\n",
       " 'Red Rock',\n",
       " 'Vaona',\n",
       " 'Villa Canestrari',\n",
       " 'François Millet',\n",
       " 'Goldwater',\n",
       " 'Chocolate Box',\n",
       " 'Brass Tacks',\n",
       " 'Château la Garde',\n",
       " 'Broadway Vineyards',\n",
       " 'Hourglass',\n",
       " 'Château de la Roulerie',\n",
       " 'Domaine Albert Mann',\n",
       " 'Castello dei Rampolla',\n",
       " 'COS',\n",
       " 'Castello di Verduno',\n",
       " 'The Crusher',\n",
       " 'Ayala',\n",
       " 'Château Nairac',\n",
       " 'Antica Fratta',\n",
       " 'Espiritu de Argentina',\n",
       " 'Falcor',\n",
       " 'Andrew Rich',\n",
       " 'Elizabeth Chambers',\n",
       " 'Season',\n",
       " \"Ca' del Solo\",\n",
       " 'Bret Brothers',\n",
       " \"Zonte's Footstep\",\n",
       " 'Château Lamartine',\n",
       " 'Paolo Calì',\n",
       " 'Barossa Valley Estate',\n",
       " 'Don Miguel Gascón',\n",
       " 'Lost River',\n",
       " 'Kings Mountain',\n",
       " 'Junta',\n",
       " \"Lawson's Dry Hills\",\n",
       " 'Domaine de Leyre-Loup',\n",
       " 'Weinrieder',\n",
       " 'Helwig',\n",
       " 'Vignoble de la Jarnoterie',\n",
       " 'Château Durfort-Vivens',\n",
       " 'Spanish Vines',\n",
       " 'Val de Los Frailes',\n",
       " 'Josh Cellars',\n",
       " 'Belden Barns',\n",
       " 'Lantieri de Paratico',\n",
       " 'Mercer Canyons',\n",
       " 'Murganheira',\n",
       " 'Martinshof',\n",
       " 'Château de Pez',\n",
       " 'Breaux',\n",
       " 'Kemblefield',\n",
       " 'Ignacio Marín',\n",
       " 'Filus',\n",
       " 'Henriet-Bazin',\n",
       " 'Mount Veeder',\n",
       " 'Cecilia Beretta',\n",
       " 'Domaine du Colombier',\n",
       " 'Caprili',\n",
       " 'Château Lynch-Moussas',\n",
       " 'San Nicolas',\n",
       " 'Burrowing Owl',\n",
       " \"Château d'Armailhac\",\n",
       " 'Lenné Estate',\n",
       " 'Eric Kent',\n",
       " 'TerraMater',\n",
       " 'Vila',\n",
       " 'Château Coutinel',\n",
       " 'Bodega Goulart',\n",
       " 'Santa Lucia',\n",
       " 'Château Fourcas Dupré',\n",
       " 'Pewsey Vale',\n",
       " 'Enkidu',\n",
       " 'Château du Port',\n",
       " 'Au Pied du Mont Chauve',\n",
       " 'Château Haut-Bergey',\n",
       " \"Poet's Leap\",\n",
       " 'Château Rauzan-Gassies',\n",
       " 'Juan Gil',\n",
       " 'Grandes Vinos y Viñedos',\n",
       " 'Tassi',\n",
       " 'San Biagio',\n",
       " 'Marqués de Vargas',\n",
       " 'Adega de Cantanhede',\n",
       " 'Sheridan Vineyard',\n",
       " 'Ruhlmann',\n",
       " 'Schulz',\n",
       " 'Fontodi',\n",
       " 'Domaine A. Machard de Gramont',\n",
       " 'Picket Fence',\n",
       " 'Tenuta di Fessina',\n",
       " 'G D Vajra',\n",
       " 'Agricoltori del Chianti Geografico',\n",
       " 'Château Couhins-Lurton',\n",
       " 'Tommaso Bussola',\n",
       " 'Inman Family',\n",
       " 'Nodland',\n",
       " 'Lyrarakis',\n",
       " 'Château la Tour Blanche',\n",
       " 'Selaks',\n",
       " 'Wise Villa',\n",
       " 'Biecher & Schaal',\n",
       " 'Spicy Vines',\n",
       " 'Otazu',\n",
       " 'Giacomo Ascheri',\n",
       " 'Mano A Mano',\n",
       " \"Trabucchi d'Illasi\",\n",
       " \"Stephen's\",\n",
       " 'Ancient Cellars',\n",
       " 'Orchid Hill',\n",
       " 'Allimant-Laugner',\n",
       " 'Occhipinti',\n",
       " 'Marc Sorrel',\n",
       " 'Ritual',\n",
       " 'Viñas del Cenit',\n",
       " 'Moccagatta',\n",
       " 'Truett Hurst',\n",
       " 'Goat Bubbles',\n",
       " 'Bella Luna',\n",
       " 'Michael Florentino',\n",
       " 'Baron-Fuenté',\n",
       " 'Fattoria di Magliano',\n",
       " 'Flying Trout',\n",
       " 'Montaribaldi',\n",
       " 'Manara',\n",
       " 'Alma del Sur',\n",
       " \"Quails' Gate\",\n",
       " 'Five Rivers',\n",
       " \"Val d'Oca\",\n",
       " 'Shoofly',\n",
       " 'Inniskillin',\n",
       " 'Veritas',\n",
       " 'Adega Mayor',\n",
       " 'Voss',\n",
       " 'Dr. Heyden',\n",
       " 'Solar de Pinheiro',\n",
       " 'Chatom',\n",
       " 'Col Vetoraz Spumanti',\n",
       " 'Peregrine',\n",
       " 'Lombard et Cie',\n",
       " 'David Sterza',\n",
       " 'Fiddletown Cellars',\n",
       " 'Château Prieuré-Lichine',\n",
       " 'Kurtz Family',\n",
       " 'Paolo Manzone',\n",
       " 'Rheingraf',\n",
       " 'Il Follo',\n",
       " 'Villa Cafaggio',\n",
       " 'Demarie',\n",
       " 'Bigi',\n",
       " 'The Calling',\n",
       " 'Château Croizet-Bages',\n",
       " 'La Jota Vineyard',\n",
       " 'Sonnet',\n",
       " 'Lake Chalice',\n",
       " 'MooBuzz',\n",
       " 'Cannonball',\n",
       " 'Reynvaan Family Vineyards',\n",
       " 'Château Thieuley',\n",
       " 'Muruve',\n",
       " 'Sallier de la Tour',\n",
       " 'Gebeshuber',\n",
       " 'Prinz',\n",
       " 'Lujon',\n",
       " 'Del Dotto',\n",
       " 'Château de France',\n",
       " 'Citille di Sopra',\n",
       " 'Ombu',\n",
       " 'Borgogno F.lli Serio e Battista',\n",
       " 'Gaba do Xil',\n",
       " 'Pauletts',\n",
       " 'Cave de Beblenheim',\n",
       " 'Sanguinhal',\n",
       " 'Château Tronquoy-Lalande',\n",
       " 'I Balzini',\n",
       " 'Eponymous',\n",
       " 'Podere Paganico',\n",
       " 'Talus',\n",
       " 'Gallo of Sonoma',\n",
       " 'Forrest Estate',\n",
       " 'Rexford',\n",
       " 'Calvet',\n",
       " 'Valle Secreto',\n",
       " 'Graci',\n",
       " 'Prime',\n",
       " 'Zimmermann',\n",
       " 'Tornesi',\n",
       " 'Philip Shaw',\n",
       " 'Louis Tête',\n",
       " 'Constant',\n",
       " 'Antolini',\n",
       " 'Albino Armani',\n",
       " 'Cantine Lenotti di Lenotti',\n",
       " 'Meander',\n",
       " 'Les Vignerons Réunis de Monségur',\n",
       " 'Longplay',\n",
       " \"Corte Sant' Alda\",\n",
       " 'Château Guiraud',\n",
       " 'Elderton',\n",
       " 'Occidental Road Cellars',\n",
       " 'Township 7',\n",
       " 'Beaver Creek',\n",
       " 'Greek Wine Cellars',\n",
       " 'Cremaschi Furlotti',\n",
       " 'Ogier',\n",
       " 'Albert Morot',\n",
       " 'Passopisciaro',\n",
       " 'Poggio Mandorlo',\n",
       " 'Pagos del Moncayo',\n",
       " 'Grans-Fassian',\n",
       " 'Vellum',\n",
       " 'Valdubón',\n",
       " 'Bernhard Ott',\n",
       " 'Roshambo',\n",
       " 'Pepi',\n",
       " 'Noceto',\n",
       " 'Pittnauer',\n",
       " 'La Fornace',\n",
       " 'Patit Creek Cellars',\n",
       " 'Forth',\n",
       " 'Emblem',\n",
       " 'Larchago',\n",
       " 'Allan Scott',\n",
       " 'Château Duhart-Milon',\n",
       " 'Besserat de Bellefon',\n",
       " 'Château Cantenac Brown',\n",
       " 'Shenandoah Vineyards',\n",
       " 'Raats Family',\n",
       " 'Ernst Triebaumer',\n",
       " 'Northwest Cellars',\n",
       " 'R & B Cellars',\n",
       " 'Martín Berdugo',\n",
       " 'Arrocal',\n",
       " 'Acordeón',\n",
       " 'Ferraud et Fils',\n",
       " 'Hunt Country Vineyards',\n",
       " 'Lucky Star',\n",
       " 'Stark',\n",
       " 'Kramer',\n",
       " 'Espuela del Gaucho',\n",
       " 'Atalon',\n",
       " 'Plumb Cellars',\n",
       " 'SuLei',\n",
       " 'Redwood Creek',\n",
       " 'Le Chiuse',\n",
       " 'Alto Moncayo',\n",
       " 'Van Duzer',\n",
       " 'Summerer',\n",
       " 'Churchill Cellars',\n",
       " 'Torre Oria',\n",
       " 'Les Belles Collines',\n",
       " 'Eradus',\n",
       " 'Zero One Vintners',\n",
       " 'Laroche',\n",
       " 'Rutz',\n",
       " 'Dr. Fischer',\n",
       " 'Bodkin',\n",
       " 'Lannac Saint-Jean',\n",
       " 'Bodegas Ateca',\n",
       " 'Corte Lenguin',\n",
       " 'Cascina delle Rose',\n",
       " 'Skinner',\n",
       " 'Brancaia',\n",
       " 'Quinta do Sagrado',\n",
       " 'Alta Colina',\n",
       " 'Collelceto',\n",
       " 'Prà',\n",
       " 'Bosio',\n",
       " 'Dominican Oaks',\n",
       " 'Giuseppe Cortese',\n",
       " 'Iby',\n",
       " 'Poggio Argentiera',\n",
       " 'Ken Brown',\n",
       " 'Baxter',\n",
       " 'Le Potazzine',\n",
       " 'Proemio',\n",
       " 'Stolo',\n",
       " 'Lisini',\n",
       " 'Protopapas',\n",
       " 'Château les Ormes de Pez',\n",
       " 'Castello di Bolgheri',\n",
       " 'Hamacher',\n",
       " 'Château Angélus',\n",
       " 'Mount Langi Ghiran',\n",
       " 'Villa Huesgen',\n",
       " 'Manincor',\n",
       " 'Château Brown',\n",
       " 'Round Hill',\n",
       " 'Cottonwood Canyon',\n",
       " 'Michel Redde et Fils',\n",
       " 'Rust en Vrede',\n",
       " 'Château Bellevue',\n",
       " 'Laurent Miquel',\n",
       " 'Clos Fourtet',\n",
       " 'Rivino',\n",
       " 'Purcari',\n",
       " \"Ca' del Baio\",\n",
       " 'Château Grand-Maison',\n",
       " 'Inama',\n",
       " 'Château de Myrat',\n",
       " 'Adega Cooperativa Ponte de Barca',\n",
       " 'Tudor Wines',\n",
       " 'Parras Wines',\n",
       " 'Viento',\n",
       " 'Martin Schaetzel',\n",
       " 'Winkler-Hermaden',\n",
       " 'Conte Collalto',\n",
       " 'Abarbanel',\n",
       " 'Viña Chocalan',\n",
       " 'Vinha Paz',\n",
       " 'Townley',\n",
       " 'Angove',\n",
       " 'Niedermayr Josef',\n",
       " 'Domaine Ferret',\n",
       " 'Chelsea Goldschmidt',\n",
       " 'Jenica Peak',\n",
       " 'Jean Becker',\n",
       " 'Fogdog',\n",
       " \"Château d'Or et de Gueules\",\n",
       " 'Mastrojanni',\n",
       " 'Nada Giuseppe',\n",
       " 'Jorge Ordóñez & Co.',\n",
       " 'Carlos Serres',\n",
       " 'Envolve',\n",
       " 'Le Ragose',\n",
       " 'Château Lafaurie-Peyraguey',\n",
       " 'Bibich',\n",
       " 'Consejo de la Alta',\n",
       " 'Mount Cass',\n",
       " 'Domaine Perrot-Minot',\n",
       " 'Château Plaisance',\n",
       " 'Boxwood',\n",
       " 'Jamie Slone Wines',\n",
       " 'Owl Ridge',\n",
       " 'Simon Hackett',\n",
       " 'Quadra',\n",
       " 'Furthermore',\n",
       " 'Les Astéries',\n",
       " 'Finca Agostino',\n",
       " 'Château Hosanna',\n",
       " 'Château la Rayre',\n",
       " 'Aia Vecchia',\n",
       " 'Thistle',\n",
       " 'Two Oceans',\n",
       " 'Henry of Pelham',\n",
       " 'Sequel',\n",
       " 'Summerwood',\n",
       " 'Domaine du Petit Coteau',\n",
       " 'Bibbiano',\n",
       " 'Transcendence',\n",
       " 'Bodegas Pirineos',\n",
       " 'Brittan Vineyards',\n",
       " 'La Braccesca',\n",
       " 'Delectus',\n",
       " 'The Farm Winery',\n",
       " 'Majolini',\n",
       " 'Château Clos Haut-Peyraguey',\n",
       " 'Notro',\n",
       " 'Saracina',\n",
       " 'Alente',\n",
       " 'Couloir',\n",
       " 'Charles & Charles',\n",
       " 'Crossbarn by Paul Hobbs',\n",
       " 'Enotria',\n",
       " 'Forget-Brimont',\n",
       " 'A Donkey and Goat',\n",
       " 'Michel & Stéphane Ogier',\n",
       " 'Bokisch',\n",
       " 'Addamo',\n",
       " 'Wood Family Vineyards',\n",
       " 'Monteverro',\n",
       " 'Rainstorm',\n",
       " 'Gracianna',\n",
       " 'Principe di Corleone',\n",
       " 'Xanadu',\n",
       " 'Lucania',\n",
       " 'Fondo Antico',\n",
       " 'Amisfield',\n",
       " 'Fornacina',\n",
       " 'Velenosi',\n",
       " 'Le Carré',\n",
       " 'Fujishin',\n",
       " 'Georg Breuer',\n",
       " 'Rijckaert',\n",
       " 'Château Siaurac',\n",
       " 'Wise',\n",
       " 'Les Bourgeois',\n",
       " 'Agrapart & Fils',\n",
       " 'Giuseppe Rinaldi',\n",
       " 'Finca Constancia',\n",
       " 'Les Vignobles Foncalieu',\n",
       " 'Le Manzane',\n",
       " 'Lundeen',\n",
       " 'Rosemont',\n",
       " 'Discoveries',\n",
       " 'Zisola',\n",
       " 'Andrea Oberto',\n",
       " 'Clos Teddi',\n",
       " 'Feather',\n",
       " 'Gianni Brunelli',\n",
       " 'Cantina Valle Isarco',\n",
       " 'Muratie',\n",
       " 'Coastal Ridge',\n",
       " 'Arauco',\n",
       " 'Chatom Vineyards',\n",
       " 'Nicosia',\n",
       " 'Arduini',\n",
       " 'Brunelli Martoccia',\n",
       " 'Lazzeretti',\n",
       " 'Windsor Sonoma',\n",
       " 'Della',\n",
       " 'Aiken',\n",
       " 'Louis Sipp',\n",
       " 'Monmousseau',\n",
       " 'Vinos de Arganza',\n",
       " 'San Elias',\n",
       " 'Castello Vicchiomaggio',\n",
       " 'Leaping Lizard',\n",
       " 'The White Knight',\n",
       " 'Les Rocailles',\n",
       " 'Far Niente',\n",
       " 'Bott Frères',\n",
       " 'Finca Albret',\n",
       " 'Château de Sours',\n",
       " 'Alexander',\n",
       " 'C. da Silva',\n",
       " 'Antica Corte',\n",
       " 'Domaine A. Cailbourdin',\n",
       " 'Ferreira',\n",
       " 'Rainer Wess',\n",
       " 'Bressia',\n",
       " 'Sauska',\n",
       " 'Del Carlo Winery',\n",
       " 'Cave des Grands Crus Blancs',\n",
       " 'Adega Cooperativa Ponte de Lima',\n",
       " 'Belle Ambiance',\n",
       " 'Sepp Moser',\n",
       " 'Château Latour à Pomerol',\n",
       " 'Pazo de Barrantes',\n",
       " 'Joseph Carr',\n",
       " 'Oakville East',\n",
       " 'Baker Lane',\n",
       " 'Fife',\n",
       " 'Leopoldo I di Toscana',\n",
       " 'Clautiere',\n",
       " 'Remo Farina',\n",
       " 'Château Lacombe Noaillac',\n",
       " 'Château Haut Bages Libéral',\n",
       " 'Vollereaux',\n",
       " 'Brogan',\n",
       " 'Perla del Garda',\n",
       " 'Lucien Le Moine',\n",
       " 'Zeal',\n",
       " 'R.L. Buller & Son',\n",
       " 'Mount Baker',\n",
       " 'Enrique Mendoza',\n",
       " 'Château Trotanoy',\n",
       " 'Château des Demoiselles',\n",
       " 'Château Figeac',\n",
       " 'Arndorfer',\n",
       " 'Peloton',\n",
       " 'Collavini',\n",
       " 'Pirouette',\n",
       " 'Ded.Reckoning',\n",
       " 'Gancedo',\n",
       " 'Gen5',\n",
       " 'Hans Igler',\n",
       " 'Caterina',\n",
       " 'Ursa',\n",
       " 'Il Poggiolo E. Cosimi',\n",
       " 'Tenuta di Pietra Porzia',\n",
       " 'Brick & Mortar',\n",
       " 'Two Sisters',\n",
       " 'Haywood',\n",
       " 'Vignerons des Terres Secrètes',\n",
       " 'Dominus',\n",
       " 'Corte Pavone',\n",
       " 'Château La Tour Figeac',\n",
       " 'Cor Cellars',\n",
       " 'Mouchão',\n",
       " 'Fattoria Scopone',\n",
       " 'Cinder',\n",
       " 'Domaine Huët',\n",
       " 'Valdicava',\n",
       " 'Tero Estates',\n",
       " 'Château de Berne',\n",
       " 'Monte De Oro',\n",
       " 'Domaine Philippe Delesvaux',\n",
       " 'Hoyt Family Vineyards',\n",
       " \"Hunter's\",\n",
       " 'Marchesato degli Aleramici',\n",
       " 'Statti',\n",
       " 'Sequum',\n",
       " 'Oakville Ranch',\n",
       " 'Château Batailley',\n",
       " 'Abbadia Ardenga',\n",
       " 'Mission Hill',\n",
       " 'Villa Erbice',\n",
       " 'Bodegas Olarra',\n",
       " \"Domaine d'Arton\",\n",
       " 'Domaine Saint-Rémy',\n",
       " 'Rubinelli Vajol',\n",
       " 'Coquerel Family Wine Estates',\n",
       " 'As Laxas',\n",
       " 'Cantina del Castello',\n",
       " 'Parxet',\n",
       " 'Quinta da Rede',\n",
       " 'Bava',\n",
       " 'Bressan',\n",
       " 'Monterebro',\n",
       " 'Leoness',\n",
       " 'Balduzzi',\n",
       " 'Merotto',\n",
       " 'Beyerskloof',\n",
       " 'Pedro Escudero',\n",
       " 'City Winery Chicago',\n",
       " 'Montinore',\n",
       " 'Montecariano',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_winery = list(winery_counts[winery_counts < 30].index)\n",
    "replace_winery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe582541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in replace_winery:\n",
    "    wine_df.winery = wine_df.winery.replace(i,\"Other\")\n",
    "\n",
    "winery_counts = wine_df.winery.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17666c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                    117763\n",
       "Williams Selyem             585\n",
       "Testarossa                  495\n",
       "DFJ Vinhos                  473\n",
       "Chateau Ste. Michelle       420\n",
       "                          ...  \n",
       "Castello del Poggio          30\n",
       "Fritsch                      30\n",
       "Domaine Chasselay            30\n",
       "Sorelle Winery               30\n",
       "La Folia Winery              30\n",
       "Name: winery, Length: 2451, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e8031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b9c1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = wine_df.drop(columns=['designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "181369af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_adjectives(text):\n",
    "#     tokenized = nltk.word_tokenize(str(text)) \n",
    "#     tagged = nltk.pos_tag(tokenized)\n",
    "#     adjectives = [word for word, pos in tagged if pos.startswith('JJ')]\n",
    "#     return adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e165340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine_df['adjectives'] = wine_df['description'].apply(get_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec56153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['full bodied','earthy','savory','herbaceous','minerally','toasty','oaky',\n",
    "             'spicy','flabby','supple','balanced','sweet','aerated','buttery','fruity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd23d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_words(row):\n",
    "    for word in word_list:\n",
    "        if word in row:\n",
    "            return word\n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f90395ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['adjectives'] = wine_df['description'].apply(check_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "326bfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = wine_df.drop(columns=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd74e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281802</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Cave de Turckheim</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281805</th>\n",
       "      <td>Italy</td>\n",
       "      <td>90</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Sicilia</td>\n",
       "      <td>None</td>\n",
       "      <td>Nero d'Avola</td>\n",
       "      <td>Cusumano</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281808</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Domaine Rieflé-Landmann</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281811</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Domaine Gresser</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>fruity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281813</th>\n",
       "      <td>France</td>\n",
       "      <td>90</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Domaine Schoffit</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  points  price           province region_1 region_2  \\\n",
       "Unnamed: 0                                                               \n",
       "281802      France      90   57.0             Alsace   Alsace     None   \n",
       "281805       Italy      90   40.0  Sicily & Sardinia  Sicilia     None   \n",
       "281808      France      90   28.0             Alsace   Alsace     None   \n",
       "281811      France      90   30.0             Alsace   Alsace     None   \n",
       "281813      France      90   21.0             Alsace   Alsace     None   \n",
       "\n",
       "                   variety                   winery  sentiment adjectives  \n",
       "Unnamed: 0                                                                 \n",
       "281802          Pinot Gris        Cave de Turckheim   0.216667       none  \n",
       "281805        Nero d'Avola                 Cusumano  -0.166667       none  \n",
       "281808          Pinot Gris  Domaine Rieflé-Landmann   0.223958       none  \n",
       "281811      Gewürztraminer          Domaine Gresser   0.087500     fruity  \n",
       "281813      Gewürztraminer         Domaine Schoffit   0.191667       none  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3446e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "int64\n",
      "float64\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "float64\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "for col in wine_df:\n",
    "    print(wine_df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c05fc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8bac756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for col in wine_df:\n",
    "    if wine_df[col].dtype == 'object':\n",
    "        enc_col = wine_df[col]\n",
    "        wine_df = wine_df.drop(columns=col)\n",
    "        enc_col2 = pd.DataFrame(enc.fit_transform(enc_col.values.reshape(-1,1)))\n",
    "        enc_col2.columns = enc.get_feature_names([col])\n",
    "        wine_df = wine_df.merge(enc_col2,left_index=True,right_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "485dda8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>country_Argentina</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Italy</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>country_US</th>\n",
       "      <th>...</th>\n",
       "      <th>adjectives_full bodied</th>\n",
       "      <th>adjectives_herbaceous</th>\n",
       "      <th>adjectives_minerally</th>\n",
       "      <th>adjectives_none</th>\n",
       "      <th>adjectives_oaky</th>\n",
       "      <th>adjectives_savory</th>\n",
       "      <th>adjectives_spicy</th>\n",
       "      <th>adjectives_supple</th>\n",
       "      <th>adjectives_sweet</th>\n",
       "      <th>adjectives_toasty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.224074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.331667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.105195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1637 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   points  price  sentiment  country_Argentina  country_Australia  \\\n",
       "0      96  235.0   0.224074                0.0                0.0   \n",
       "1      96  110.0   0.331667                0.0                0.0   \n",
       "2      96   90.0   0.137500                0.0                0.0   \n",
       "3      96   65.0   0.105195                0.0                0.0   \n",
       "4      95   66.0   0.088889                0.0                0.0   \n",
       "\n",
       "   country_Canada  country_France  country_Italy  country_Spain  country_US  \\\n",
       "0             0.0             0.0            0.0            0.0         1.0   \n",
       "1             0.0             0.0            0.0            1.0         0.0   \n",
       "2             0.0             0.0            0.0            0.0         1.0   \n",
       "3             0.0             0.0            0.0            0.0         1.0   \n",
       "4             0.0             1.0            0.0            0.0         0.0   \n",
       "\n",
       "   ...  adjectives_full bodied  adjectives_herbaceous  adjectives_minerally  \\\n",
       "0  ...                     0.0                    0.0                   0.0   \n",
       "1  ...                     0.0                    0.0                   0.0   \n",
       "2  ...                     0.0                    0.0                   0.0   \n",
       "3  ...                     0.0                    0.0                   0.0   \n",
       "4  ...                     0.0                    0.0                   0.0   \n",
       "\n",
       "   adjectives_none  adjectives_oaky  adjectives_savory  adjectives_spicy  \\\n",
       "0              1.0              0.0                0.0               0.0   \n",
       "1              0.0              0.0                0.0               0.0   \n",
       "2              0.0              0.0                0.0               0.0   \n",
       "3              0.0              0.0                0.0               0.0   \n",
       "4              1.0              0.0                0.0               0.0   \n",
       "\n",
       "   adjectives_supple  adjectives_sweet  adjectives_toasty  \n",
       "0                0.0               0.0                0.0  \n",
       "1                0.0               0.0                1.0  \n",
       "2                0.0               0.0                0.0  \n",
       "3                0.0               0.0                1.0  \n",
       "4                0.0               0.0                0.0  \n",
       "\n",
       "[5 rows x 1637 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeacdb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points\n",
      "price\n",
      "sentiment\n",
      "country_Argentina\n",
      "country_Australia\n",
      "country_Canada\n",
      "country_France\n",
      "country_Italy\n",
      "country_Spain\n",
      "country_US\n",
      "province_Alsace\n",
      "province_Andalucia\n",
      "province_Arizona\n",
      "province_Australia Other\n",
      "province_Beaujolais\n",
      "province_Bordeaux\n",
      "province_British Columbia\n",
      "province_Burgundy\n",
      "province_California\n",
      "province_Canada Other\n",
      "province_Catalonia\n",
      "province_Central Italy\n",
      "province_Central Spain\n",
      "province_Champagne\n",
      "province_Colorado\n",
      "province_Connecticut\n",
      "province_France Other\n",
      "province_Galicia\n",
      "province_Idaho\n",
      "province_Iowa\n",
      "province_Italy Other\n",
      "province_Kentucky\n",
      "province_Languedoc-Roussillon\n",
      "province_Levante\n",
      "province_Loire Valley\n",
      "province_Lombardy\n",
      "province_Massachusetts\n",
      "province_Mendoza Province\n",
      "province_Michigan\n",
      "province_Missouri\n",
      "province_Nevada\n",
      "province_New Jersey\n",
      "province_New Mexico\n",
      "province_New South Wales\n",
      "province_New York\n",
      "province_North Carolina\n",
      "province_Northeastern Italy\n",
      "province_Northern Spain\n",
      "province_Northwestern Italy\n",
      "province_Ohio\n",
      "province_Ontario\n",
      "province_Oregon\n",
      "province_Other\n",
      "province_Pennsylvania\n",
      "province_Piedmont\n",
      "province_Provence\n",
      "province_Rhône Valley\n",
      "province_Sicily & Sardinia\n",
      "province_South Australia\n",
      "province_Southern Italy\n",
      "province_Southwest France\n",
      "province_Spain Other\n",
      "province_Spanish Islands\n",
      "province_Tasmania\n",
      "province_Texas\n",
      "province_Tuscany\n",
      "province_Veneto\n",
      "province_Vermont\n",
      "province_Victoria\n",
      "province_Virginia\n",
      "province_Washington\n",
      "province_Western Australia\n",
      "region_1_Alexander Valley\n",
      "region_1_Alsace\n",
      "region_1_Alto Adige\n",
      "region_1_Amador County\n",
      "region_1_Amarone della Valpolicella Classico\n",
      "region_1_Anderson Valley\n",
      "region_1_Barbaresco\n",
      "region_1_Barolo\n",
      "region_1_Barossa Valley\n",
      "region_1_Bolgheri\n",
      "region_1_Bordeaux\n",
      "region_1_Bordeaux Blanc\n",
      "region_1_Bordeaux Supérieur\n",
      "region_1_Bourgogne\n",
      "region_1_Brunello di Montalcino\n",
      "region_1_Cahors\n",
      "region_1_California\n",
      "region_1_Carneros\n",
      "region_1_Cava\n",
      "region_1_Central Coast\n",
      "region_1_Chablis\n",
      "region_1_Champagne\n",
      "region_1_Chehalem Mountains\n",
      "region_1_Chianti Classico\n",
      "region_1_Colli Orientali del Friuli\n",
      "region_1_Collio\n",
      "region_1_Columbia Valley (WA)\n",
      "region_1_Conegliano Valdobbiadene Prosecco Superiore\n",
      "region_1_Côtes de Provence\n",
      "region_1_Dry Creek Valley\n",
      "region_1_Dundee Hills\n",
      "region_1_Edna Valley\n",
      "region_1_El Dorado\n",
      "region_1_Finger Lakes\n",
      "region_1_Franciacorta\n",
      "region_1_Haut-Médoc\n",
      "region_1_Horse Heaven Hills\n",
      "region_1_Lake County\n",
      "region_1_Livermore Valley\n",
      "region_1_Lodi\n",
      "region_1_Margaux\n",
      "region_1_McLaren Vale\n",
      "region_1_Mendocino\n",
      "region_1_Mendocino County\n",
      "region_1_Mendoza\n",
      "region_1_Monterey\n",
      "region_1_Monterey County\n",
      "region_1_Médoc\n",
      "region_1_Napa Valley\n",
      "region_1_Navarra\n",
      "region_1_North Coast\n",
      "region_1_North Fork of Long Island\n",
      "region_1_Oakville\n",
      "region_1_Oregon\n",
      "region_1_Other\n",
      "region_1_Paso Robles\n",
      "region_1_Pauillac\n",
      "region_1_Pessac-Léognan\n",
      "region_1_Priorat\n",
      "region_1_Red Mountain\n",
      "region_1_Ribera del Duero\n",
      "region_1_Rioja\n",
      "region_1_Rogue Valley\n",
      "region_1_Rosso di Montalcino\n",
      "region_1_Rueda\n",
      "region_1_Russian River Valley\n",
      "region_1_Rutherford\n",
      "region_1_Rías Baixas\n",
      "region_1_Saint-Émilion\n",
      "region_1_Sancerre\n",
      "region_1_Santa Barbara County\n",
      "region_1_Santa Cruz Mountains\n",
      "region_1_Santa Lucia Highlands\n",
      "region_1_Santa Maria Valley\n",
      "region_1_Santa Ynez Valley\n",
      "region_1_Sicilia\n",
      "region_1_Sierra Foothills\n",
      "region_1_Sonoma Coast\n",
      "region_1_Sonoma County\n",
      "region_1_Sonoma Valley\n",
      "region_1_South Australia\n",
      "region_1_South Eastern Australia\n",
      "region_1_Sta. Rita Hills\n",
      "region_1_Toscana\n",
      "region_1_Uco Valley\n",
      "region_1_Vino de la Tierra de Castilla\n",
      "region_1_Virginia\n",
      "region_1_Wahluke Slope\n",
      "region_1_Walla Walla Valley (WA)\n",
      "region_1_Washington\n",
      "region_1_Willamette Valley\n",
      "region_1_Yakima Valley\n",
      "region_2_California Other\n",
      "region_2_Central Coast\n",
      "region_2_Central Valley\n",
      "region_2_Columbia Valley\n",
      "region_2_Finger Lakes\n",
      "region_2_Long Island\n",
      "region_2_Mendocino/Lake Counties\n",
      "region_2_Napa\n",
      "region_2_Napa-Sonoma\n",
      "region_2_New York Other\n",
      "region_2_None\n",
      "region_2_North Coast\n",
      "region_2_Oregon Other\n",
      "region_2_Sierra Foothills\n",
      "region_2_Sonoma\n",
      "region_2_South Coast\n",
      "region_2_Southern Oregon\n",
      "region_2_Washington Other\n",
      "region_2_Willamette Valley\n",
      "variety_Aglianico\n",
      "variety_Airen\n",
      "variety_Albariño\n",
      "variety_Alicante Bouschet\n",
      "variety_Aligoté\n",
      "variety_Alsace white blend\n",
      "variety_Arneis\n",
      "variety_Auxerrois\n",
      "variety_Barbera\n",
      "variety_Black Muscat\n",
      "variety_Blaufränkisch\n",
      "variety_Bobal\n",
      "variety_Bonarda\n",
      "variety_Bordeaux-style Red Blend\n",
      "variety_Bordeaux-style White Blend\n",
      "variety_Bovale\n",
      "variety_Cabernet Blend\n",
      "variety_Cabernet Franc\n",
      "variety_Cabernet Franc-Malbec\n",
      "variety_Cabernet Franc-Merlot\n",
      "variety_Cabernet Merlot\n",
      "variety_Cabernet Sauvignon\n",
      "variety_Cabernet Sauvignon-Cabernet Franc\n",
      "variety_Cabernet Sauvignon-Carmenère\n",
      "variety_Cabernet Sauvignon-Malbec\n",
      "variety_Cabernet Sauvignon-Merlot\n",
      "variety_Cabernet Sauvignon-Sangiovese\n",
      "variety_Cabernet Sauvignon-Shiraz\n",
      "variety_Cabernet Sauvignon-Syrah\n",
      "variety_Cabernet-Shiraz\n",
      "variety_Cabernet-Syrah\n",
      "variety_Cannonau\n",
      "variety_Carignan\n",
      "variety_Carignan-Grenache\n",
      "variety_Carignane\n",
      "variety_Carignano\n",
      "variety_Carineña\n",
      "variety_Cariñena-Garnacha\n",
      "variety_Carmenère\n",
      "variety_Carricante\n",
      "variety_Catarratto\n",
      "variety_Cayuga\n",
      "variety_Cesanese d'Affile\n",
      "variety_Chambourcin\n",
      "variety_Champagne Blend\n",
      "variety_Charbono\n",
      "variety_Chardonnay\n",
      "variety_Chardonnay-Albariño\n",
      "variety_Chardonnay-Sauvignon Blanc\n",
      "variety_Chardonnay-Semillon\n",
      "variety_Chardonnay-Viognier\n",
      "variety_Chasselas\n",
      "variety_Chenin Blanc\n",
      "variety_Chenin Blanc-Chardonnay\n",
      "variety_Ciliegiolo\n",
      "variety_Cinsault\n",
      "variety_Claret\n",
      "variety_Cococciola\n",
      "variety_Colombard\n",
      "variety_Colombard-Sauvignon Blanc\n",
      "variety_Colombard-Ugni Blanc\n",
      "variety_Cortese\n",
      "variety_Corvina, Rondinella, Molinara\n",
      "variety_Counoise\n",
      "variety_Debit\n",
      "variety_Dolcetto\n",
      "variety_Duras\n",
      "variety_Falanghina\n",
      "variety_Fer Servadou\n",
      "variety_Fiano\n",
      "variety_Frappato\n",
      "variety_Friulano\n",
      "variety_Fumé Blanc\n",
      "variety_G-S-M\n",
      "variety_Gaglioppo\n",
      "variety_Gamay\n",
      "variety_Gamay Noir\n",
      "variety_Garganega\n",
      "variety_Garnacha\n",
      "variety_Garnacha Blanca\n",
      "variety_Garnacha Tintorera\n",
      "variety_Garnacha-Cabernet\n",
      "variety_Garnacha-Monastrell\n",
      "variety_Garnacha-Syrah\n",
      "variety_Garnacha-Tempranillo\n",
      "variety_Gewürztraminer\n",
      "variety_Glera\n",
      "variety_Godello\n",
      "variety_Graciano\n",
      "variety_Grecanico\n",
      "variety_Greco\n",
      "variety_Greco Bianco\n",
      "variety_Grenache\n",
      "variety_Grenache Blanc\n",
      "variety_Grenache Blend\n",
      "variety_Grenache-Carignan\n",
      "variety_Grenache-Syrah\n",
      "variety_Grillo\n",
      "variety_Gros Manseng\n",
      "variety_Gros and Petit Manseng\n",
      "variety_Grüner Veltliner\n",
      "variety_Hondarrabi Zuri\n",
      "variety_Insolia\n",
      "variety_Inzolia\n",
      "variety_Jacquère\n",
      "variety_Jaen\n",
      "variety_Kerner\n",
      "variety_Lacrima\n",
      "variety_Lagrein\n",
      "variety_Lambrusco\n",
      "variety_Lambrusco Grasparossa\n",
      "variety_Lambrusco di Sorbara\n",
      "variety_Lemberger\n",
      "variety_Macabeo\n",
      "variety_Malbec\n",
      "variety_Malbec Blend\n",
      "variety_Malbec-Cabernet Sauvignon\n",
      "variety_Malbec-Merlot\n",
      "variety_Malbec-Petit Verdot\n",
      "variety_Malbec-Tannat\n",
      "variety_Malbec-Tempranillo\n",
      "variety_Malvar\n",
      "variety_Malvasia\n",
      "variety_Malvasia Bianca\n",
      "variety_Malvasia Nera\n",
      "variety_Mansois\n",
      "variety_Mantonico\n",
      "variety_Marsanne\n",
      "variety_Maturana\n",
      "variety_Mauzac\n",
      "variety_Melon\n",
      "variety_Mencía\n",
      "variety_Meritage\n",
      "variety_Merlot\n",
      "variety_Merlot-Cabernet\n",
      "variety_Merlot-Cabernet Franc\n",
      "variety_Merlot-Cabernet Sauvignon\n",
      "variety_Merlot-Malbec\n",
      "variety_Mission\n",
      "variety_Monastrell\n",
      "variety_Monastrell-Syrah\n",
      "variety_Mondeuse\n",
      "variety_Monica\n",
      "variety_Montepulciano\n",
      "variety_Moscatel\n",
      "variety_Moscato\n",
      "variety_Moscato Giallo\n",
      "variety_Mourvèdre\n",
      "variety_Muscadel\n",
      "variety_Muscat\n",
      "variety_Muscat Blanc\n",
      "variety_Muscat Canelli\n",
      "variety_Müller-Thurgau\n",
      "variety_Nebbiolo\n",
      "variety_Negrette\n",
      "variety_Negroamaro\n",
      "variety_Nerello Cappuccio\n",
      "variety_Nerello Mascalese\n",
      "variety_Nero d'Avola\n",
      "variety_Nero di Troia\n",
      "variety_Norton\n",
      "variety_Orange Muscat\n",
      "variety_Pallagrello\n",
      "variety_Pallagrello Nero\n",
      "variety_Palomino\n",
      "variety_Passerina\n",
      "variety_Pecorino\n",
      "variety_Pedro Ximénez\n",
      "variety_Perricone\n",
      "variety_Petit Manseng\n",
      "variety_Petit Verdot\n",
      "variety_Petite Sirah\n",
      "variety_Petite Verdot\n",
      "variety_Picolit\n",
      "variety_Picpoul\n",
      "variety_Piedirosso\n",
      "variety_Pinot Auxerrois\n",
      "variety_Pinot Bianco\n",
      "variety_Pinot Blanc\n",
      "variety_Pinot Grigio\n",
      "variety_Pinot Grigio-Sauvignon Blanc\n",
      "variety_Pinot Gris\n",
      "variety_Pinot Meunier\n",
      "variety_Pinot Nero\n",
      "variety_Pinot Noir\n",
      "variety_Pinot Noir-Gamay\n",
      "variety_Pinot Noir-Syrah\n",
      "variety_Pinotage\n",
      "variety_Port\n",
      "variety_Premsal\n",
      "variety_Prieto Picudo\n",
      "variety_Primitivo\n",
      "variety_Prié Blanc\n",
      "variety_Prosecco\n",
      "variety_Provence red blend\n",
      "variety_Raboso\n",
      "variety_Red Blend\n",
      "variety_Rhône-style Red Blend\n",
      "variety_Rhône-style White Blend\n",
      "variety_Ribolla Gialla\n",
      "variety_Riesling\n",
      "variety_Rkatsiteli\n",
      "variety_Romorantin\n",
      "variety_Rosado\n",
      "variety_Rosato\n",
      "variety_Rosé\n",
      "variety_Roussanne\n",
      "variety_Roussanne-Viognier\n",
      "variety_Sagrantino\n",
      "variety_Sangiovese\n",
      "variety_Sangiovese Grosso\n",
      "variety_Sangiovese-Cabernet Sauvignon\n",
      "variety_Sangiovese-Syrah\n",
      "variety_Sauvignon\n",
      "variety_Sauvignon Blanc\n",
      "variety_Sauvignon Blanc-Chardonnay\n",
      "variety_Sauvignon Blanc-Semillon\n",
      "variety_Savagnin\n",
      "variety_Scheurebe\n",
      "variety_Schiava\n",
      "variety_Segalin\n",
      "variety_Semillon-Sauvignon Blanc\n",
      "variety_Sherry\n",
      "variety_Shiraz\n",
      "variety_Shiraz-Cabernet Sauvignon\n",
      "variety_Shiraz-Grenache\n",
      "variety_Shiraz-Tempranillo\n",
      "variety_Shiraz-Viognier\n",
      "variety_Sparkling Blend\n",
      "variety_Sylvaner\n",
      "variety_Syrah\n",
      "variety_Syrah-Cabernet\n",
      "variety_Syrah-Cabernet Sauvignon\n",
      "variety_Syrah-Grenache\n",
      "variety_Syrah-Merlot\n",
      "variety_Syrah-Mourvèdre\n",
      "variety_Syrah-Petite Sirah\n",
      "variety_Syrah-Tempranillo\n",
      "variety_Sémillon\n",
      "variety_Tannat\n",
      "variety_Tannat-Cabernet\n",
      "variety_Tannat-Cabernet Franc\n",
      "variety_Tannat-Merlot\n",
      "variety_Tempranillo\n",
      "variety_Tempranillo Blanco\n",
      "variety_Tempranillo Blend\n",
      "variety_Tempranillo-Cabernet Sauvignon\n",
      "variety_Tempranillo-Garnacha\n",
      "variety_Tempranillo-Shiraz\n",
      "variety_Teroldego\n",
      "variety_Teroldego Rotaliano\n",
      "variety_Tinta Fina\n",
      "variety_Tinta de Toro\n",
      "variety_Tintilia \n",
      "variety_Tinto Fino\n",
      "variety_Tinto del Pais\n",
      "variety_Tocai Friulano\n",
      "variety_Tokay\n",
      "variety_Torbato\n",
      "variety_Torrontés\n",
      "variety_Touriga Nacional\n",
      "variety_Traminer\n",
      "variety_Traminette\n",
      "variety_Trebbiano\n",
      "variety_Trebbiano di Lugana\n",
      "variety_Trepat\n",
      "variety_Turbiana\n",
      "variety_Ugni Blanc\n",
      "variety_Ugni Blanc-Colombard\n",
      "variety_Uva di Troia\n",
      "variety_Veltliner\n",
      "variety_Verdeca\n",
      "variety_Verdejo\n",
      "variety_Verdelho\n",
      "variety_Verdicchio\n",
      "variety_Vermentino\n",
      "variety_Vernaccia\n",
      "variety_Vidadillo\n",
      "variety_Vidal\n",
      "variety_Vidal Blanc\n",
      "variety_Vignoles\n",
      "variety_Viognier\n",
      "variety_Viognier-Chardonnay\n",
      "variety_Viognier-Marsanne\n",
      "variety_Viura\n",
      "variety_White Blend\n",
      "variety_White Riesling\n",
      "variety_Xarel-lo\n",
      "variety_Zibibbo\n",
      "variety_Zinfandel\n",
      "variety_Zweigelt\n",
      "winery_14 Hands\n",
      "winery_3 Horse Ranch Vineyards\n",
      "winery_:Nota Bene\n",
      "winery_Abacela\n",
      "winery_Abadia Retuerta\n",
      "winery_Abbazia di Novacella\n",
      "winery_Acacia\n",
      "winery_Achaval-Ferrer\n",
      "winery_Adelaida\n",
      "winery_Agustí Torelló Mata\n",
      "winery_Airfield Estates\n",
      "winery_Alain Brumont\n",
      "winery_Alain Jaume et Fils\n",
      "winery_Albert Bichot\n",
      "winery_Albet I Noya\n",
      "winery_Albino Rocca\n",
      "winery_Alex Gambal\n",
      "winery_Alexander Valley Vineyards\n",
      "winery_Alfredo Roca\n",
      "winery_Alidis\n",
      "winery_Alma Rosa\n",
      "winery_Alta Alella\n",
      "winery_Alta Maria\n",
      "winery_Alta Vista\n",
      "winery_Altesino\n",
      "winery_Altocedro\n",
      "winery_Amador Foothill Winery\n",
      "winery_Amavi\n",
      "winery_Amici\n",
      "winery_Ampelos\n",
      "winery_Anaba\n",
      "winery_Anam Cara\n",
      "winery_Andeluna\n",
      "winery_Andis\n",
      "winery_Andretti\n",
      "winery_Andrew Murray\n",
      "winery_Andriano\n",
      "winery_André Kientzler\n",
      "winery_Angel Vine\n",
      "winery_Angeline\n",
      "winery_Anthony Nappa\n",
      "winery_Anthony Road\n",
      "winery_Apex\n",
      "winery_Apolloni\n",
      "winery_Arbor Brook\n",
      "winery_Arbor Crest\n",
      "winery_Arcadian\n",
      "winery_Archery Summit\n",
      "winery_Argento\n",
      "winery_Argiano\n",
      "winery_Argiolas\n",
      "winery_Argyle\n",
      "winery_Arista\n",
      "winery_Armanino Family Cellars\n",
      "winery_Armida\n",
      "winery_Arnaldo Caprai\n",
      "winery_Artadi\n",
      "winery_Artesa\n",
      "winery_Ascension Cellars\n",
      "winery_Atwater\n",
      "winery_Aubry\n",
      "winery_Avide\n",
      "winery_Avignonesi\n",
      "winery_B Cellars\n",
      "winery_Babcock\n",
      "winery_Baglio del Cristo di Campobello\n",
      "winery_Baglio di Pianetto\n",
      "winery_Baileyana\n",
      "winery_Ballentine\n",
      "winery_Balletto\n",
      "winery_Banfi\n",
      "winery_Barboursville Vineyards\n",
      "winery_Barnett\n",
      "winery_Baron De Ley\n",
      "winery_Baron Philippe de Rothschild\n",
      "winery_Barone Ricasoli\n",
      "winery_Barrister\n",
      "winery_Barton & Guestier\n",
      "winery_Beaulieu Vineyard\n",
      "winery_Beauregard\n",
      "winery_Bedell\n",
      "winery_Belhurst\n",
      "winery_Bellangelo\n",
      "winery_Benanti\n",
      "winery_Benegas\n",
      "winery_Benessere\n",
      "winery_Beni di Batasiolo\n",
      "winery_Benovia\n",
      "winery_Beresan\n",
      "winery_Bergström\n",
      "winery_Bernard Magrez\n",
      "winery_Bernardus\n",
      "winery_Beronia\n",
      "winery_Bersano\n",
      "winery_Bethel Heights\n",
      "winery_Bianchi\n",
      "winery_Big Basin\n",
      "winery_Billsboro\n",
      "winery_Bisceglia\n",
      "winery_Black Box\n",
      "winery_Black Kite\n",
      "winery_Black Stallion\n",
      "winery_Blackbird Vineyards\n",
      "winery_Bleasdale\n",
      "winery_Bodega Catena Zapata\n",
      "winery_Bodega NQN\n",
      "winery_Bodega Norton\n",
      "winery_Bodega Renacer\n",
      "winery_Bodegas Aragonesas\n",
      "winery_Bodegas Bilbainas\n",
      "winery_Bodegas Dios Baco S.L.\n",
      "winery_Bodegas Fariña\n",
      "winery_Bodegas Luzón\n",
      "winery_Bodegas Muriel\n",
      "winery_Bodegas Navarro López\n",
      "winery_Bodegas Ontañón\n",
      "winery_Bodegas Palacio\n",
      "winery_Bodegas Riojanas\n",
      "winery_Bodegas Valdemar\n",
      "winery_Bodegas y Viñedos Tábula\n",
      "winery_Boeckel\n",
      "winery_Boedecker Cellars\n",
      "winery_Boekenoogen\n",
      "winery_Bogle\n",
      "winery_Bolla\n",
      "winery_Bonacchi\n",
      "winery_Bonny Doon\n",
      "winery_Bonterra\n",
      "winery_Borra\n",
      "winery_Borsao\n",
      "winery_Boscarelli\n",
      "winery_Bota Box\n",
      "winery_Bouchard Père & Fils\n",
      "winery_Bougrier\n",
      "winery_Bouvet-Ladubay\n",
      "winery_Brander\n",
      "winery_Brecon Estate\n",
      "winery_Brian Carter Cellars\n",
      "winery_Bric Cenciurio\n",
      "winery_Bridlewood\n",
      "winery_Broken Earth\n",
      "winery_Brooks\n",
      "winery_Brotte\n",
      "winery_Browne Family Vineyards\n",
      "winery_Bruliam\n",
      "winery_Brutocao\n",
      "winery_Buena Vista\n",
      "winery_Burgess\n",
      "winery_Buttonwood Farm\n",
      "winery_Buty\n",
      "winery_Byington\n",
      "winery_Byron\n",
      "winery_CVNE\n",
      "winery_Ca'Romè\n",
      "winery_Calera\n",
      "winery_Caligiore\n",
      "winery_Caliza\n",
      "winery_Callia\n",
      "winery_Cambria\n",
      "winery_Cameron Hughes\n",
      "winery_Camigliano\n",
      "winery_Canneto\n",
      "winery_Canoe Ridge\n",
      "winery_Cantina Produttori San Michele Appiano\n",
      "winery_Cantina Santadi\n",
      "winery_Cantina Terlano\n",
      "winery_Cantina del Nebbiolo\n",
      "winery_Cantina di Soave\n",
      "winery_Capanna\n",
      "winery_Capezzana\n",
      "winery_Carabella\n",
      "winery_Carlisle\n",
      "winery_Carlos Basso\n",
      "winery_Carol Shelton\n",
      "winery_Carpineto\n",
      "winery_Carr\n",
      "winery_Caruso & Minini\n",
      "winery_Casa de la Ermita\n",
      "winery_Casarena\n",
      "winery_Cascina Ballarin\n",
      "winery_Cascina Bruciata\n",
      "winery_Cascina Chicco\n",
      "winery_Cascina del Monastero\n",
      "winery_Cass\n",
      "winery_Castellani\n",
      "winery_Castellare di Castellina\n",
      "winery_Castelli del Grevepesa\n",
      "winery_Castello Romitorio\n",
      "winery_Castello d'Albola\n",
      "winery_Castello del Terriccio\n",
      "winery_Castello di Ama\n",
      "winery_Castello di Amorosa\n",
      "winery_Castello di Bossi\n",
      "winery_Castello di Meleto\n",
      "winery_Castello di Monsanto\n",
      "winery_Castello di Neive\n",
      "winery_Castle Rock\n",
      "winery_Castoro Cellars\n",
      "winery_Cathedral Ridge\n",
      "winery_Cave Spring\n",
      "winery_Cave de Kientzheim-Kaysersberg\n",
      "winery_Cave de Lugny\n",
      "winery_Cave de Ribeauvillé\n",
      "winery_Cave de Tain\n",
      "winery_Cave de Turckheim\n",
      "winery_Cave du Marmandais\n",
      "winery_Cavit\n",
      "winery_Cecchi\n",
      "winery_Cennatoio\n",
      "winery_Center of Effort\n",
      "winery_Ceralti\n",
      "winery_Ceretto\n",
      "winery_Cesari\n",
      "winery_Ceuso\n",
      "winery_Chacewater\n",
      "winery_Chakana\n",
      "winery_Chamisal Vineyards\n",
      "winery_Chanson Père et Fils\n",
      "winery_Charles Ellner\n",
      "winery_Charles Krug\n",
      "winery_Charles Smith\n",
      "winery_Chateau Lafayette Reneau\n",
      "winery_Chateau St. Jean\n",
      "winery_Chateau Ste. Michelle\n",
      "winery_Chehalem\n",
      "winery_Cheval Quancard\n",
      "winery_Chime\n",
      "winery_Chimney Rock\n",
      "winery_Chronic Cellars\n",
      "winery_Château Bertinerie\n",
      "winery_Château Bélingard\n",
      "winery_Château Cos d'Estournel\n",
      "winery_Château Eugénie\n",
      "winery_Château Haut Selve\n",
      "winery_Château Haut-Brion\n",
      "winery_Château La Mission Haut-Brion\n",
      "winery_Château Lagrézette\n",
      "winery_Château Lamothe-Vincent\n",
      "winery_Château Larrivet Haut-Brion\n",
      "winery_Château Laulerie\n",
      "winery_Château Léoube\n",
      "winery_Château Margaux\n",
      "winery_Château Moncontour\n",
      "winery_Château Peyros\n",
      "winery_Château Roubine\n",
      "winery_Château Saint-Didier-Parnac\n",
      "winery_Château Sainte Marguerite\n",
      "winery_Château Sainte Roseline\n",
      "winery_Château Suduiraut\n",
      "winery_Château Tour des Gendres\n",
      "winery_Château Valandraud\n",
      "winery_Château Vignelaure\n",
      "winery_Château d'Aydie\n",
      "winery_Château d'Esclans\n",
      "winery_Château de Belcier\n",
      "winery_Château de Brigue\n",
      "winery_Château de Cénac\n",
      "winery_Château de Fuissé\n",
      "winery_Château de Gaudou\n",
      "winery_Château de Pizay\n",
      "winery_Château de Santenay\n",
      "winery_Château les Valentines\n",
      "winery_Ciacci Piccolomini d'Aragona\n",
      "winery_Cinnabar\n",
      "winery_Claiborne & Churchill\n",
      "winery_Claudia Springs\n",
      "winery_Clif Family\n",
      "winery_Cline\n",
      "winery_Clos La Chance\n",
      "winery_Clos Pegase\n",
      "winery_Clos Troteligotte\n",
      "winery_Clos du Bois\n",
      "winery_Clos du Val\n",
      "winery_Cloudlift Cellars\n",
      "winery_Codorníu\n",
      "winery_Coeur de Terre\n",
      "winery_Collier Falls\n",
      "winery_Collovray et Terrier\n",
      "winery_Colomé\n",
      "winery_Colter's Creek\n",
      "winery_Colterenzio\n",
      "winery_Columbia Crest\n",
      "winery_Columbia Winery\n",
      "winery_Comartin\n",
      "winery_Commanderie de la Bargemone\n",
      "winery_Concannon\n",
      "winery_Condado de Oriza\n",
      "winery_Conterno Fantino\n",
      "winery_Cooper-Garrod\n",
      "winery_Coppo\n",
      "winery_Coquelicot\n",
      "winery_Cornerstone\n",
      "winery_Cosentino\n",
      "winery_Coto de Hayas\n",
      "winery_Cottanera\n",
      "winery_Courtney Benham\n",
      "winery_Covington\n",
      "winery_Cowhorn\n",
      "winery_Cristom\n",
      "winery_Cru\n",
      "winery_Cruz Alta\n",
      "winery_Cusumano\n",
      "winery_Cuvaison\n",
      "winery_Côte Bonneville\n",
      "winery_D'Arenberg\n",
      "winery_Damiani\n",
      "winery_Daou\n",
      "winery_Darcie Kent Vineyards\n",
      "winery_Darioush\n",
      "winery_David Hill\n",
      "winery_Davis Bynum\n",
      "winery_Davis Family\n",
      "winery_De Bortoli\n",
      "winery_De Loach\n",
      "winery_De Stefani\n",
      "winery_DeLille\n",
      "winery_DeLorimier\n",
      "winery_Deaver\n",
      "winery_Deep Sea\n",
      "winery_Deerfield Ranch\n",
      "winery_Del Rio\n",
      "winery_Demetria\n",
      "winery_Den Hoed\n",
      "winery_Derby\n",
      "winery_Di Giovanna\n",
      "winery_Di Meo\n",
      "winery_Diamond Creek\n",
      "winery_Dierberg\n",
      "winery_Dinastía Vivanco\n",
      "winery_Domaine Barmès-Buecher\n",
      "winery_Domaine Bott-Geyl\n",
      "winery_Domaine Charles Baur\n",
      "winery_Domaine Charles Frey\n",
      "winery_Domaine Chasselay\n",
      "winery_Domaine D'en Ségur\n",
      "winery_Domaine Ehrhart\n",
      "winery_Domaine Faiveley\n",
      "winery_Domaine Fernand Engel\n",
      "winery_Domaine Fouassier\n",
      "winery_Domaine François Schmitt\n",
      "winery_Domaine Gresser\n",
      "winery_Domaine Jacques Prieur\n",
      "winery_Domaine Jean Bousquet\n",
      "winery_Domaine Laporte\n",
      "winery_Domaine Laroche\n",
      "winery_Domaine Marcel Deiss\n",
      "winery_Domaine Ostertag\n",
      "winery_Domaine Pfister\n",
      "winery_Domaine Pouillon\n",
      "winery_Domaine René Bouvier\n",
      "winery_Domaine Rieflé-Landmann\n",
      "winery_Domaine Rotier\n",
      "winery_Domaine Saint-André de Figuière\n",
      "winery_Domaine Sangouard-Guyot\n",
      "winery_Domaine Schoffit\n",
      "winery_Domaine Serene\n",
      "winery_Domaine Vincent Girardin\n",
      "winery_Domaine Vincent Stoeffler\n",
      "winery_Domaine Vrignaud\n",
      "winery_Domaine Weinbach\n",
      "winery_Domaine Zinck\n",
      "winery_Domaine Zind-Humbrecht\n",
      "winery_Domaine de Bellene\n",
      "winery_Domaine de Cause\n",
      "winery_Domaine de Chevalier\n",
      "winery_Domaine de la Mordorée\n",
      "winery_Domaine de la Sanglière\n",
      "winery_Domaine des Baumard\n",
      "winery_Domaine du Tariquet\n",
      "winery_Domaines Ott\n",
      "winery_Domaines Schlumberger\n",
      "winery_Dominio de Eguren\n",
      "winery_Dominio de Tares\n",
      "winery_Donati\n",
      "winery_Donkey & Goat\n",
      "winery_Donnafugata\n",
      "winery_Donum\n",
      "winery_Dopff & Irion\n",
      "winery_Dopff Au Moulin\n",
      "winery_Dourthe\n",
      "winery_Doña Paula\n",
      "winery_Dr. Konstantin Frank\n",
      "winery_Dragonette\n",
      "winery_Dry Creek Vineyard\n",
      "winery_Duca di Salaparuta\n",
      "winery_Duck Pond\n",
      "winery_Duckhorn\n",
      "winery_Dumas Station\n",
      "winery_Dunham\n",
      "winery_Durigutti\n",
      "winery_Dusted Valley\n",
      "winery_Dutcher Crossing\n",
      "winery_Dutton Estate\n",
      "winery_Dutton-Goldfield\n",
      "winery_E. Guigal\n",
      "winery_EOS\n",
      "winery_Easton\n",
      "winery_Eberle\n",
      "winery_Edna Valley Vineyard\n",
      "winery_Efeste\n",
      "winery_Ehret\n",
      "winery_Eight Bells\n",
      "winery_El Coto\n",
      "winery_El Enemigo\n",
      "winery_Elena Walch\n",
      "winery_Elevation Cellars\n",
      "winery_Elk Cove\n",
      "winery_Elvio Cogno\n",
      "winery_Elyse\n",
      "winery_Emile Beyer\n",
      "winery_Emilio Moro\n",
      "winery_Emina\n",
      "winery_En Garde\n",
      "winery_Enate\n",
      "winery_Enrique Foster\n",
      "winery_Epiphany\n",
      "winery_Erath\n",
      "winery_Erste Neue\n",
      "winery_Etude\n",
      "winery_Evening Land\n",
      "winery_FEL\n",
      "winery_Fabre Montmayou\n",
      "winery_Failla\n",
      "winery_Falcone\n",
      "winery_Famille Perrin\n",
      "winery_Farnese\n",
      "winery_Fattori\n",
      "winery_Fattoria La Lecciaia\n",
      "winery_Fattoria dei Barbi\n",
      "winery_Fazio\n",
      "winery_Fenestra\n",
      "winery_Ferrari-Carano\n",
      "winery_Fess Parker\n",
      "winery_Fetzer\n",
      "winery_Feudi del Pisciotto\n",
      "winery_Feudi di San Gregorio\n",
      "winery_Feudi di San Marzano\n",
      "winery_Feudo Arancio\n",
      "winery_Feudo Montoni\n",
      "winery_Feudo Principi di Butera\n",
      "winery_Feudo di Santa Tresa\n",
      "winery_Fidelitas\n",
      "winery_Field Stone\n",
      "winery_Fields Family\n",
      "winery_Finca El Origen\n",
      "winery_Finca Flichman\n",
      "winery_Finca Sophenia\n",
      "winery_Firesteed\n",
      "winery_Firestone\n",
      "winery_Firriato\n",
      "winery_Flora Springs\n",
      "winery_Flowers\n",
      "winery_Flying Goat Cellars\n",
      "winery_Fog Crest\n",
      "winery_Foley\n",
      "winery_Folin Cellars\n",
      "winery_Fontanafredda\n",
      "winery_Foppiano\n",
      "winery_Force Majeure\n",
      "winery_Forefathers\n",
      "winery_Forgeron\n",
      "winery_Fort Ross\n",
      "winery_Four Vines\n",
      "winery_Foursight\n",
      "winery_Fox Creek\n",
      "winery_Fox Run\n",
      "winery_Foxen\n",
      "winery_Francis Coppola\n",
      "winery_Francis Ford Coppola\n",
      "winery_Franciscan\n",
      "winery_Frank Cornelissen\n",
      "winery_Frank Family\n",
      "winery_François Lurton\n",
      "winery_Fratelli Alessandria\n",
      "winery_Freemark Abbey\n",
      "winery_Freixenet\n",
      "winery_Fritz\n",
      "winery_Frog's Leap\n",
      "winery_Frostwatch\n",
      "winery_Fulcrum\n",
      "winery_Fulkerson\n",
      "winery_Gainey\n",
      "winery_Gaja\n",
      "winery_Galante\n",
      "winery_García Figuero\n",
      "winery_Gary Farrell\n",
      "winery_Genium Celler\n",
      "winery_Georges Vigouroux\n",
      "winery_Geyser Peak\n",
      "winery_Ghost Pines\n",
      "winery_Gianni Gagliardo\n",
      "winery_Giant Steps\n",
      "winery_Gifford Hirlinger\n",
      "winery_Gini\n",
      "winery_Giorgio Meletti Cavallari\n",
      "winery_Girard\n",
      "winery_Girasole\n",
      "winery_Girlan\n",
      "winery_Girolamo Russo\n",
      "winery_Glenora\n",
      "winery_Gloria Ferrer\n",
      "winery_Gnarly Head\n",
      "winery_Goldschmidt\n",
      "winery_González Byass\n",
      "winery_Gordon Estate\n",
      "winery_Gramercy\n",
      "winery_Graziano\n",
      "winery_Greenwood Ridge\n",
      "winery_Grgich Hills\n",
      "winery_Griffin Creek\n",
      "winery_Guarachi Family\n",
      "winery_Guardian\n",
      "winery_Guicciardini Strozzi\n",
      "winery_Gundlach Bundschu\n",
      "winery_Gustafson Family\n",
      "winery_Gustave Lorentz\n",
      "winery_Gård\n",
      "winery_H. Blin\n",
      "winery_Hall\n",
      "winery_Halleck\n",
      "winery_Halter Ranch\n",
      "winery_HammerSky\n",
      "winery_HandCraft\n",
      "winery_Hanzell\n",
      "winery_Hawkins Cellars\n",
      "winery_Hawley\n",
      "winery_Hearst Ranch\n",
      "winery_Helfrich\n",
      "winery_Helix by Reininger\n",
      "winery_Henri Bourgeois\n",
      "winery_Henri Schoenheitz\n",
      "winery_Henry Fessy\n",
      "winery_Henschke\n",
      "winery_Heron Hill\n",
      "winery_Herzog\n",
      "winery_Hess Collection\n",
      "winery_Hightower\n",
      "winery_Highway 12\n",
      "winery_Hirsch\n",
      "winery_Horse & Plow\n",
      "winery_Hosmer\n",
      "winery_Howard Park\n",
      "winery_Howell Mountain Vineyards\n",
      "winery_Hudson-Chatham\n",
      "winery_Hugel\n",
      "winery_Hunt Cellars\n",
      "winery_Husch\n",
      "winery_Hyland\n",
      "winery_I Capitani\n",
      "winery_I Giusti e Zanza\n",
      "winery_I Veroni\n",
      "winery_Il Falchetto\n",
      "winery_Indigené\n",
      "winery_Iris Vineyards\n",
      "winery_Ironstone\n",
      "winery_Irony\n",
      "winery_J Vineyards & Winery\n",
      "winery_J. Garcia Carrion\n",
      "winery_J. Lohr\n",
      "winery_Jacob's Creek\n",
      "winery_Jada Vineyard & Winery\n",
      "winery_Jaffurs\n",
      "winery_Jarvis\n",
      "winery_Jason-Stephens\n",
      "winery_Jean Milan\n",
      "winery_Jean-Baptiste Adam\n",
      "winery_Jean-Luc Baldès\n",
      "winery_Jean-Luc Colombo\n",
      "winery_Jean-Luc and Paul Aegerter\n",
      "winery_Jean-Marc Bernhard\n",
      "winery_Jefferson Vineyards\n",
      "winery_Jermann\n",
      "winery_Jim Barry\n",
      "winery_John Duval Wines\n",
      "winery_Joseph Cattin\n",
      "winery_Joseph Drouhin\n",
      "winery_Joseph Faiveley\n",
      "winery_Joseph Fritsch\n",
      "winery_Joseph Jewell\n",
      "winery_Joseph Mellot\n",
      "winery_Joseph Phelps\n",
      "winery_Joseph Swan Vineyards\n",
      "winery_Josmeyer\n",
      "winery_Joullian\n",
      "winery_Justin\n",
      "winery_Juvé y Camps\n",
      "winery_K Vintners\n",
      "winery_Kaiken\n",
      "winery_Kaleidos\n",
      "winery_Keating\n",
      "winery_Keenan\n",
      "winery_Keller\n",
      "winery_Keller Estate\n",
      "winery_Kellerei Kaltern Caldaro\n",
      "winery_Kelley Fox\n",
      "winery_Ken Wright\n",
      "winery_Kendall-Jackson\n",
      "winery_Kenefick Ranch\n",
      "winery_Kenwood\n",
      "winery_Kerloo\n",
      "winery_Kessler-Haak\n",
      "winery_Keuka Lake Vineyards\n",
      "winery_Keuka Spring\n",
      "winery_Kilikanoon\n",
      "winery_King Estate\n",
      "winery_Kiona\n",
      "winery_Kirkland Signature\n",
      "winery_Klinker Brick\n",
      "winery_Koehler\n",
      "winery_Kokomo\n",
      "winery_Korbel\n",
      "winery_Krupp Brothers\n",
      "winery_Krutz\n",
      "winery_Kuentz-Bas\n",
      "winery_Kuleto Estate\n",
      "winery_Kunde\n",
      "winery_Kynsi\n",
      "winery_L'Ecole No. 41\n",
      "winery_La Cave des Vignerons de Pfaffenheim\n",
      "winery_La Crema\n",
      "winery_La Fenêtre\n",
      "winery_La Follette\n",
      "winery_La Posta\n",
      "winery_La Rochelle\n",
      "winery_Labouré-Roi\n",
      "winery_Lachini\n",
      "winery_Laetitia\n",
      "winery_Lafond\n",
      "winery_Lagarde\n",
      "winery_Laird\n",
      "winery_Lakewood\n",
      "winery_Lamadrid\n",
      "winery_Lamoreaux Landing\n",
      "winery_Lancaster\n",
      "winery_Landmark\n",
      "winery_LangeTwins\n",
      "winery_Langtry\n",
      "winery_Las Positas\n",
      "winery_Latium di Morini\n",
      "winery_Laurel Glen\n",
      "winery_Lava Cap\n",
      "winery_Lawer\n",
      "winery_Le Cadeau\n",
      "winery_Le Macchiole\n",
      "winery_Le Vigne\n",
      "winery_Ledson\n",
      "winery_Leeuwin Estate\n",
      "winery_Left Coast Cellars\n",
      "winery_Lemelson\n",
      "winery_Leone de Castris\n",
      "winery_Les Maîtres Vignerons de la Presqu'île de Saint-Tropez\n",
      "winery_Les Vignobles Gueissard\n",
      "winery_Les Vins de Vienne\n",
      "winery_Librandi\n",
      "winery_Lieb\n",
      "winery_Lis Neris\n",
      "winery_Llopart\n",
      "winery_Lone Madrone\n",
      "winery_Longboard\n",
      "winery_Longoria\n",
      "winery_Lorenzi Estate\n",
      "winery_Loring Wine Company\n",
      "winery_Louis Bernard\n",
      "winery_Louis Latour\n",
      "winery_Louis M. Martini\n",
      "winery_Louis Max\n",
      "winery_Lucas & Lewellen\n",
      "winery_Lucien Albrecht\n",
      "winery_Luigi Bosca\n",
      "winery_Lumos\n",
      "winery_Luna Beberide\n",
      "winery_Lynmar\n",
      "winery_M. Chapoutier\n",
      "winery_MacMurray Ranch\n",
      "winery_MacPhail\n",
      "winery_MacRostie\n",
      "winery_Madrigal\n",
      "winery_Mahoney\n",
      "winery_MandraRossa\n",
      "winery_Mannina Cellars\n",
      "winery_Manzoni\n",
      "winery_Marc Kreydenweiss\n",
      "winery_Marchesi Antinori\n",
      "winery_Marchesi de' Frescobaldi\n",
      "winery_Marchesi di Barolo\n",
      "winery_Margerum\n",
      "winery_Marimar Estate\n",
      "winery_Mario Gagliasso\n",
      "winery_Markham\n",
      "winery_Marques de Griñon\n",
      "winery_Marqués de Cáceres\n",
      "winery_Marqués de Gelida\n",
      "winery_Marqués de Murrieta\n",
      "winery_Marqués de la Concordia\n",
      "winery_Marrenon\n",
      "winery_Martin & Weyrich\n",
      "winery_Martin Ranch\n",
      "winery_Martin Ray\n",
      "winery_Maryhill\n",
      "winery_Mas de Cadenet\n",
      "winery_Mastroberardino\n",
      "winery_Matarromera\n",
      "winery_Matchbook\n",
      "winery_Materra Cunat Family Vineyards\n",
      "winery_Mauro Sebaste\n",
      "winery_Mauro Veglio\n",
      "winery_Mazzei\n",
      "winery_Mazzocco\n",
      "winery_McCay Cellars\n",
      "winery_McFadden\n",
      "winery_McIntyre Vineyards\n",
      "winery_Medlock Ames\n",
      "winery_Melini\n",
      "winery_Melipal\n",
      "winery_Melrose\n",
      "winery_Mercer\n",
      "winery_Mercy\n",
      "winery_Merriam\n",
      "winery_Merry Cellars\n",
      "winery_Merry Edwards\n",
      "winery_Merryvale\n",
      "winery_Mezzacorona\n",
      "winery_Michael David\n",
      "winery_Michael Pozzan\n",
      "winery_Michel Torino\n",
      "winery_Michele Satta\n",
      "winery_Midnight\n",
      "winery_Midsummer Cellars\n",
      "winery_Migration\n",
      "winery_Milbrandt\n",
      "winery_Mill Creek\n",
      "winery_Millbrook\n",
      "winery_Minassian-Young\n",
      "winery_Miner\n",
      "winery_Miraflores\n",
      "winery_Miro\n",
      "winery_Mont Marçal\n",
      "winery_Montalbera\n",
      "winery_Monte Tondo\n",
      "winery_Monte Volpe\n",
      "winery_Montecillo\n",
      "winery_Monteviejo\n",
      "winery_Montevina\n",
      "winery_Monticello Vineyards\n",
      "winery_Morgan\n",
      "winery_Mount Pleasant Winery\n",
      "winery_Mounts\n",
      "winery_Muga\n",
      "winery_Mumm Napa\n",
      "winery_Murphy-Goode\n",
      "winery_Murrieta's Well\n",
      "winery_Muscardini\n",
      "winery_Máté\n",
      "winery_Naggiar\n",
      "winery_Nals Margreid\n",
      "winery_Napa Cellars\n",
      "winery_Navarro\n",
      "winery_Negretti\n",
      "winery_Nicholson Ranch\n",
      "winery_Nieto Senetiner\n",
      "winery_Noble Vines\n",
      "winery_Nottingham Cellars\n",
      "winery_Novy\n",
      "winery_Nugan Family Estates\n",
      "winery_Numanthia\n",
      "winery_ONX\n",
      "winery_OS Winery\n",
      "winery_Oak Grove\n",
      "winery_Oak Knoll\n",
      "winery_Obelisco Estate\n",
      "winery_Occasio\n",
      "winery_Ochoa\n",
      "winery_Oddero\n",
      "winery_One Hope\n",
      "winery_Orfila\n",
      "winery_Orlando Abrigo\n",
      "winery_Osborne\n",
      "winery_Oso Libre\n",
      "winery_Other\n",
      "winery_Ott & Murphy\n",
      "winery_Ousterhout\n",
      "winery_Owen Roe\n",
      "winery_Page Cellars\n",
      "winery_Pagos del Rey\n",
      "winery_Palacios Remondo\n",
      "winery_Pali\n",
      "winery_Palladino\n",
      "winery_Palmina\n",
      "winery_Panther Creek\n",
      "winery_Paraduxx\n",
      "winery_Paraiso Vineyards\n",
      "winery_Parducci\n",
      "winery_Parusso\n",
      "winery_Pascual Toso\n",
      "winery_Paso a Paso\n",
      "winery_Patland\n",
      "winery_Patterson\n",
      "winery_Patton Valley\n",
      "winery_Patz & Hall\n",
      "winery_Paul Blanck\n",
      "winery_Paul Jaboulet Aîné\n",
      "winery_Peachy Canyon\n",
      "winery_Pech Merle\n",
      "winery_Pedroncelli\n",
      "winery_Peirano\n",
      "winery_Peju\n",
      "winery_Pelassa\n",
      "winery_Peltier\n",
      "winery_Penfolds\n",
      "winery_Penner-Ash\n",
      "winery_Pepper Bridge\n",
      "winery_Perry Creek\n",
      "winery_Pessagno\n",
      "winery_Peter Franus\n",
      "winery_Peter Lehmann\n",
      "winery_Peter Paul Wines\n",
      "winery_Peter Zemmer\n",
      "winery_Peters Family\n",
      "winery_Phelps Creek\n",
      "winery_Phillips Hill\n",
      "winery_Philo Ridge\n",
      "winery_Pianetta\n",
      "winery_Piattelli\n",
      "winery_Piccini\n",
      "winery_Piera Martellozzo\n",
      "winery_Pierre Gimonnet et Fils\n",
      "winery_Pierre Sparr\n",
      "winery_Pietra Santa\n",
      "winery_Pine Ridge\n",
      "winery_Pinord\n",
      "winery_Pio Cesare\n",
      "winery_Pizzolato\n",
      "winery_Piña\n",
      "winery_Planeta\n",
      "winery_Plantagenet\n",
      "winery_Plungerhead\n",
      "winery_Podere San Cristoforo\n",
      "winery_Poderi Luigi Einaudi\n",
      "winery_Poggio Antico\n",
      "winery_Poggio Nardone\n",
      "winery_Poggio al Tesoro\n",
      "winery_Poliziano\n",
      "winery_Pondera\n",
      "winery_Ponzi\n",
      "winery_Pratesi\n",
      "winery_Presqu'ile\n",
      "winery_Pride Mountain\n",
      "winery_Principi di Spadafora\n",
      "winery_Producteurs Plaimont\n",
      "winery_Produttori del Barbaresco\n",
      "winery_Prospect 772\n",
      "winery_Proulx\n",
      "winery_Provenance Vineyards\n",
      "winery_Príncipe de Viana\n",
      "winery_Pulenta Estate\n",
      "winery_Quady\n",
      "winery_Quady North\n",
      "winery_Quivira\n",
      "winery_Qupé\n",
      "winery_R2\n",
      "winery_Ram's Gate\n",
      "winery_Ramey\n",
      "winery_Ramón Bilbao\n",
      "winery_Rancho Sisquoc\n",
      "winery_Rancho Zabaco\n",
      "winery_Raptor Ridge\n",
      "winery_Ravenswood\n",
      "winery_Ravoire et Fils\n",
      "winery_Raymond\n",
      "winery_Red Car\n",
      "winery_Red Newt Cellars\n",
      "winery_Redhawk\n",
      "winery_Refugio Ranch\n",
      "winery_Renato Ratti\n",
      "winery_Renieri\n",
      "winery_Renwood\n",
      "winery_René Muré\n",
      "winery_Resalte\n",
      "winery_Reustle\n",
      "winery_Rex Hill\n",
      "winery_Ricardo Santos\n",
      "winery_Rideau\n",
      "winery_Ridge\n",
      "winery_Rieflé\n",
      "winery_Rioja Vega\n",
      "winery_River Road\n",
      "winery_Riverbench\n",
      "winery_Rivetti Massimo\n",
      "winery_Rivetto\n",
      "winery_Rizzi\n",
      "winery_Roadhouse Winery\n",
      "winery_Roar\n",
      "winery_Robert Biale\n",
      "winery_Robert Hall\n",
      "winery_Robert Mondavi\n",
      "winery_Robert Renzoni\n",
      "winery_Rocca\n",
      "winery_Rocca delle Macìe\n",
      "winery_Roche\n",
      "winery_Roche de Bellene\n",
      "winery_Rock Wall\n",
      "winery_Roco\n",
      "winery_Rodney Strong\n",
      "winery_Rooster Hill\n",
      "winery_Rosa d'Oro\n",
      "winery_Roth\n",
      "winery_Round Pond\n",
      "winery_Ruca Malen\n",
      "winery_Rusack\n",
      "winery_Russiz Superiore\n",
      "winery_Rutherford Hill\n",
      "winery_Rutini\n",
      "winery_Saddleback\n",
      "winery_Saget la Perrière\n",
      "winery_Saintsbury\n",
      "winery_Salcheto\n",
      "winery_Salentein\n",
      "winery_San Antonio\n",
      "winery_San Fabiano Calcinaia\n",
      "winery_San Simeon\n",
      "winery_Sandro de Bruno\n",
      "winery_Sanford\n",
      "winery_Sanglier Cellars\n",
      "winery_Sanguis\n",
      "winery_Santa Barbara Winery\n",
      "winery_Santa Julia\n",
      "winery_Santi\n",
      "winery_Sarah's Vineyard\n",
      "winery_Savage Grace\n",
      "winery_Savannah-Chanelle\n",
      "winery_Saviah\n",
      "winery_Sawtooth\n",
      "winery_Sbragia\n",
      "winery_Schramsberg\n",
      "winery_Schug\n",
      "winery_Sculpterra\n",
      "winery_Sea Smoke\n",
      "winery_Segura Viudas\n",
      "winery_Septima\n",
      "winery_Sequoia Grove\n",
      "winery_Sextant\n",
      "winery_Shannon Ridge\n",
      "winery_Shaw\n",
      "winery_Shea\n",
      "winery_Sheldrake Point\n",
      "winery_Shooting Star\n",
      "winery_Siduri\n",
      "winery_Sierra Cantabria\n",
      "winery_Signé Vigneron\n",
      "winery_Silvan Ridge\n",
      "winery_Silver Thread\n",
      "winery_Simi\n",
      "winery_Simonnet-Febvre\n",
      "winery_Sineann\n",
      "winery_Six Sigma Ranch\n",
      "winery_Sleight of Hand\n",
      "winery_Small Vines\n",
      "winery_Smith-Madrone\n",
      "winery_Smoking Loon\n",
      "winery_Sobon Estate\n",
      "winery_Sojourn\n",
      "winery_Sokol Blosser\n",
      "winery_Soléna\n",
      "winery_Sonoma-Cutrer\n",
      "winery_Sordo\n",
      "winery_Sorelle Winery\n",
      "winery_South Coast\n",
      "winery_Souverain\n",
      "winery_Spann Vineyards\n",
      "winery_Sparkling Pointe\n",
      "winery_Sparkman\n",
      "winery_Speri\n",
      "winery_Spindrift Cellars\n",
      "winery_St. Francis\n",
      "winery_St. Pauls\n",
      "winery_St. Supéry\n",
      "winery_Stag's Leap Wine Cellars\n",
      "winery_Standing Stone\n",
      "winery_Steele\n",
      "winery_Stemmari\n",
      "winery_Stemmler\n",
      "winery_Stephen Ross\n",
      "winery_Steven Kent\n",
      "winery_Still Waters\n",
      "winery_Stoller\n",
      "winery_Stolpman\n",
      "winery_StoneCap\n",
      "winery_Suavia\n",
      "winery_Substance\n",
      "winery_Summerland\n",
      "winery_Summers\n",
      "winery_Sur de los Andes\n",
      "winery_Swedish Hill\n",
      "winery_Sweet Cheeks\n",
      "winery_Swiftwater Cellars\n",
      "winery_Syncline\n",
      "winery_Tablas Creek\n",
      "winery_Tahbilk\n",
      "winery_Taittinger\n",
      "winery_Talbott\n",
      "winery_Talisman\n",
      "winery_Talley\n",
      "winery_Taltarni\n",
      "winery_Tamarack Cellars\n",
      "winery_Tamarí\n",
      "winery_Tamber Bey\n",
      "winery_Tantara\n",
      "winery_Tapiz\n",
      "winery_Tarara\n",
      "winery_Tardieu-Laurent\n",
      "winery_Tasca d'Almerita\n",
      "winery_Telaya\n",
      "winery_Telmo Rodríguez\n",
      "winery_Tenuta Argentiera\n",
      "winery_Tenuta La Fuga\n",
      "winery_Tenuta Luisa\n",
      "winery_Tenuta Rapitalà\n",
      "winery_Tenuta Rocca\n",
      "winery_Tenuta Sette Ponti\n",
      "winery_Tenuta Vitanza\n",
      "winery_Tenuta delle Terre Nere\n",
      "winery_Tenuta di Trecciano\n",
      "winery_Tenute Cisa Asinari dei Marchesi di Gresy\n",
      "winery_Tenute Silvio Nardi\n",
      "winery_Tenute Soletta\n",
      "winery_Terras Gauda\n",
      "winery_Terrazas de Los Andes\n",
      "winery_Terre Rouge\n",
      "winery_Terre da Vino\n",
      "winery_Terre del Marchesato\n",
      "winery_Terredora\n",
      "winery_Tertulia\n",
      "winery_Teso La Monja\n",
      "winery_Testarossa\n",
      "winery_The Eyrie Vineyards\n",
      "winery_The Williamsburg Winery\n",
      "winery_Thomas George\n",
      "winery_Three Sticks\n",
      "winery_Thurston Wolfe\n",
      "winery_Tiefenbrunner\n",
      "winery_Tin Barn\n",
      "winery_Tinazzi\n",
      "winery_Tinhorn Creek\n",
      "winery_TintoNegro\n",
      "winery_Tolosa\n",
      "winery_Tomero\n",
      "winery_Tommasi\n",
      "winery_Torbreck\n",
      "winery_Torii Mor\n",
      "winery_Torres\n",
      "winery_Tortoise Creek\n",
      "winery_Tramin\n",
      "winery_Trapiche\n",
      "winery_Trefethen\n",
      "winery_Treleaven\n",
      "winery_Trenel Fils\n",
      "winery_Trimbach\n",
      "winery_Trinchero\n",
      "winery_Trinitas\n",
      "winery_Trione\n",
      "winery_Trisaetum\n",
      "winery_Trivento\n",
      "winery_Troon\n",
      "winery_Trump\n",
      "winery_Turnbull\n",
      "winery_Tussock Jumper\n",
      "winery_Two Mountain\n",
      "winery_Two Vintners\n",
      "winery_Umani Ronchi\n",
      "winery_Umberto Cesari\n",
      "winery_V. Sattui\n",
      "winery_Va Piano\n",
      "winery_Valentin Bianchi\n",
      "winery_Vall Llach\n",
      "winery_Valle dell'Acate\n",
      "winery_Valley View\n",
      "winery_Vallobera\n",
      "winery_Vecchia Cantina di Montepulciano\n",
      "winery_Vega Sindoa\n",
      "winery_Veramar\n",
      "winery_Verum\n",
      "winery_Viberti\n",
      "winery_Vicente Gandia\n",
      "winery_Vidon Vineyard\n",
      "winery_Vie Winery\n",
      "winery_Vietti\n",
      "winery_Vignerons de Bel Air\n",
      "winery_Vignerons de Buxy\n",
      "winery_Villa Calcinaia\n",
      "winery_Villa Matilde\n",
      "winery_Villa Raiano\n",
      "winery_Villa San Juliette\n",
      "winery_Vina Robles\n",
      "winery_Vinum\n",
      "winery_Vinum Cellars\n",
      "winery_Virna Borgogno\n",
      "winery_Vista Hills\n",
      "winery_Vivác Winery\n",
      "winery_Viña Albali\n",
      "winery_Viña Cobos\n",
      "winery_Viña Mayor\n",
      "winery_Viñedos de Paganos\n",
      "winery_Volpaia\n",
      "winery_Volver\n",
      "winery_Von Strasser\n",
      "winery_Wagner\n",
      "winery_Wakefield Estate\n",
      "winery_Walnut City WineWorks\n",
      "winery_Walt\n",
      "winery_Waterbrook\n",
      "winery_Watermill\n",
      "winery_Waters\n",
      "winery_Waxwing\n",
      "winery_Wellington\n",
      "winery_Wente\n",
      "winery_Westerly\n",
      "winery_Willamette Valley Vineyards\n",
      "winery_William Church\n",
      "winery_William Hill Estate\n",
      "winery_Williams Selyem\n",
      "winery_Willm\n",
      "winery_Willow Crest\n",
      "winery_Wilridge\n",
      "winery_Wilson\n",
      "winery_Winderlea\n",
      "winery_Windsor Oaks\n",
      "winery_Winter's Hill\n",
      "winery_Wirra Wirra\n",
      "winery_Wolfberger\n",
      "winery_Woodinville Wine Cellars\n",
      "winery_Woodward Canyon\n",
      "winery_World's End\n",
      "winery_Wrath\n",
      "winery_Wunsch & Mann\n",
      "winery_Wynns Coonawarra Estate\n",
      "winery_Wölffer\n",
      "winery_Xavier Flouret\n",
      "winery_Y Rousseau\n",
      "winery_Yalumba\n",
      "winery_Yorkville Cellars\n",
      "winery_Zaca Mesa\n",
      "winery_Zenato\n",
      "winery_Zepaltas\n",
      "winery_Zolo\n",
      "winery_Zorzal\n",
      "winery_Zuccardi\n",
      "winery_Ànima Negra\n",
      "winery_àMaurice\n",
      "adjectives_balanced\n",
      "adjectives_buttery\n",
      "adjectives_earthy\n",
      "adjectives_flabby\n",
      "adjectives_fruity\n",
      "adjectives_full bodied\n",
      "adjectives_herbaceous\n",
      "adjectives_minerally\n",
      "adjectives_none\n",
      "adjectives_oaky\n",
      "adjectives_savory\n",
      "adjectives_spicy\n",
      "adjectives_supple\n",
      "adjectives_sweet\n",
      "adjectives_toasty\n"
     ]
    }
   ],
   "source": [
    "for col in wine_df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bddadd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_df['points']\n",
    "X = wine_df.drop(columns='points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c2a56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e33d9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bf18f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13bb9095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 09:18:12.288709: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_layers_1 = 750\n",
    "hidden_layers_list = [250]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_layers_1, input_dim=number_input_features, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "nn.add(tf.keras.layers.Dropout(0.5))\n",
    "for i in hidden_layers_list:\n",
    "    nn.add(tf.keras.layers.Dense(units=i, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "    nn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='relu'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e4c293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_weights.h5',save_best_only=True,save_weights_only = True,monitor = 'val_mae',verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4ca9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss = 'mae',optimizer ='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c411dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 750)               1227750   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 750)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               187750    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,415,751\n",
      "Trainable params: 1,415,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6d4ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_mae',patience = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f30f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 261.8367 - mae: 76.2651\n",
      "Epoch 1: val_mae improved from inf to 43.78849, saving model to best_weights.h5\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 250.9417 - mae: 74.9413 - val_loss: 106.9280 - val_mae: 43.7885\n",
      "Epoch 2/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 75.4849 - mae: 20.3276\n",
      "Epoch 2: val_mae improved from 43.78849 to 31.32539, saving model to best_weights.h5\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 75.4849 - mae: 20.3276 - val_loss: 79.9195 - val_mae: 31.3254\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 59.7871 - mae: 15.3407\n",
      "Epoch 3: val_mae did not improve from 31.32539\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 59.5752 - mae: 15.3122 - val_loss: 73.2698 - val_mae: 31.9266\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 52.9685 - mae: 14.2623\n",
      "Epoch 4: val_mae improved from 31.32539 to 24.30031, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 52.7401 - mae: 14.2972 - val_loss: 60.1867 - val_mae: 24.3003\n",
      "Epoch 5/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 47.1257 - mae: 13.6014\n",
      "Epoch 5: val_mae did not improve from 24.30031\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 46.6893 - mae: 13.4542 - val_loss: 56.4289 - val_mae: 25.2822\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 41.9971 - mae: 12.5483\n",
      "Epoch 6: val_mae improved from 24.30031 to 21.14927, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 41.9731 - mae: 12.5822 - val_loss: 49.0079 - val_mae: 21.1493\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 38.8688 - mae: 12.5810\n",
      "Epoch 7: val_mae did not improve from 21.14927\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 38.8295 - mae: 12.5608 - val_loss: 51.2914 - val_mae: 26.0507\n",
      "Epoch 8/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 35.7033 - mae: 11.6506\n",
      "Epoch 8: val_mae did not improve from 21.14927\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 35.6090 - mae: 11.5932 - val_loss: 52.6761 - val_mae: 29.5046\n",
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 33.8619 - mae: 11.6575\n",
      "Epoch 9: val_mae improved from 21.14927 to 21.11721, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 33.8229 - mae: 11.6308 - val_loss: 43.3430 - val_mae: 21.1172\n",
      "Epoch 10/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 32.4751 - mae: 11.4106\n",
      "Epoch 10: val_mae improved from 21.11721 to 16.33792, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 32.4720 - mae: 11.4717 - val_loss: 36.9501 - val_mae: 16.3379\n",
      "Epoch 11/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 30.9329 - mae: 10.7784\n",
      "Epoch 11: val_mae improved from 16.33792 to 14.97982, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 30.8837 - mae: 10.7618 - val_loss: 34.7804 - val_mae: 14.9798\n",
      "Epoch 12/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 30.0679 - mae: 10.4653\n",
      "Epoch 12: val_mae did not improve from 14.97982\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 30.0818 - mae: 10.4704 - val_loss: 42.6871 - val_mae: 23.0039\n",
      "Epoch 13/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 29.0342 - mae: 9.7517\n",
      "Epoch 13: val_mae improved from 14.97982 to 14.71790, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 29.1186 - mae: 9.8468 - val_loss: 33.7550 - val_mae: 14.7179\n",
      "Epoch 14/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 28.6364 - mae: 9.6967\n",
      "Epoch 14: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 28.5785 - mae: 9.6398 - val_loss: 45.2712 - val_mae: 26.4286\n",
      "Epoch 15/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 28.6623 - mae: 9.5910\n",
      "Epoch 15: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 28.6244 - mae: 9.5573 - val_loss: 37.3678 - val_mae: 18.4734\n",
      "Epoch 16/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 28.1210 - mae: 9.4470\n",
      "Epoch 16: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 28.0884 - mae: 9.4213 - val_loss: 41.1062 - val_mae: 22.4489\n",
      "Epoch 17/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 28.2714 - mae: 9.4072\n",
      "Epoch 17: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 28.2714 - mae: 9.4072 - val_loss: 35.4249 - val_mae: 16.4004\n",
      "Epoch 18/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 28.1626 - mae: 9.0284\n",
      "Epoch 18: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 28.2131 - mae: 9.0582 - val_loss: 41.3120 - val_mae: 21.8015\n",
      "Epoch 18: early stopping\n",
      "loaded Weights 1\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 29.1036 - mae: 10.0229\n",
      "Epoch 1: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 29.0571 - mae: 10.0056 - val_loss: 59.8730 - val_mae: 41.1055\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 28.4732 - mae: 10.1193\n",
      "Epoch 2: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 28.3227 - mae: 9.9394 - val_loss: 40.2285 - val_mae: 21.4679\n",
      "Epoch 3/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 28.0173 - mae: 9.4880\n",
      "Epoch 3: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 28.0051 - mae: 9.4974 - val_loss: 39.5879 - val_mae: 21.3652\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 27.7085 - mae: 9.1043\n",
      "Epoch 4: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 27.6892 - mae: 9.0828 - val_loss: 45.4877 - val_mae: 26.8484\n",
      "Epoch 5/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 27.6450 - mae: 9.0782\n",
      "Epoch 5: val_mae did not improve from 14.71790\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 27.5418 - mae: 8.9715 - val_loss: 38.2055 - val_mae: 19.4456\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 27.6718 - mae: 8.9075\n",
      "Epoch 6: val_mae improved from 14.71790 to 11.82752, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 27.6599 - mae: 8.8684 - val_loss: 31.0604 - val_mae: 11.8275\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 27.6416 - mae: 8.9225\n",
      "Epoch 7: val_mae improved from 11.82752 to 7.33981, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 27.6208 - mae: 8.9034 - val_loss: 25.9829 - val_mae: 7.3398\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 27.3670 - mae: 8.7508\n",
      "Epoch 8: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 27.3670 - mae: 8.7508 - val_loss: 35.8954 - val_mae: 16.7883\n",
      "Epoch 9/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 27.6457 - mae: 8.6200\n",
      "Epoch 9: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 27.6457 - mae: 8.6200 - val_loss: 34.5153 - val_mae: 14.9269\n",
      "Epoch 10/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 28.0518 - mae: 8.7580\n",
      "Epoch 10: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 28.0201 - mae: 8.7146 - val_loss: 45.2863 - val_mae: 25.8541\n",
      "Epoch 11/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 27.2861 - mae: 8.1234\n",
      "Epoch 11: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 27.4932 - mae: 8.3408 - val_loss: 53.6004 - val_mae: 34.1500\n",
      "Epoch 12/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 28.8811 - mae: 9.6771 \n",
      "Epoch 12: val_mae did not improve from 7.33981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 9ms/step - loss: 28.6504 - mae: 9.4608 - val_loss: 34.2425 - val_mae: 15.2056\n",
      "Epoch 12: early stopping\n",
      "Random Weights 2\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 26.3398 - mae: 8.0728\n",
      "Epoch 1: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 26.3516 - mae: 8.0970 - val_loss: 38.2286 - val_mae: 20.3722\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 25.4852 - mae: 7.9735\n",
      "Epoch 2: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 25.4044 - mae: 7.9006 - val_loss: 26.9058 - val_mae: 9.4826\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 25.1754 - mae: 8.0424\n",
      "Epoch 3: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 25.0809 - mae: 7.9613 - val_loss: 41.9911 - val_mae: 24.9293\n",
      "Epoch 4/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 24.4149 - mae: 7.9400\n",
      "Epoch 4: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 24.2982 - mae: 7.8415 - val_loss: 48.1294 - val_mae: 31.6149\n",
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 23.7053 - mae: 7.6903\n",
      "Epoch 5: val_mae did not improve from 7.33981\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 23.6909 - mae: 7.6509 - val_loss: 44.1730 - val_mae: 27.7278\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 24.3492 - mae: 8.1262\n",
      "Epoch 6: val_mae improved from 7.33981 to 7.01168, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 24.3171 - mae: 8.0580 - val_loss: 23.4456 - val_mae: 7.0117\n",
      "Epoch 7/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 23.8475 - mae: 7.6575\n",
      "Epoch 7: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 23.8016 - mae: 7.6189 - val_loss: 29.9543 - val_mae: 13.9809\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 22.9015 - mae: 7.5430\n",
      "Epoch 8: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 22.8159 - mae: 7.4600 - val_loss: 22.4997 - val_mae: 7.1305\n",
      "Epoch 9/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 22.7404 - mae: 7.6383\n",
      "Epoch 9: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 22.7404 - mae: 7.6383 - val_loss: 36.5113 - val_mae: 21.2137\n",
      "Epoch 10/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 22.1807 - mae: 7.4090\n",
      "Epoch 10: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 22.1951 - mae: 7.4533 - val_loss: 26.3245 - val_mae: 11.9317\n",
      "Epoch 11/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 22.2743 - mae: 7.7960\n",
      "Epoch 11: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 22.2743 - mae: 7.7960 - val_loss: 28.5340 - val_mae: 13.8476\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 3\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 23.1576 - mae: 7.4740\n",
      "Epoch 1: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 23.0579 - mae: 7.4426 - val_loss: 32.3756 - val_mae: 17.0748\n",
      "Epoch 2/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 21.9723 - mae: 7.2584\n",
      "Epoch 2: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 21.9723 - mae: 7.2584 - val_loss: 35.3026 - val_mae: 20.5486\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 21.8007 - mae: 7.3495\n",
      "Epoch 3: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 21.7480 - mae: 7.3122 - val_loss: 31.1247 - val_mae: 16.9098\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 21.4977 - mae: 7.2290\n",
      "Epoch 4: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 21.4977 - mae: 7.2290 - val_loss: 23.1575 - val_mae: 8.7755\n",
      "Epoch 5/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 21.0582 - mae: 7.1583\n",
      "Epoch 5: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 21.0263 - mae: 7.1039 - val_loss: 21.8254 - val_mae: 7.8073\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 21.3059 - mae: 7.4424\n",
      "Epoch 6: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 21.3059 - mae: 7.4424 - val_loss: 21.9875 - val_mae: 8.2931\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 20.6073 - mae: 7.1188\n",
      "Epoch 7: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 20.5737 - mae: 7.0857 - val_loss: 38.5866 - val_mae: 25.0310\n",
      "Epoch 8/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 20.7766 - mae: 7.5869\n",
      "Epoch 8: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 20.7613 - mae: 7.5370 - val_loss: 38.9791 - val_mae: 25.3867\n",
      "Epoch 9/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 20.0481 - mae: 7.0623\n",
      "Epoch 9: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 20.0281 - mae: 7.0418 - val_loss: 30.4192 - val_mae: 17.3832\n",
      "Epoch 10/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 19.4410 - mae: 6.8805\n",
      "Epoch 10: val_mae did not improve from 7.01168\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.3968 - mae: 6.8629 - val_loss: 22.4424 - val_mae: 10.1526\n",
      "Epoch 10: early stopping\n",
      "Random Weights 4\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 19.2866 - mae: 7.1050\n",
      "Epoch 1: val_mae improved from 7.01168 to 2.95538, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 19.2902 - mae: 7.1059 - val_loss: 15.2316 - val_mae: 2.9554\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 18.9986 - mae: 7.0842\n",
      "Epoch 2: val_mae improved from 2.95538 to 2.06533, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.9920 - mae: 7.0662 - val_loss: 14.3078 - val_mae: 2.0653\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 18.9166 - mae: 6.9179\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.9315 - mae: 6.9332 - val_loss: 30.4205 - val_mae: 18.3802\n",
      "Epoch 4/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 18.5076 - mae: 6.8150\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.4611 - mae: 6.7772 - val_loss: 18.6218 - val_mae: 7.1358\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 18.2630 - mae: 7.1293\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.2588 - mae: 7.1277 - val_loss: 19.5879 - val_mae: 8.5059\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 17.8102 - mae: 6.8954\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.7925 - mae: 6.8648 - val_loss: 16.4785 - val_mae: 5.3909\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 18.0140 - mae: 7.1674\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.0291 - mae: 7.1787 - val_loss: 23.0023 - val_mae: 11.9922\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 5\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 19.5234 - mae: 7.6512\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.5164 - mae: 7.6475 - val_loss: 27.0310 - val_mae: 15.1509\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 18.6341 - mae: 7.0774\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.6663 - mae: 7.1439 - val_loss: 31.5913 - val_mae: 20.2317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 18.1131 - mae: 7.1956\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.1624 - mae: 7.2506 - val_loss: 18.6799 - val_mae: 7.7897\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 18.1003 - mae: 7.3370\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.2418 - mae: 7.4813 - val_loss: 27.0570 - val_mae: 16.3539\n",
      "Epoch 5/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 17.4794 - mae: 7.0456\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.4229 - mae: 7.0018 - val_loss: 18.4146 - val_mae: 8.1227\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 16.7725 - mae: 6.5859\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.7787 - mae: 6.5957 - val_loss: 19.6629 - val_mae: 9.6734\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 16.4522 - mae: 6.6913\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.4549 - mae: 6.6776 - val_loss: 24.0169 - val_mae: 13.9982\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 16.5699 - mae: 6.8652\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.5699 - mae: 6.8652 - val_loss: 24.2453 - val_mae: 14.5756\n",
      "Epoch 8: early stopping\n",
      "Random Weights 6\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 17.0241 - mae: 7.4474\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 17.0476 - mae: 7.4639 - val_loss: 15.4696 - val_mae: 5.7675\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 16.2156 - mae: 6.9615\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 16.1874 - mae: 6.9314 - val_loss: 23.3710 - val_mae: 14.1126\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 15.6112 - mae: 6.7792\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.5749 - mae: 6.7468 - val_loss: 22.5145 - val_mae: 13.9632\n",
      "Epoch 4/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 15.3035 - mae: 6.8883\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.3572 - mae: 6.9156 - val_loss: 30.6539 - val_mae: 21.7889\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 15.1092 - mae: 6.4910\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.1092 - mae: 6.4910 - val_loss: 18.1709 - val_mae: 9.6844\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 14.7417 - mae: 6.5805\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.7478 - mae: 6.5782 - val_loss: 17.8431 - val_mae: 9.5387\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 7\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 18.6951 - mae: 7.0376\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.7205 - mae: 7.0377 - val_loss: 15.5133 - val_mae: 3.6700\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 18.9792 - mae: 7.2070\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.0371 - mae: 7.2770 - val_loss: 21.8367 - val_mae: 10.0125\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 18.6315 - mae: 7.1199\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.6678 - mae: 7.1544 - val_loss: 25.3618 - val_mae: 13.8774\n",
      "Epoch 4/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 17.8142 - mae: 6.6879\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.8352 - mae: 6.7091 - val_loss: 26.4562 - val_mae: 15.3197\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 17.5189 - mae: 6.7963\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.5189 - mae: 6.7963 - val_loss: 18.8807 - val_mae: 8.0615\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 17.3143 - mae: 6.8011\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.3143 - mae: 6.8011 - val_loss: 29.9742 - val_mae: 19.4908\n",
      "Epoch 6: early stopping\n",
      "Random Weights 8\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 17.2130 - mae: 6.9606\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.1182 - mae: 6.8407 - val_loss: 18.4839 - val_mae: 7.9680\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 16.7135 - mae: 6.7199\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.6320 - mae: 6.6659 - val_loss: 24.2187 - val_mae: 14.5099\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 16.1680 - mae: 6.6188\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.1680 - mae: 6.6188 - val_loss: 20.9712 - val_mae: 11.2838\n",
      "Epoch 4/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 16.3633 - mae: 6.6895\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.4709 - mae: 6.8114 - val_loss: 22.9443 - val_mae: 13.4574\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 16.1464 - mae: 6.8354\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.1464 - mae: 6.8354 - val_loss: 18.6799 - val_mae: 9.2085\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 16.4774 - mae: 7.1147\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.5020 - mae: 7.1691 - val_loss: 22.1943 - val_mae: 13.0892\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 9\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 18.8381 - mae: 7.1165\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.8397 - mae: 7.0849 - val_loss: 33.3778 - val_mae: 21.2533\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 18.9770 - mae: 7.1848\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.9045 - mae: 7.1090 - val_loss: 26.7497 - val_mae: 14.9125\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 19.1277 - mae: 7.4328\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.1334 - mae: 7.4451 - val_loss: 23.0613 - val_mae: 11.4452\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 18.7318 - mae: 7.0479\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.7318 - mae: 7.0479 - val_loss: 27.7725 - val_mae: 16.2522\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 18.0926 - mae: 6.8047\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.0926 - mae: 6.8047 - val_loss: 15.2475 - val_mae: 4.0352\n",
      "Epoch 6/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 18.0192 - mae: 7.0720\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.0568 - mae: 7.1181 - val_loss: 16.9773 - val_mae: 6.3538\n",
      "Epoch 7/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 16.9264 - mae: 6.5623\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.9264 - mae: 6.5623 - val_loss: 23.8760 - val_mae: 13.5571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 16.5776 - mae: 6.5933\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.4579 - mae: 6.4550 - val_loss: 18.8706 - val_mae: 8.7020\n",
      "Epoch 9/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 16.4648 - mae: 6.6511\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.4710 - mae: 6.6495 - val_loss: 20.1600 - val_mae: 10.3894\n",
      "Epoch 10/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 16.2217 - mae: 6.6167\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.2364 - mae: 6.6027 - val_loss: 15.3960 - val_mae: 5.6236\n",
      "Epoch 10: early stopping\n",
      "Random Weights 10\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 16.0745 - mae: 6.6868\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.1115 - mae: 6.6989 - val_loss: 13.5541 - val_mae: 3.8576\n",
      "Epoch 2/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 16.3722 - mae: 6.8376\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.2446 - mae: 6.7190 - val_loss: 19.6409 - val_mae: 10.1908\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 15.9721 - mae: 6.5920\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.9537 - mae: 6.5808 - val_loss: 16.7445 - val_mae: 7.4445\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 15.6449 - mae: 6.5893\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.6893 - mae: 6.6000 - val_loss: 15.9509 - val_mae: 6.6431\n",
      "Epoch 5/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 15.5757 - mae: 6.4714\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.5338 - mae: 6.4305 - val_loss: 16.0979 - val_mae: 7.0528\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 15.2836 - mae: 6.4951\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.3179 - mae: 6.5294 - val_loss: 14.3584 - val_mae: 5.6695\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 11\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 19.0491 - mae: 7.0452\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.0417 - mae: 6.9963 - val_loss: 33.7754 - val_mae: 21.4842\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 19.4871 - mae: 7.1697\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.4772 - mae: 7.1738 - val_loss: 26.3403 - val_mae: 14.1647\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 18.7929 - mae: 6.7743\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.8536 - mae: 6.7979 - val_loss: 29.3341 - val_mae: 16.9841\n",
      "Epoch 4/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 19.0819 - mae: 7.0427\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.0099 - mae: 6.9879 - val_loss: 38.3829 - val_mae: 26.4317\n",
      "Epoch 5/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 18.4682 - mae: 7.0159\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.4230 - mae: 6.9690 - val_loss: 26.0297 - val_mae: 14.4803\n",
      "Epoch 6/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 18.6796 - mae: 7.2285\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 18.6601 - mae: 7.2156 - val_loss: 18.2250 - val_mae: 7.0446\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 17.5867 - mae: 6.6875\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.5686 - mae: 6.6666 - val_loss: 21.4348 - val_mae: 10.3478\n",
      "Epoch 8/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 17.3609 - mae: 6.7095\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.3546 - mae: 6.6907 - val_loss: 19.2667 - val_mae: 8.5531\n",
      "Epoch 9/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 17.0644 - mae: 6.7547\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.0517 - mae: 6.7596 - val_loss: 20.8133 - val_mae: 10.6278\n",
      "Epoch 10/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 16.9616 - mae: 6.7834\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.9819 - mae: 6.7912 - val_loss: 24.1299 - val_mae: 13.7716\n",
      "Epoch 11/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 16.8626 - mae: 6.6421\n",
      "Epoch 11: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.8202 - mae: 6.6055 - val_loss: 19.0014 - val_mae: 8.9278\n",
      "Epoch 11: early stopping\n",
      "Random Weights 12\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 16.5763 - mae: 6.9754\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.5796 - mae: 6.9734 - val_loss: 17.7772 - val_mae: 8.0662\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 16.5665 - mae: 6.8050\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.6186 - mae: 6.8635 - val_loss: 23.8791 - val_mae: 14.1644\n",
      "Epoch 3/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 15.9357 - mae: 6.5141\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.0171 - mae: 6.5873 - val_loss: 12.8724 - val_mae: 3.5503\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 16.4127 - mae: 7.1182\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.4102 - mae: 7.1087 - val_loss: 20.9728 - val_mae: 11.5610\n",
      "Epoch 5/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 15.6999 - mae: 6.6341\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.7047 - mae: 6.6407 - val_loss: 24.5383 - val_mae: 15.4762\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 15.7998 - mae: 6.7560\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.7701 - mae: 6.7287 - val_loss: 15.7377 - val_mae: 6.7738\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 14.7951 - mae: 6.2438\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.8034 - mae: 6.2678 - val_loss: 28.5647 - val_mae: 20.3136\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 14.6866 - mae: 6.6025\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.6866 - mae: 6.6025 - val_loss: 11.2660 - val_mae: 2.8547\n",
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 14.7493 - mae: 6.4124\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.7110 - mae: 6.3690 - val_loss: 17.8137 - val_mae: 9.4561\n",
      "Epoch 10/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.3846 - mae: 6.2360\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.3980 - mae: 6.2499 - val_loss: 13.9239 - val_mae: 5.8623\n",
      "Epoch 11/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 14.2729 - mae: 6.4394\n",
      "Epoch 11: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.2729 - mae: 6.4394 - val_loss: 13.9244 - val_mae: 6.1063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 14.7651 - mae: 6.8474\n",
      "Epoch 12: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.7958 - mae: 6.8520 - val_loss: 25.3289 - val_mae: 16.9321\n",
      "Epoch 13/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.7433 - mae: 6.6457\n",
      "Epoch 13: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.7418 - mae: 6.6484 - val_loss: 10.1939 - val_mae: 2.2662\n",
      "Epoch 14/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 13.9354 - mae: 6.3842\n",
      "Epoch 14: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.9640 - mae: 6.4260 - val_loss: 12.9816 - val_mae: 5.7675\n",
      "Epoch 15/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 13.6494 - mae: 6.3059\n",
      "Epoch 15: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.6494 - mae: 6.3059 - val_loss: 15.7660 - val_mae: 8.2413\n",
      "Epoch 16/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 13.8834 - mae: 6.4460\n",
      "Epoch 16: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.8110 - mae: 6.3752 - val_loss: 11.3665 - val_mae: 3.9968\n",
      "Epoch 17/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 13.7772 - mae: 6.5319\n",
      "Epoch 17: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.7930 - mae: 6.5492 - val_loss: 14.5429 - val_mae: 7.4214\n",
      "Epoch 18/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 13.7443 - mae: 6.6212\n",
      "Epoch 18: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.7731 - mae: 6.6451 - val_loss: 11.3934 - val_mae: 4.0538\n",
      "Epoch 18: early stopping\n",
      "loaded Weights 13\n",
      "Epoch 1/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 19.1684 - mae: 6.6486\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.3098 - mae: 6.7345 - val_loss: 27.9563 - val_mae: 14.5398\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 21.6016 - mae: 7.5859\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 21.6007 - mae: 7.5522 - val_loss: 18.8632 - val_mae: 4.4319\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 21.0044 - mae: 7.2417\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 21.0121 - mae: 7.2457 - val_loss: 32.6300 - val_mae: 18.6310\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 20.6095 - mae: 7.2995\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 20.5042 - mae: 7.2296 - val_loss: 22.6675 - val_mae: 9.7237\n",
      "Epoch 5/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 19.6878 - mae: 6.9474\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.7480 - mae: 7.0257 - val_loss: 15.7385 - val_mae: 3.2096\n",
      "Epoch 6/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 19.1881 - mae: 7.0170\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.2650 - mae: 7.0477 - val_loss: 16.9045 - val_mae: 4.3826\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 19.1636 - mae: 7.1486\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.1712 - mae: 7.1594 - val_loss: 23.8048 - val_mae: 11.9873\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 17.8017 - mae: 6.6863\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.8352 - mae: 6.7285 - val_loss: 12.8084 - val_mae: 2.2101\n",
      "Epoch 9/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 17.9842 - mae: 7.3375\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.8906 - mae: 7.2458 - val_loss: 18.9730 - val_mae: 8.3434\n",
      "Epoch 10/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 17.2068 - mae: 6.9097\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.2152 - mae: 6.9222 - val_loss: 17.1754 - val_mae: 6.9445\n",
      "Epoch 11/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 16.8451 - mae: 6.9000\n",
      "Epoch 11: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.7898 - mae: 6.8445 - val_loss: 14.9320 - val_mae: 4.9582\n",
      "Epoch 12/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 16.4158 - mae: 6.8471\n",
      "Epoch 12: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.3961 - mae: 6.7941 - val_loss: 27.0074 - val_mae: 16.8276\n",
      "Epoch 13/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 16.6650 - mae: 6.7770\n",
      "Epoch 13: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.6650 - mae: 6.7770 - val_loss: 16.7775 - val_mae: 6.8641\n",
      "Epoch 13: early stopping\n",
      "Random Weights 14\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 16.3708 - mae: 6.4717\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 16.3601 - mae: 6.4668 - val_loss: 21.9332 - val_mae: 12.3022\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 16.5914 - mae: 7.3787\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.6184 - mae: 7.3998 - val_loss: 16.4791 - val_mae: 7.2733\n",
      "Epoch 3/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 15.6157 - mae: 6.7141\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.5724 - mae: 6.7033 - val_loss: 15.6806 - val_mae: 7.0813\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 14.9824 - mae: 6.4994\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.9863 - mae: 6.5058 - val_loss: 13.8678 - val_mae: 5.5586\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.7263 - mae: 6.6095\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.7122 - mae: 6.5915 - val_loss: 11.8740 - val_mae: 3.7235\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 15.0744 - mae: 6.9524\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.0744 - mae: 6.9524 - val_loss: 18.1080 - val_mae: 9.7893\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 14.4840 - mae: 6.4791\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.4401 - mae: 6.4416 - val_loss: 14.5078 - val_mae: 6.5046\n",
      "Epoch 8/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 14.3947 - mae: 6.5390\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.3641 - mae: 6.5012 - val_loss: 11.0425 - val_mae: 3.1399\n",
      "Epoch 9/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 14.3296 - mae: 6.6779\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.3585 - mae: 6.7079 - val_loss: 15.8629 - val_mae: 8.2592\n",
      "Epoch 10/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 13.5283 - mae: 6.2398\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.6004 - mae: 6.3103 - val_loss: 17.7066 - val_mae: 10.4203\n",
      "Epoch 11/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 13.4831 - mae: 6.5106\n",
      "Epoch 11: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.4947 - mae: 6.5193 - val_loss: 12.0303 - val_mae: 4.9480\n",
      "Epoch 12/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50 [===========================>..] - ETA: 0s - loss: 13.5725 - mae: 6.5317\n",
      "Epoch 12: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.5924 - mae: 6.5505 - val_loss: 11.9245 - val_mae: 4.9119\n",
      "Epoch 13/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 13.4113 - mae: 6.4950\n",
      "Epoch 13: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.4448 - mae: 6.4965 - val_loss: 13.1191 - val_mae: 5.9177\n",
      "Epoch 13: early stopping\n",
      "loaded Weights 15\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 19.4656 - mae: 7.0915\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.6439 - mae: 7.0763 - val_loss: 33.2673 - val_mae: 19.0235\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 21.6979 - mae: 7.1438\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 21.7383 - mae: 7.1317 - val_loss: 38.3134 - val_mae: 22.8286\n",
      "Epoch 3/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 21.7585 - mae: 6.5431\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 21.7072 - mae: 6.5542 - val_loss: 44.1386 - val_mae: 29.4448\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 21.0829 - mae: 6.9476\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 21.0720 - mae: 6.9385 - val_loss: 26.2284 - val_mae: 12.1894\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 20.2336 - mae: 6.7391\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 20.2545 - mae: 6.7718 - val_loss: 31.5669 - val_mae: 18.4507\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 19.5764 - mae: 6.8045\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 19.6066 - mae: 6.8262 - val_loss: 34.3099 - val_mae: 21.3987\n",
      "Epoch 7/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 19.5059 - mae: 6.9063\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 19.5059 - mae: 6.9063 - val_loss: 38.8214 - val_mae: 26.5095\n",
      "Epoch 8/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 18.6004 - mae: 6.9028\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 18.5739 - mae: 6.9002 - val_loss: 22.9597 - val_mae: 11.5482\n",
      "Epoch 9/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 18.0380 - mae: 6.8064\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.9833 - mae: 6.7549 - val_loss: 21.6089 - val_mae: 10.5117\n",
      "Epoch 10/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 17.7263 - mae: 6.8854\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.7390 - mae: 6.8990 - val_loss: 15.0266 - val_mae: 4.2999\n",
      "Epoch 11/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 17.8019 - mae: 7.0963\n",
      "Epoch 11: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.7933 - mae: 7.0706 - val_loss: 24.0563 - val_mae: 13.2871\n",
      "Epoch 12/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 17.2565 - mae: 6.5936\n",
      "Epoch 12: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 17.2565 - mae: 6.5936 - val_loss: 23.3171 - val_mae: 12.5746\n",
      "Epoch 13/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 17.0469 - mae: 6.8092\n",
      "Epoch 13: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 16.9429 - mae: 6.7127 - val_loss: 13.3279 - val_mae: 3.2023\n",
      "Epoch 14/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 17.1331 - mae: 7.1037\n",
      "Epoch 14: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 17.1041 - mae: 7.0787 - val_loss: 21.4851 - val_mae: 11.7568\n",
      "Epoch 15/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 15.9917 - mae: 6.6985\n",
      "Epoch 15: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.0118 - mae: 6.7263 - val_loss: 22.6939 - val_mae: 13.3960\n",
      "Epoch 16/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 15.9449 - mae: 6.6352\n",
      "Epoch 16: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.9069 - mae: 6.5916 - val_loss: 19.4760 - val_mae: 10.1013\n",
      "Epoch 17/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 15.8844 - mae: 6.7113\n",
      "Epoch 17: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.8844 - mae: 6.7113 - val_loss: 24.4252 - val_mae: 15.3101\n",
      "Epoch 18/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 15.4567 - mae: 6.5841\n",
      "Epoch 18: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.4479 - mae: 6.5678 - val_loss: 21.4285 - val_mae: 12.4906\n",
      "Epoch 18: early stopping\n",
      "Random Weights 16\n",
      "Epoch 1/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 15.3880 - mae: 6.6809\n",
      "Epoch 1: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.3917 - mae: 6.6889 - val_loss: 15.7989 - val_mae: 7.2166\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 15.0519 - mae: 6.5092\n",
      "Epoch 2: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.1298 - mae: 6.5563 - val_loss: 14.8783 - val_mae: 6.0347\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 15.3007 - mae: 6.9453\n",
      "Epoch 3: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.2990 - mae: 6.9412 - val_loss: 15.7254 - val_mae: 7.3876\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 15.2248 - mae: 6.8609\n",
      "Epoch 4: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.1156 - mae: 6.7701 - val_loss: 17.9991 - val_mae: 9.9528\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 14.8912 - mae: 6.7795\n",
      "Epoch 5: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.8786 - mae: 6.7561 - val_loss: 19.8400 - val_mae: 11.2283\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 14.8954 - mae: 6.7249\n",
      "Epoch 6: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.8954 - mae: 6.7249 - val_loss: 12.8710 - val_mae: 4.8180\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 14.3623 - mae: 6.3461\n",
      "Epoch 7: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.3741 - mae: 6.3834 - val_loss: 21.0148 - val_mae: 13.2444\n",
      "Epoch 8/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 13.8008 - mae: 6.2920\n",
      "Epoch 8: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.8865 - mae: 6.4025 - val_loss: 21.1735 - val_mae: 13.9158\n",
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 13.7720 - mae: 6.5993\n",
      "Epoch 9: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.7838 - mae: 6.6096 - val_loss: 13.4550 - val_mae: 6.3374\n",
      "Epoch 10/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 13.7733 - mae: 6.6281\n",
      "Epoch 10: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.7856 - mae: 6.6287 - val_loss: 13.6208 - val_mae: 6.5100\n",
      "Epoch 11/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 14.3043 - mae: 6.9340\n",
      "Epoch 11: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.3448 - mae: 6.9515 - val_loss: 11.8734 - val_mae: 4.4428\n",
      "Epoch 12/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/50 [==========================>...] - ETA: 0s - loss: 14.0832 - mae: 6.8580\n",
      "Epoch 12: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.0319 - mae: 6.8284 - val_loss: 9.8410 - val_mae: 2.8698\n",
      "Epoch 13/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 13.0686 - mae: 6.2910\n",
      "Epoch 13: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.0662 - mae: 6.2881 - val_loss: 15.2782 - val_mae: 8.5182\n",
      "Epoch 14/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.6380 - mae: 6.1243\n",
      "Epoch 14: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.6238 - mae: 6.1099 - val_loss: 10.5248 - val_mae: 4.0825\n",
      "Epoch 15/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 12.5574 - mae: 6.3843\n",
      "Epoch 15: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.4758 - mae: 6.2717 - val_loss: 11.2766 - val_mae: 4.8680\n",
      "Epoch 16/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 12.8759 - mae: 6.3576\n",
      "Epoch 16: val_mae did not improve from 2.06533\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.8679 - mae: 6.3337 - val_loss: 9.5141 - val_mae: 2.8959\n",
      "Epoch 17/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 13.1132 - mae: 6.4070\n",
      "Epoch 17: val_mae improved from 2.06533 to 1.88797, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.2243 - mae: 6.5219 - val_loss: 8.4963 - val_mae: 1.8880\n",
      "Epoch 18/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 12.8104 - mae: 6.2968\n",
      "Epoch 18: val_mae improved from 1.88797 to 1.87827, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.8104 - mae: 6.2968 - val_loss: 8.3531 - val_mae: 1.8783\n",
      "Epoch 19/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 12.8632 - mae: 6.4308\n",
      "Epoch 19: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.8632 - mae: 6.4308 - val_loss: 13.0305 - val_mae: 6.7201\n",
      "Epoch 20/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 12.7636 - mae: 6.6303\n",
      "Epoch 20: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.6765 - mae: 6.5411 - val_loss: 11.1303 - val_mae: 5.0288\n",
      "Epoch 21/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.1588 - mae: 6.3117\n",
      "Epoch 21: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.1696 - mae: 6.3198 - val_loss: 9.5431 - val_mae: 3.6147\n",
      "Epoch 22/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 12.8614 - mae: 6.8231\n",
      "Epoch 22: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.8460 - mae: 6.8065 - val_loss: 8.4185 - val_mae: 2.4551\n",
      "Epoch 23/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.9877 - mae: 6.2792\n",
      "Epoch 23: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.0098 - mae: 6.3006 - val_loss: 7.8773 - val_mae: 2.1957\n",
      "Epoch 23: early stopping\n",
      "loaded Weights 17\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 12.8297 - mae: 6.4611\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.7572 - mae: 6.3843 - val_loss: 8.4345 - val_mae: 2.0901\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 12.3793 - mae: 6.1683\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.4750 - mae: 6.2519 - val_loss: 10.4875 - val_mae: 4.1781\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 12.7596 - mae: 6.4880\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.7596 - mae: 6.4880 - val_loss: 11.7014 - val_mae: 5.5488\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 12.5496 - mae: 6.3864\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.5636 - mae: 6.4038 - val_loss: 14.1989 - val_mae: 8.1292\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 12.3188 - mae: 6.3440\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.3188 - mae: 6.3440 - val_loss: 15.6863 - val_mae: 9.7584\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 12.0723 - mae: 6.3163\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.1492 - mae: 6.3492 - val_loss: 13.7294 - val_mae: 7.6141\n",
      "Epoch 6: early stopping\n",
      "Random Weights 18\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 12.2051 - mae: 6.2356\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.2202 - mae: 6.2513 - val_loss: 9.6712 - val_mae: 3.7959\n",
      "Epoch 2/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 12.0342 - mae: 6.3883\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.0337 - mae: 6.4095 - val_loss: 9.3317 - val_mae: 3.8031\n",
      "Epoch 3/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 11.9068 - mae: 6.4136\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 11.8467 - mae: 6.3492 - val_loss: 14.9850 - val_mae: 9.4497\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 11.6611 - mae: 6.3604\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 11.6611 - mae: 6.3604 - val_loss: 8.0003 - val_mae: 2.8001\n",
      "Epoch 5/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.8195 - mae: 6.4865\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.7986 - mae: 6.4623 - val_loss: 12.0689 - val_mae: 6.7641\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.5862 - mae: 6.3038\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.5807 - mae: 6.2926 - val_loss: 15.8685 - val_mae: 10.3640\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.4526 - mae: 6.1242\n",
      "Epoch 7: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.3985 - mae: 6.0941 - val_loss: 7.8160 - val_mae: 2.9624\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.2324 - mae: 6.3177\n",
      "Epoch 8: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.2417 - mae: 6.3235 - val_loss: 9.1775 - val_mae: 4.2735\n",
      "Epoch 9/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.9917 - mae: 6.3520\n",
      "Epoch 9: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.9826 - mae: 6.3461 - val_loss: 7.5582 - val_mae: 3.0930\n",
      "Epoch 9: early stopping\n",
      "loaded Weights 19\n",
      "Epoch 1/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 13.2584 - mae: 6.6143\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.3610 - mae: 6.6647 - val_loss: 19.3968 - val_mae: 12.0229\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.0767 - mae: 6.4526\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.0676 - mae: 6.4439 - val_loss: 18.2516 - val_mae: 10.6587\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.1320 - mae: 6.6075\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.1099 - mae: 6.5812 - val_loss: 14.5843 - val_mae: 6.9943\n",
      "Epoch 4/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 13.8570 - mae: 6.6375\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.8249 - mae: 6.6160 - val_loss: 10.1256 - val_mae: 3.2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 12.9243 - mae: 6.0793\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.9728 - mae: 6.1385 - val_loss: 10.6996 - val_mae: 4.0874\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 12.5202 - mae: 6.1763\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.5202 - mae: 6.1763 - val_loss: 12.6024 - val_mae: 6.4248\n",
      "Epoch 7/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 12.4702 - mae: 6.2542\n",
      "Epoch 7: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.5012 - mae: 6.2603 - val_loss: 10.4194 - val_mae: 4.1577\n",
      "Epoch 8/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 12.6072 - mae: 6.5610\n",
      "Epoch 8: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.5878 - mae: 6.5393 - val_loss: 10.3995 - val_mae: 4.4044\n",
      "Epoch 9/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 11.8816 - mae: 6.1009\n",
      "Epoch 9: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.9103 - mae: 6.1290 - val_loss: 9.6652 - val_mae: 3.9711\n",
      "Epoch 9: early stopping\n",
      "Random Weights 20\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 11.9511 - mae: 6.2646\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 11.9511 - mae: 6.2646 - val_loss: 7.5902 - val_mae: 1.9709\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.6011 - mae: 6.2306\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.5940 - mae: 6.2232 - val_loss: 9.1201 - val_mae: 3.8232\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.3698 - mae: 6.3006\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.3634 - mae: 6.2937 - val_loss: 7.0397 - val_mae: 2.0149\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.2811 - mae: 6.1440\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.3276 - mae: 6.1881 - val_loss: 8.0292 - val_mae: 2.8173\n",
      "Epoch 5/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 11.3751 - mae: 6.3522\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.3656 - mae: 6.3390 - val_loss: 8.2900 - val_mae: 3.3076\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.2737 - mae: 6.3728\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 11.2375 - mae: 6.3482 - val_loss: 8.3312 - val_mae: 3.7382\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 21\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 13.4613 - mae: 6.4390\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 13.4613 - mae: 6.4390 - val_loss: 10.6190 - val_mae: 2.7637\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 14.2910 - mae: 6.2301\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.3767 - mae: 6.2866 - val_loss: 11.0404 - val_mae: 2.7332\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 14.7055 - mae: 6.3222\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.6853 - mae: 6.2982 - val_loss: 18.3490 - val_mae: 9.8557\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 14.7259 - mae: 6.5384\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 14.6638 - mae: 6.5133 - val_loss: 13.4373 - val_mae: 5.7586\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 13.8247 - mae: 6.4533\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.8075 - mae: 6.4385 - val_loss: 17.1739 - val_mae: 9.9063\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 13.7266 - mae: 6.5304\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.7033 - mae: 6.4971 - val_loss: 14.4764 - val_mae: 7.1992\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 13.3809 - mae: 6.2723\n",
      "Epoch 7: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 13.4377 - mae: 6.3345 - val_loss: 10.3800 - val_mae: 3.4569\n",
      "Epoch 7: early stopping\n",
      "Random Weights 22\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 13.3308 - mae: 6.3116\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 13.3308 - mae: 6.3116 - val_loss: 10.0502 - val_mae: 3.4191\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 12.8485 - mae: 6.2115\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.8942 - mae: 6.2614 - val_loss: 17.7512 - val_mae: 11.2524\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 12.5729 - mae: 6.3432\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.5918 - mae: 6.3639 - val_loss: 9.5258 - val_mae: 3.3910\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.3120 - mae: 6.2872\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.3099 - mae: 6.2856 - val_loss: 16.2266 - val_mae: 10.2920\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.0683 - mae: 6.3571\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.0750 - mae: 6.3598 - val_loss: 14.3618 - val_mae: 8.5044\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 12.3200 - mae: 6.3117\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.2353 - mae: 6.2566 - val_loss: 8.2441 - val_mae: 2.6104\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 11.4079 - mae: 6.1008\n",
      "Epoch 7: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 11.3643 - mae: 6.0647 - val_loss: 9.5890 - val_mae: 4.3478\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.5371 - mae: 6.1720\n",
      "Epoch 8: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.5162 - mae: 6.1492 - val_loss: 7.2491 - val_mae: 1.9553\n",
      "Epoch 9/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 11.1577 - mae: 6.0146\n",
      "Epoch 9: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.1118 - mae: 5.9757 - val_loss: 10.4523 - val_mae: 5.4374\n",
      "Epoch 10/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 11.1950 - mae: 6.2935\n",
      "Epoch 10: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 11.1950 - mae: 6.2935 - val_loss: 10.3291 - val_mae: 5.5519\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.0907 - mae: 6.2429\n",
      "Epoch 11: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.0269 - mae: 6.1778 - val_loss: 11.0110 - val_mae: 6.1855\n",
      "Epoch 12/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.0942 - mae: 6.3133\n",
      "Epoch 12: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.0613 - mae: 6.2783 - val_loss: 9.3598 - val_mae: 4.6107\n",
      "Epoch 13/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.8441 - mae: 5.9946\n",
      "Epoch 13: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.8636 - mae: 6.0087 - val_loss: 8.6417 - val_mae: 3.7421\n",
      "Epoch 13: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded Weights 23\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 14.3347 - mae: 6.6106\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.3812 - mae: 6.6279 - val_loss: 16.4844 - val_mae: 7.3089\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 16.0232 - mae: 6.5744\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 16.0042 - mae: 6.5521 - val_loss: 26.2296 - val_mae: 16.6350\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 15.5781 - mae: 6.4057\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.5766 - mae: 6.4136 - val_loss: 19.5150 - val_mae: 10.7007\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 14.8422 - mae: 6.5644\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.8590 - mae: 6.5873 - val_loss: 16.0130 - val_mae: 8.1548\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.4941 - mae: 6.5438\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.4549 - mae: 6.5222 - val_loss: 19.5006 - val_mae: 12.0707\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 13.2347 - mae: 6.1358\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.2156 - mae: 6.1202 - val_loss: 15.3102 - val_mae: 8.5589\n",
      "Epoch 6: early stopping\n",
      "Random Weights 24\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.8480 - mae: 6.3747\n",
      "Epoch 1: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.8702 - mae: 6.3949 - val_loss: 29.5463 - val_mae: 23.0238\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 12.8916 - mae: 6.3881\n",
      "Epoch 2: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 12.8461 - mae: 6.3446 - val_loss: 9.4945 - val_mae: 3.1088\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 12.8510 - mae: 6.4733\n",
      "Epoch 3: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.8915 - mae: 6.5133 - val_loss: 9.9643 - val_mae: 3.6689\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.2455 - mae: 6.2807\n",
      "Epoch 4: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.2514 - mae: 6.2866 - val_loss: 10.6516 - val_mae: 4.8010\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.3758 - mae: 6.4297\n",
      "Epoch 5: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.3702 - mae: 6.4261 - val_loss: 11.4444 - val_mae: 5.6941\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.7293 - mae: 6.1763\n",
      "Epoch 6: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.7348 - mae: 6.1777 - val_loss: 8.5934 - val_mae: 2.9251\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.7682 - mae: 6.2883\n",
      "Epoch 7: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.7986 - mae: 6.2991 - val_loss: 10.4754 - val_mae: 4.6796\n",
      "Epoch 8/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 11.8848 - mae: 6.3684\n",
      "Epoch 8: val_mae did not improve from 1.87827\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.8235 - mae: 6.3514 - val_loss: 8.7479 - val_mae: 3.8733\n",
      "Epoch 9/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.1152 - mae: 6.3224\n",
      "Epoch 9: val_mae improved from 1.87827 to 1.86384, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.0831 - mae: 6.2851 - val_loss: 6.6926 - val_mae: 1.8638\n",
      "Epoch 10/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.8956 - mae: 6.1023\n",
      "Epoch 10: val_mae did not improve from 1.86384\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.9467 - mae: 6.1501 - val_loss: 6.9522 - val_mae: 2.2034\n",
      "Epoch 11/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.5938 - mae: 5.9941\n",
      "Epoch 11: val_mae did not improve from 1.86384\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.5712 - mae: 5.9719 - val_loss: 7.0357 - val_mae: 2.5202\n",
      "Epoch 12/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.4838 - mae: 6.0063\n",
      "Epoch 12: val_mae did not improve from 1.86384\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.5309 - mae: 6.0559 - val_loss: 6.3714 - val_mae: 2.0463\n",
      "Epoch 13/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 11.0163 - mae: 6.3934\n",
      "Epoch 13: val_mae did not improve from 1.86384\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.0114 - mae: 6.3917 - val_loss: 6.7676 - val_mae: 2.2785\n",
      "Epoch 14/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.7866 - mae: 6.2895\n",
      "Epoch 14: val_mae did not improve from 1.86384\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.7827 - mae: 6.2909 - val_loss: 9.1331 - val_mae: 4.9871\n",
      "Epoch 14: early stopping\n",
      "loaded Weights 25\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.9307 - mae: 6.1096\n",
      "Epoch 1: val_mae improved from 1.86384 to 1.65440, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 10.9515 - mae: 6.1324 - val_loss: 6.3142 - val_mae: 1.6544\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.1760 - mae: 6.5016\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.1515 - mae: 6.4796 - val_loss: 7.3458 - val_mae: 2.8196\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.6039 - mae: 6.1560\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.6754 - mae: 6.2318 - val_loss: 6.3519 - val_mae: 2.1474\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.8544 - mae: 6.3990\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.8435 - mae: 6.3841 - val_loss: 6.9015 - val_mae: 2.3289\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.4040 - mae: 6.0515\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.3706 - mae: 6.0137 - val_loss: 7.2116 - val_mae: 2.8363\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.5595 - mae: 6.1879\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.5466 - mae: 6.1767 - val_loss: 10.2303 - val_mae: 6.0296\n",
      "Epoch 6: early stopping\n",
      "Random Weights 26\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.3203 - mae: 6.2441\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 10.3232 - mae: 6.2505 - val_loss: 10.6686 - val_mae: 6.7223\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.0033 - mae: 6.0458\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9656 - mae: 6.0075 - val_loss: 8.5670 - val_mae: 4.7103\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.0001 - mae: 6.1068\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9664 - mae: 6.0716 - val_loss: 12.7859 - val_mae: 8.9993\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.6906 - mae: 5.8514\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7130 - mae: 5.8650 - val_loss: 17.2973 - val_mae: 13.3139\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.5010 - mae: 6.2088\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.4956 - mae: 6.2053 - val_loss: 11.8704 - val_mae: 7.7945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.9801 - mae: 6.2419 \n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9751 - mae: 6.2358 - val_loss: 10.8275 - val_mae: 7.1330\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.6887 - mae: 6.0065\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6783 - mae: 5.9963 - val_loss: 6.0853 - val_mae: 2.4563\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.6052 - mae: 6.0996\n",
      "Epoch 8: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6179 - mae: 6.1153 - val_loss: 12.8314 - val_mae: 9.5495\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.4105 - mae: 6.2695\n",
      "Epoch 9: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4120 - mae: 6.2711 - val_loss: 4.8585 - val_mae: 1.7923\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2535 - mae: 6.1398\n",
      "Epoch 10: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2761 - mae: 6.1593 - val_loss: 10.3271 - val_mae: 7.1557\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.4565 - mae: 6.3567\n",
      "Epoch 11: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4584 - mae: 6.3412 - val_loss: 7.9644 - val_mae: 4.5098\n",
      "Epoch 12/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.3016 - mae: 6.0949\n",
      "Epoch 12: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2915 - mae: 6.0903 - val_loss: 6.6928 - val_mae: 3.8722\n",
      "Epoch 13/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9316 - mae: 6.0650\n",
      "Epoch 13: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9240 - mae: 6.0541 - val_loss: 7.6727 - val_mae: 4.6890\n",
      "Epoch 14/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.0991 - mae: 6.0010\n",
      "Epoch 14: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1087 - mae: 6.0061 - val_loss: 7.3831 - val_mae: 4.3130\n",
      "Epoch 14: early stopping\n",
      "loaded Weights 27\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.0866 - mae: 6.0547\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.0745 - mae: 6.0294 - val_loss: 8.3314 - val_mae: 2.6797\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.2249 - mae: 6.2825\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.2250 - mae: 6.2820 - val_loss: 10.7036 - val_mae: 4.7783\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.9698 - mae: 6.1341\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.9754 - mae: 6.1386 - val_loss: 11.6641 - val_mae: 5.8882\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.8710 - mae: 6.1425\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.8706 - mae: 6.1322 - val_loss: 8.3138 - val_mae: 2.4390\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 12.3180 - mae: 6.5304\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.3068 - mae: 6.5285 - val_loss: 10.2851 - val_mae: 4.9335\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.0117 - mae: 6.1196\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.9608 - mae: 6.0728 - val_loss: 11.7273 - val_mae: 7.1260\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.8885 - mae: 6.2994\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.8637 - mae: 6.2785 - val_loss: 10.0023 - val_mae: 5.7532\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.0188 - mae: 5.9750\n",
      "Epoch 8: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.0069 - mae: 5.9636 - val_loss: 8.0019 - val_mae: 4.0907\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.2778 - mae: 6.2140\n",
      "Epoch 9: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.2665 - mae: 6.1955 - val_loss: 11.8736 - val_mae: 7.5768\n",
      "Epoch 9: early stopping\n",
      "Random Weights 28\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.8843 - mae: 5.8892 \n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9029 - mae: 5.9163 - val_loss: 6.9037 - val_mae: 3.2760\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.7682 - mae: 6.1133\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7703 - mae: 6.1186 - val_loss: 11.5659 - val_mae: 8.0726\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.7294 - mae: 6.0888\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7154 - mae: 6.0756 - val_loss: 7.4368 - val_mae: 3.9859\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.4684 - mae: 6.0984\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4833 - mae: 6.1166 - val_loss: 5.6617 - val_mae: 2.5493\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.3489 - mae: 6.1593\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.3692 - mae: 6.1742 - val_loss: 5.2980 - val_mae: 1.9411\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.5289 - mae: 6.1640\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.5325 - mae: 6.1684 - val_loss: 5.0674 - val_mae: 1.8765\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.2412 - mae: 6.0970\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2537 - mae: 6.1130 - val_loss: 6.3679 - val_mae: 3.4312\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0297 - mae: 6.0793\n",
      "Epoch 8: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0332 - mae: 6.0852 - val_loss: 5.0632 - val_mae: 2.3135\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0069 - mae: 6.1532\n",
      "Epoch 9: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0103 - mae: 6.1478 - val_loss: 7.3304 - val_mae: 4.1841\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2662 - mae: 6.1737\n",
      "Epoch 10: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2731 - mae: 6.1820 - val_loss: 10.8266 - val_mae: 7.9064\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.0682 - mae: 6.1934\n",
      "Epoch 11: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0730 - mae: 6.1984 - val_loss: 8.1467 - val_mae: 5.4012\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 29\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.2765 - mae: 6.5929\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.3063 - mae: 6.5944 - val_loss: 11.0048 - val_mae: 3.9679\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 13.2771 - mae: 6.0566\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.2705 - mae: 6.0467 - val_loss: 14.0603 - val_mae: 6.8895\n",
      "Epoch 3/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50 [===========================>..] - ETA: 0s - loss: 13.1240 - mae: 6.2415\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 13.1075 - mae: 6.2264 - val_loss: 16.0612 - val_mae: 9.3667\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.6933 - mae: 6.2184\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.7012 - mae: 6.2246 - val_loss: 12.2720 - val_mae: 5.8891\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.2405 - mae: 6.3345\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.2598 - mae: 6.3579 - val_loss: 9.3971 - val_mae: 3.7992\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.4104 - mae: 6.1181\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.3733 - mae: 6.0888 - val_loss: 7.2713 - val_mae: 2.3198\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.2721 - mae: 6.4259\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.2761 - mae: 6.4299 - val_loss: 10.0927 - val_mae: 5.3385\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.0887 - mae: 6.2245\n",
      "Epoch 8: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.1063 - mae: 6.2360 - val_loss: 8.9981 - val_mae: 3.9349\n",
      "Epoch 9/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.6873 - mae: 6.1588\n",
      "Epoch 9: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.6769 - mae: 6.1688 - val_loss: 7.6476 - val_mae: 3.7639\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.6235 - mae: 5.9599\n",
      "Epoch 10: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6318 - mae: 5.9687 - val_loss: 5.6201 - val_mae: 2.1086\n",
      "Epoch 11/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.9280 - mae: 6.2300\n",
      "Epoch 11: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9041 - mae: 6.1952 - val_loss: 6.3278 - val_mae: 2.5577\n",
      "Epoch 12/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.0628 - mae: 6.1848\n",
      "Epoch 12: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.0548 - mae: 6.1776 - val_loss: 5.5823 - val_mae: 1.8996\n",
      "Epoch 13/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.8428 - mae: 6.2210\n",
      "Epoch 13: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.8080 - mae: 6.1822 - val_loss: 7.0561 - val_mae: 3.4859\n",
      "Epoch 14/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.6261 - mae: 6.2441\n",
      "Epoch 14: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6394 - mae: 6.2550 - val_loss: 5.7081 - val_mae: 2.2999\n",
      "Epoch 15/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.6463 - mae: 6.2178\n",
      "Epoch 15: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6328 - mae: 6.2064 - val_loss: 8.1067 - val_mae: 4.8986\n",
      "Epoch 16/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2233 - mae: 6.0709\n",
      "Epoch 16: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1947 - mae: 6.0394 - val_loss: 9.2561 - val_mae: 6.0848\n",
      "Epoch 17/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.4708 - mae: 6.1892\n",
      "Epoch 17: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4422 - mae: 6.1570 - val_loss: 6.1126 - val_mae: 2.7237\n",
      "Epoch 17: early stopping\n",
      "Random Weights 30\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9300 - mae: 5.7638\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9462 - mae: 5.7871 - val_loss: 5.2811 - val_mae: 2.4385\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0186 - mae: 6.1521\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0324 - mae: 6.1679 - val_loss: 5.0318 - val_mae: 2.4074\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8268 - mae: 6.1741\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8112 - mae: 6.1467 - val_loss: 8.0087 - val_mae: 5.1685\n",
      "Epoch 4/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.8887 - mae: 6.1035\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8658 - mae: 6.0841 - val_loss: 9.5027 - val_mae: 6.8877\n",
      "Epoch 5/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.0526 - mae: 6.3306\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0641 - mae: 6.3275 - val_loss: 8.9427 - val_mae: 6.0954\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.1519 - mae: 6.1956\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1805 - mae: 6.2249 - val_loss: 6.5904 - val_mae: 3.7695\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8086 - mae: 6.0819\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8046 - mae: 6.0727 - val_loss: 4.7522 - val_mae: 2.0196\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.0588 - mae: 6.1798\n",
      "Epoch 8: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0274 - mae: 6.1551 - val_loss: 8.5938 - val_mae: 5.9265\n",
      "Epoch 9/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.6767 - mae: 5.9625\n",
      "Epoch 9: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6522 - mae: 5.9409 - val_loss: 5.4546 - val_mae: 2.9460\n",
      "Epoch 10/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7624 - mae: 6.0415\n",
      "Epoch 10: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7552 - mae: 6.0133 - val_loss: 7.2364 - val_mae: 4.0561\n",
      "Epoch 11/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.3119 - mae: 6.1075\n",
      "Epoch 11: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2942 - mae: 6.1045 - val_loss: 7.5757 - val_mae: 4.8134\n",
      "Epoch 12/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.7807 - mae: 6.1913\n",
      "Epoch 12: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7545 - mae: 6.1652 - val_loss: 11.6592 - val_mae: 9.1544\n",
      "Epoch 12: early stopping\n",
      "loaded Weights 31\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 12.7452 - mae: 6.2392\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 12.7452 - mae: 6.2392 - val_loss: 10.4050 - val_mae: 2.0605\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 15.3980 - mae: 6.4325\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 15.5203 - mae: 6.4470 - val_loss: 14.5518 - val_mae: 4.7180\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 15.8958 - mae: 6.3006\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 15.9118 - mae: 6.3299 - val_loss: 15.4375 - val_mae: 6.2570\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.7294 - mae: 6.2803\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.7446 - mae: 6.3017 - val_loss: 17.9645 - val_mae: 9.7857\n",
      "Epoch 5/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 13.8539 - mae: 6.3919\n",
      "Epoch 5: val_mae did not improve from 1.65440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 8ms/step - loss: 13.7983 - mae: 6.3730 - val_loss: 15.5605 - val_mae: 8.8725\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 12.3699 - mae: 6.1986\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 12.3006 - mae: 6.1846 - val_loss: 14.6692 - val_mae: 9.0404\n",
      "Epoch 6: early stopping\n",
      "Random Weights 32\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 11.5857 - mae: 6.3647\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 11.5544 - mae: 6.3446 - val_loss: 12.2171 - val_mae: 7.3820\n",
      "Epoch 2/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 10.8794 - mae: 6.2057\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 10.8794 - mae: 6.2057 - val_loss: 8.0983 - val_mae: 3.5476\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 10.5811 - mae: 6.0384\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.5939 - mae: 6.0653 - val_loss: 14.3043 - val_mae: 9.9775\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.3793 - mae: 6.2083\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.3739 - mae: 6.2064 - val_loss: 8.6888 - val_mae: 4.8530\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.8127 - mae: 6.1153\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.8508 - mae: 6.1526 - val_loss: 10.4354 - val_mae: 6.8497\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.9001 - mae: 6.2434\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9369 - mae: 6.2824 - val_loss: 7.3035 - val_mae: 3.9436\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.5250 - mae: 6.0356\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4865 - mae: 5.9968 - val_loss: 11.0737 - val_mae: 7.6600\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 33\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 12.4294 - mae: 6.2028\n",
      "Epoch 1: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.5014 - mae: 6.2392 - val_loss: 10.6483 - val_mae: 2.6693\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 14.6108 - mae: 6.1151\n",
      "Epoch 2: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 14.6192 - mae: 6.0968 - val_loss: 16.2813 - val_mae: 7.2644\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 15.5159 - mae: 6.5907\n",
      "Epoch 3: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 15.5159 - mae: 6.5907 - val_loss: 14.6728 - val_mae: 5.9177\n",
      "Epoch 4/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 14.6568 - mae: 6.5371\n",
      "Epoch 4: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 14.5916 - mae: 6.5339 - val_loss: 11.0650 - val_mae: 4.1840\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 12.1161 - mae: 6.0231\n",
      "Epoch 5: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 12.1481 - mae: 6.0670 - val_loss: 7.5798 - val_mae: 1.9826\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 11.4435 - mae: 6.2384\n",
      "Epoch 6: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 11.4233 - mae: 6.2267 - val_loss: 6.2357 - val_mae: 1.6885\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.6588 - mae: 6.3590\n",
      "Epoch 7: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.6428 - mae: 6.3442 - val_loss: 8.4586 - val_mae: 4.2981\n",
      "Epoch 8/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.3222 - mae: 6.0704\n",
      "Epoch 8: val_mae did not improve from 1.65440\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.3105 - mae: 6.0671 - val_loss: 8.1333 - val_mae: 4.2991\n",
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.9096 - mae: 6.1988\n",
      "Epoch 9: val_mae improved from 1.65440 to 1.64532, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.8964 - mae: 6.1813 - val_loss: 5.3016 - val_mae: 1.6453\n",
      "Epoch 10/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.3976 - mae: 5.9409\n",
      "Epoch 10: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3976 - mae: 5.9409 - val_loss: 9.4903 - val_mae: 6.1702\n",
      "Epoch 11/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.3030 - mae: 6.0345\n",
      "Epoch 11: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 9.3132 - mae: 6.0468 - val_loss: 5.2841 - val_mae: 2.2234\n",
      "Epoch 12/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0544 - mae: 5.9363\n",
      "Epoch 12: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0596 - mae: 5.9401 - val_loss: 5.1487 - val_mae: 2.1392\n",
      "Epoch 13/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.2081 - mae: 6.0841\n",
      "Epoch 13: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2032 - mae: 6.0738 - val_loss: 7.4893 - val_mae: 4.3055\n",
      "Epoch 14/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.3616 - mae: 6.1178\n",
      "Epoch 14: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3345 - mae: 6.0921 - val_loss: 5.7019 - val_mae: 2.5986\n",
      "Epoch 14: early stopping\n",
      "Random Weights 34\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.2884 - mae: 6.1356\n",
      "Epoch 1: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2585 - mae: 6.1014 - val_loss: 9.3815 - val_mae: 6.2935\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.1783 - mae: 6.1762\n",
      "Epoch 2: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1583 - mae: 6.1546 - val_loss: 5.3623 - val_mae: 2.4409\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7195 - mae: 5.8362\n",
      "Epoch 3: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7333 - mae: 5.8500 - val_loss: 10.2568 - val_mae: 7.5145\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9818 - mae: 6.0731\n",
      "Epoch 4: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9641 - mae: 6.0546 - val_loss: 8.9267 - val_mae: 6.1860\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2621 - mae: 6.0640\n",
      "Epoch 5: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2630 - mae: 6.0500 - val_loss: 11.5190 - val_mae: 7.6098\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.6430 - mae: 6.1878\n",
      "Epoch 6: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6110 - mae: 6.1708 - val_loss: 21.3940 - val_mae: 18.4668\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9904 - mae: 5.9828\n",
      "Epoch 7: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0200 - mae: 6.0134 - val_loss: 11.8770 - val_mae: 9.0515\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 35\n",
      "Epoch 1/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 10.0051 - mae: 6.2630\n",
      "Epoch 1: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.9695 - mae: 6.2102 - val_loss: 5.6238 - val_mae: 1.7602\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.7135 - mae: 5.9412\n",
      "Epoch 2: val_mae did not improve from 1.64532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7571 - mae: 5.9915 - val_loss: 6.4614 - val_mae: 2.9532\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.8025 - mae: 6.1895\n",
      "Epoch 3: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.8194 - mae: 6.2073 - val_loss: 5.1007 - val_mae: 1.7017\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.5975 - mae: 6.0222\n",
      "Epoch 4: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6073 - mae: 6.0324 - val_loss: 8.1646 - val_mae: 4.7296\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.2457 - mae: 6.3404\n",
      "Epoch 5: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.2157 - mae: 6.3137 - val_loss: 5.3784 - val_mae: 1.7837\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.3558 - mae: 6.0706\n",
      "Epoch 6: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.3523 - mae: 6.0686 - val_loss: 4.7462 - val_mae: 1.7159\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.1390 - mae: 6.1096\n",
      "Epoch 7: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1418 - mae: 6.1115 - val_loss: 5.1531 - val_mae: 2.2045\n",
      "Epoch 8/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.6509 - mae: 5.8617\n",
      "Epoch 8: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7280 - mae: 5.9370 - val_loss: 6.8562 - val_mae: 4.1836\n",
      "Epoch 8: early stopping\n",
      "Random Weights 36\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8955 - mae: 6.0597\n",
      "Epoch 1: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9139 - mae: 6.0694 - val_loss: 6.0757 - val_mae: 3.1604\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.1260 - mae: 6.1026\n",
      "Epoch 2: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1327 - mae: 6.1149 - val_loss: 4.4415 - val_mae: 1.6840\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7969 - mae: 6.0180\n",
      "Epoch 3: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8024 - mae: 6.0244 - val_loss: 4.4290 - val_mae: 1.8590\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5326 - mae: 5.9111\n",
      "Epoch 4: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5314 - mae: 5.9071 - val_loss: 4.5317 - val_mae: 1.9365\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9665 - mae: 6.2668\n",
      "Epoch 5: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9457 - mae: 6.2416 - val_loss: 5.2026 - val_mae: 2.3827\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0375 - mae: 5.9948\n",
      "Epoch 6: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0426 - mae: 5.9967 - val_loss: 4.6800 - val_mae: 1.6487\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7382 - mae: 5.9476\n",
      "Epoch 7: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7144 - mae: 5.9247 - val_loss: 4.5048 - val_mae: 1.9482\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5351 - mae: 5.9368\n",
      "Epoch 8: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5335 - mae: 5.9370 - val_loss: 4.0908 - val_mae: 1.6959\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.4544 - mae: 6.0933\n",
      "Epoch 9: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4446 - mae: 6.0832 - val_loss: 4.8035 - val_mae: 2.5709\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.6782 - mae: 6.2912\n",
      "Epoch 10: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6859 - mae: 6.2939 - val_loss: 8.7882 - val_mae: 6.2976\n",
      "Epoch 11/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5140 - mae: 5.9854\n",
      "Epoch 11: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4931 - mae: 5.9646 - val_loss: 4.6125 - val_mae: 2.2170\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 37\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 10.3364 - mae: 6.2783\n",
      "Epoch 1: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.3547 - mae: 6.2780 - val_loss: 8.0739 - val_mae: 3.6697\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.2887 - mae: 5.9922\n",
      "Epoch 2: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.3053 - mae: 6.0096 - val_loss: 6.2097 - val_mae: 2.0502\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.6335 - mae: 6.3659\n",
      "Epoch 3: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.6420 - mae: 6.3678 - val_loss: 6.4068 - val_mae: 2.0029\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.1985 - mae: 5.9810\n",
      "Epoch 4: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.2129 - mae: 5.9959 - val_loss: 7.6786 - val_mae: 3.5683\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 10.3262 - mae: 6.2469\n",
      "Epoch 5: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.3133 - mae: 6.2367 - val_loss: 7.0341 - val_mae: 3.2360\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.5989 - mae: 5.8745\n",
      "Epoch 6: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6653 - mae: 5.9225 - val_loss: 5.4998 - val_mae: 1.7001\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.7880 - mae: 6.2067\n",
      "Epoch 7: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7978 - mae: 6.2234 - val_loss: 5.1987 - val_mae: 1.9081\n",
      "Epoch 8/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.2333 - mae: 6.0038\n",
      "Epoch 8: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2105 - mae: 5.9759 - val_loss: 4.9992 - val_mae: 1.8188\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.3975 - mae: 6.0915\n",
      "Epoch 9: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.3747 - mae: 6.0627 - val_loss: 5.1580 - val_mae: 1.6959\n",
      "Epoch 10/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.6459 - mae: 6.2314\n",
      "Epoch 10: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6073 - mae: 6.1956 - val_loss: 5.0307 - val_mae: 1.7630\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.2579 - mae: 6.1072\n",
      "Epoch 11: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2510 - mae: 6.1051 - val_loss: 5.4381 - val_mae: 2.5712\n",
      "Epoch 12/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.1332 - mae: 6.2243\n",
      "Epoch 12: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1368 - mae: 6.2285 - val_loss: 4.8432 - val_mae: 2.1318\n",
      "Epoch 13/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0205 - mae: 6.0281\n",
      "Epoch 13: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0178 - mae: 6.0179 - val_loss: 4.9634 - val_mae: 1.7097\n",
      "Epoch 14/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.0554 - mae: 6.0569\n",
      "Epoch 14: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0700 - mae: 6.0815 - val_loss: 4.5419 - val_mae: 1.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: early stopping\n",
      "Random Weights 38\n",
      "Epoch 1/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.5203 - mae: 5.9504\n",
      "Epoch 1: val_mae did not improve from 1.64532\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5709 - mae: 5.9897 - val_loss: 5.2154 - val_mae: 2.5765\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.6789 - mae: 6.0771\n",
      "Epoch 2: val_mae improved from 1.64532 to 1.63771, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6626 - mae: 6.0617 - val_loss: 4.0836 - val_mae: 1.6377\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.4943 - mae: 5.9403\n",
      "Epoch 3: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5253 - mae: 5.9683 - val_loss: 4.3122 - val_mae: 1.8567\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7043 - mae: 6.0099\n",
      "Epoch 4: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7036 - mae: 6.0076 - val_loss: 5.8495 - val_mae: 3.2475\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.2473 - mae: 5.8054\n",
      "Epoch 5: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.2295 - mae: 5.7884 - val_loss: 4.1783 - val_mae: 1.9069\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.4442 - mae: 5.9775\n",
      "Epoch 6: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4806 - mae: 6.0132 - val_loss: 4.8184 - val_mae: 2.4619\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.5242 - mae: 6.1173\n",
      "Epoch 7: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5650 - mae: 6.1510 - val_loss: 4.0770 - val_mae: 1.6816\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 39\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8270 - mae: 6.2248\n",
      "Epoch 1: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8555 - mae: 6.2449 - val_loss: 4.3983 - val_mae: 1.7497\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0212 - mae: 6.2040\n",
      "Epoch 2: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0437 - mae: 6.2270 - val_loss: 4.2385 - val_mae: 1.6575\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5248 - mae: 5.9446\n",
      "Epoch 3: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4940 - mae: 5.9127 - val_loss: 4.4239 - val_mae: 1.9120\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.8095 - mae: 5.9864\n",
      "Epoch 4: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8231 - mae: 5.9993 - val_loss: 4.5266 - val_mae: 1.8380\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7555 - mae: 6.0604\n",
      "Epoch 5: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7862 - mae: 6.0887 - val_loss: 4.6308 - val_mae: 1.9623\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.6000 - mae: 5.9861\n",
      "Epoch 6: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5783 - mae: 5.9619 - val_loss: 4.3629 - val_mae: 1.7556\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0221 - mae: 5.9758\n",
      "Epoch 7: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0272 - mae: 5.9878 - val_loss: 4.2590 - val_mae: 1.6756\n",
      "Epoch 7: early stopping\n",
      "Random Weights 40\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9427 - mae: 6.1176\n",
      "Epoch 1: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9278 - mae: 6.1008 - val_loss: 4.5547 - val_mae: 1.8469\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.4392 - mae: 5.9678\n",
      "Epoch 2: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5114 - mae: 6.0403 - val_loss: 3.9135 - val_mae: 1.6418\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5598 - mae: 6.1125\n",
      "Epoch 3: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5341 - mae: 6.0898 - val_loss: 3.8699 - val_mae: 1.7001\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.1484 - mae: 5.9309\n",
      "Epoch 4: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1737 - mae: 5.9532 - val_loss: 6.1881 - val_mae: 4.0753\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.3727 - mae: 5.8937\n",
      "Epoch 5: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3829 - mae: 5.8989 - val_loss: 7.5081 - val_mae: 5.0626\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.5287 - mae: 5.9701\n",
      "Epoch 6: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4759 - mae: 5.9188 - val_loss: 4.8640 - val_mae: 2.5033\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.3712 - mae: 5.9564\n",
      "Epoch 7: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3841 - mae: 5.9673 - val_loss: 5.0207 - val_mae: 2.6819\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 41\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8239 - mae: 6.0481\n",
      "Epoch 1: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8316 - mae: 6.0507 - val_loss: 5.0484 - val_mae: 2.3253\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7665 - mae: 6.0201\n",
      "Epoch 2: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7727 - mae: 6.0224 - val_loss: 4.5475 - val_mae: 1.7770\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.7940 - mae: 6.0370\n",
      "Epoch 3: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7573 - mae: 6.0059 - val_loss: 4.2068 - val_mae: 1.7465\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5999 - mae: 5.9855\n",
      "Epoch 4: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6229 - mae: 6.0062 - val_loss: 4.7107 - val_mae: 2.1382\n",
      "Epoch 5/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.7737 - mae: 6.0757\n",
      "Epoch 5: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7752 - mae: 6.0716 - val_loss: 4.5788 - val_mae: 1.9415\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8825 - mae: 6.1364\n",
      "Epoch 6: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8754 - mae: 6.1212 - val_loss: 4.5229 - val_mae: 1.7673\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.8929 - mae: 6.0879\n",
      "Epoch 7: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8834 - mae: 6.0777 - val_loss: 4.6260 - val_mae: 1.9530\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7238 - mae: 6.0301\n",
      "Epoch 8: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7148 - mae: 6.0181 - val_loss: 4.4608 - val_mae: 1.8099\n",
      "Epoch 8: early stopping\n",
      "Random Weights 42\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7211 - mae: 6.1401\n",
      "Epoch 1: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7323 - mae: 6.1489 - val_loss: 4.1409 - val_mae: 1.6815\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.4049 - mae: 5.9862\n",
      "Epoch 2: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4123 - mae: 5.9921 - val_loss: 4.0260 - val_mae: 1.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.4871 - mae: 6.1169\n",
      "Epoch 3: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4513 - mae: 6.0831 - val_loss: 4.4351 - val_mae: 2.3109\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.3990 - mae: 6.0801\n",
      "Epoch 4: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3980 - mae: 6.0758 - val_loss: 3.9921 - val_mae: 1.6492\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.6913 - mae: 6.0836\n",
      "Epoch 5: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6872 - mae: 6.0768 - val_loss: 4.3548 - val_mae: 1.8081\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.2855 - mae: 5.9468\n",
      "Epoch 6: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.2848 - mae: 5.9445 - val_loss: 3.9492 - val_mae: 1.7668\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 7.9631 - mae: 5.7653\n",
      "Epoch 7: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 7.9769 - mae: 5.7758 - val_loss: 3.8652 - val_mae: 1.6831\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.3416 - mae: 6.1100\n",
      "Epoch 8: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3377 - mae: 6.1054 - val_loss: 3.9714 - val_mae: 1.9079\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.4189 - mae: 6.2452\n",
      "Epoch 9: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4033 - mae: 6.2287 - val_loss: 4.0062 - val_mae: 1.9943\n",
      "Epoch 9: early stopping\n",
      "loaded Weights 43\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9530 - mae: 5.9987\n",
      "Epoch 1: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9411 - mae: 5.9805 - val_loss: 4.9171 - val_mae: 1.8081\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.4235 - mae: 6.1455\n",
      "Epoch 2: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.4201 - mae: 6.1409 - val_loss: 5.2060 - val_mae: 2.0444\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.5469 - mae: 6.2845\n",
      "Epoch 3: val_mae did not improve from 1.63771\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.5705 - mae: 6.3081 - val_loss: 4.9381 - val_mae: 1.8690\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.1618 - mae: 6.0260\n",
      "Epoch 4: val_mae improved from 1.63771 to 1.63616, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.1943 - mae: 6.0781 - val_loss: 4.4151 - val_mae: 1.6362\n",
      "Epoch 5/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.0008 - mae: 5.9726\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0164 - mae: 5.9928 - val_loss: 4.6185 - val_mae: 1.8924\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.6115 - mae: 5.9225\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7085 - mae: 6.0096 - val_loss: 5.1269 - val_mae: 2.5206\n",
      "Epoch 7/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.9441 - mae: 6.2835\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8929 - mae: 6.2393 - val_loss: 4.5426 - val_mae: 2.1133\n",
      "Epoch 8/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.2578 - mae: 5.8351\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 8.2514 - mae: 5.8326 - val_loss: 4.2856 - val_mae: 2.0435\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5814 - mae: 6.0991\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5775 - mae: 6.0925 - val_loss: 4.5056 - val_mae: 2.0635\n",
      "Epoch 9: early stopping\n",
      "Random Weights 44\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8842 - mae: 6.1604\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9078 - mae: 6.1756 - val_loss: 4.4959 - val_mae: 1.7420\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7596 - mae: 6.0617\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7598 - mae: 6.0617 - val_loss: 4.1808 - val_mae: 1.6854\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.5654 - mae: 6.1093\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5985 - mae: 6.1520 - val_loss: 5.7813 - val_mae: 3.5582\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.7610 - mae: 6.3340\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 8.6951 - mae: 6.2707 - val_loss: 3.9573 - val_mae: 1.6751\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.4094 - mae: 6.0235\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3954 - mae: 6.0109 - val_loss: 3.7856 - val_mae: 1.6526\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.1810 - mae: 5.9504\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.1647 - mae: 5.9023 - val_loss: 4.1466 - val_mae: 1.6766\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.5475 - mae: 6.0856\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5765 - mae: 6.1145 - val_loss: 3.9314 - val_mae: 1.6790\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.2086 - mae: 6.0101\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2086 - mae: 6.0101 - val_loss: 3.7306 - val_mae: 1.6980\n",
      "Epoch 9/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.2663 - mae: 6.1839\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2460 - mae: 6.1615 - val_loss: 3.9260 - val_mae: 1.9564\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.2438 - mae: 6.1611\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2283 - mae: 6.1437 - val_loss: 3.7824 - val_mae: 1.7715\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 45\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9827 - mae: 6.0939\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 8.9788 - mae: 6.0755 - val_loss: 5.2088 - val_mae: 2.1104\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.3950 - mae: 6.2285\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3458 - mae: 6.1897 - val_loss: 5.9419 - val_mae: 3.0674\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.3447 - mae: 6.1684\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3641 - mae: 6.1697 - val_loss: 5.2311 - val_mae: 1.9941\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.0937 - mae: 6.1373\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0937 - mae: 6.1373 - val_loss: 4.1910 - val_mae: 1.6645\n",
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.5539 - mae: 5.9358\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5739 - mae: 5.9569 - val_loss: 5.0569 - val_mae: 2.5643\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/50 [==========================>...] - ETA: 0s - loss: 8.5301 - mae: 6.0094\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5235 - mae: 6.0072 - val_loss: 3.9739 - val_mae: 1.6455\n",
      "Epoch 7/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.5581 - mae: 6.0050\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5653 - mae: 5.9975 - val_loss: 5.0236 - val_mae: 2.4639\n",
      "Epoch 8/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.8202 - mae: 6.2762\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8076 - mae: 6.2680 - val_loss: 4.2360 - val_mae: 1.8689\n",
      "Epoch 9/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.4824 - mae: 6.0626\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5108 - mae: 6.0948 - val_loss: 4.1049 - val_mae: 1.7933\n",
      "Epoch 10/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.7353 - mae: 6.2163\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5851 - mae: 6.0611 - val_loss: 4.1426 - val_mae: 1.7206\n",
      "Epoch 11/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.4621 - mae: 5.9598\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4787 - mae: 5.9802 - val_loss: 5.6226 - val_mae: 3.3192\n",
      "Epoch 11: early stopping\n",
      "Random Weights 46\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.6890 - mae: 6.2898\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7174 - mae: 6.3148 - val_loss: 4.5012 - val_mae: 2.2089\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.4108 - mae: 6.0173\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4376 - mae: 6.0424 - val_loss: 4.5651 - val_mae: 2.2818\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5111 - mae: 6.1214\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5111 - mae: 6.1214 - val_loss: 5.4561 - val_mae: 3.1391\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.4608 - mae: 6.1794\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4521 - mae: 6.1721 - val_loss: 4.2031 - val_mae: 1.9534\n",
      "Epoch 5/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.4636 - mae: 6.0329\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4067 - mae: 5.9811 - val_loss: 7.0919 - val_mae: 4.8409\n",
      "Epoch 6/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.3095 - mae: 6.0583\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3230 - mae: 6.0781 - val_loss: 7.3001 - val_mae: 5.2364\n",
      "Epoch 7/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.0600 - mae: 5.8961\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1611 - mae: 5.9823 - val_loss: 5.7257 - val_mae: 3.5126\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.2982 - mae: 5.9995\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2982 - mae: 5.9995 - val_loss: 4.7981 - val_mae: 2.7095\n",
      "Epoch 9/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.2052 - mae: 5.9574\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2826 - mae: 6.0045 - val_loss: 9.2485 - val_mae: 6.8888\n",
      "Epoch 9: early stopping\n",
      "loaded Weights 47\n",
      "Epoch 1/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.2137 - mae: 6.0849\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2665 - mae: 6.1267 - val_loss: 5.0981 - val_mae: 1.9387\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.6543 - mae: 6.1506\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.6898 - mae: 6.1520 - val_loss: 6.7298 - val_mae: 3.0117\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.8604 - mae: 6.1187\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.8604 - mae: 6.1187 - val_loss: 6.2265 - val_mae: 2.5021\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.5435 - mae: 5.9675\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.5175 - mae: 5.9729 - val_loss: 4.7803 - val_mae: 1.6889\n",
      "Epoch 5/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.1547 - mae: 6.0646\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1484 - mae: 6.0711 - val_loss: 4.9777 - val_mae: 2.1068\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.8842 - mae: 5.9434\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9006 - mae: 5.9628 - val_loss: 4.9701 - val_mae: 2.2478\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.6648 - mae: 5.9811\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6925 - mae: 6.0049 - val_loss: 4.7098 - val_mae: 2.0921\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.6088 - mae: 6.0655\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5894 - mae: 6.0463 - val_loss: 4.5029 - val_mae: 2.1903\n",
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.4486 - mae: 6.0365\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4676 - mae: 6.0400 - val_loss: 4.4012 - val_mae: 1.8947\n",
      "Epoch 9: early stopping\n",
      "Random Weights 48\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5851 - mae: 6.0337\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5851 - mae: 6.0337 - val_loss: 4.2452 - val_mae: 1.8650\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.7112 - mae: 6.0733\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7235 - mae: 6.0941 - val_loss: 4.7519 - val_mae: 2.3341\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.5957 - mae: 6.0928\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5943 - mae: 6.0876 - val_loss: 4.2068 - val_mae: 1.8578\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5266 - mae: 5.9992\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5266 - mae: 5.9992 - val_loss: 4.7187 - val_mae: 2.1945\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7665 - mae: 6.1401\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7658 - mae: 6.1325 - val_loss: 4.5073 - val_mae: 1.7687\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.5758 - mae: 5.9097\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6015 - mae: 5.9379 - val_loss: 4.3571 - val_mae: 1.9204\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.2150 - mae: 5.7955\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.2240 - mae: 5.8048 - val_loss: 3.9852 - val_mae: 1.7950\n",
      "Epoch 8/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.5842 - mae: 6.2650\n",
      "Epoch 8: val_mae did not improve from 1.63616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6211 - mae: 6.3095 - val_loss: 4.2464 - val_mae: 2.1172\n",
      "Epoch 9/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.2100 - mae: 6.0339\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1948 - mae: 6.0194 - val_loss: 3.9362 - val_mae: 1.8647\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.1551 - mae: 5.9582\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1441 - mae: 5.9475 - val_loss: 4.0531 - val_mae: 2.0422\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 49\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.2375 - mae: 6.1019\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 9.2328 - mae: 6.0761 - val_loss: 5.8950 - val_mae: 2.3762\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.8787 - mae: 6.1601\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.8258 - mae: 6.1298 - val_loss: 4.9367 - val_mae: 1.7876\n",
      "Epoch 3/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.1819 - mae: 6.1430\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2637 - mae: 6.2486 - val_loss: 4.6865 - val_mae: 1.9615\n",
      "Epoch 4/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.0150 - mae: 6.2612\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0373 - mae: 6.2808 - val_loss: 4.5147 - val_mae: 1.8169\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.6611 - mae: 5.9673\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6611 - mae: 5.9673 - val_loss: 4.5197 - val_mae: 1.9444\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.6667 - mae: 5.9675\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6193 - mae: 5.9213 - val_loss: 4.2101 - val_mae: 1.6567\n",
      "Epoch 7/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.6918 - mae: 6.0452\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7651 - mae: 6.1265 - val_loss: 4.2419 - val_mae: 1.8058\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.8237 - mae: 6.1049\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8424 - mae: 6.1254 - val_loss: 4.4571 - val_mae: 1.9606\n",
      "Epoch 9/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.7558 - mae: 6.1870\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7569 - mae: 6.1879 - val_loss: 4.3045 - val_mae: 1.9703\n",
      "Epoch 10/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.4464 - mae: 6.0931\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4329 - mae: 6.0785 - val_loss: 3.9652 - val_mae: 1.7099\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.3912 - mae: 6.0402\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3726 - mae: 6.0161 - val_loss: 4.0164 - val_mae: 1.7208\n",
      "Epoch 11: early stopping\n",
      "Random Weights 50\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.6728 - mae: 6.1908\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6411 - mae: 6.1686 - val_loss: 4.2366 - val_mae: 1.9395\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.6288 - mae: 6.2233\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6658 - mae: 6.2513 - val_loss: 4.2387 - val_mae: 1.8381\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.5454 - mae: 6.2017\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4831 - mae: 6.1389 - val_loss: 4.0155 - val_mae: 1.7832\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.3496 - mae: 5.9759\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3496 - mae: 5.9759 - val_loss: 4.2456 - val_mae: 1.9200\n",
      "Epoch 5/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.4510 - mae: 6.0629\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4805 - mae: 6.0911 - val_loss: 4.5724 - val_mae: 2.2793\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.3315 - mae: 6.0028\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3424 - mae: 6.0165 - val_loss: 3.9200 - val_mae: 1.7515\n",
      "Epoch 7/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.3679 - mae: 6.0873\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3753 - mae: 6.0873 - val_loss: 3.9490 - val_mae: 1.7971\n",
      "Epoch 8/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.3379 - mae: 6.1230\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3789 - mae: 6.1637 - val_loss: 3.9206 - val_mae: 1.8277\n",
      "Epoch 9/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.3654 - mae: 6.1695\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2998 - mae: 6.0958 - val_loss: 4.0910 - val_mae: 1.9517\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.1470 - mae: 5.9115\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1418 - mae: 5.9046 - val_loss: 3.9912 - val_mae: 1.8895\n",
      "Epoch 11/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.5173 - mae: 6.3171\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4584 - mae: 6.2619 - val_loss: 3.8933 - val_mae: 1.8194\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 51\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.5704 - mae: 6.1700\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.5886 - mae: 6.1710 - val_loss: 5.2222 - val_mae: 1.8108\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.1982 - mae: 5.9360\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2094 - mae: 5.9418 - val_loss: 5.7039 - val_mae: 2.5796\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.3110 - mae: 5.9624\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4529 - mae: 6.0391 - val_loss: 5.7926 - val_mae: 1.9488\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.9600 - mae: 5.9174 \n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.9695 - mae: 5.9244 - val_loss: 5.8974 - val_mae: 2.0716\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 10.1372 - mae: 6.1688\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 10.1372 - mae: 6.1688 - val_loss: 6.7970 - val_mae: 3.4493\n",
      "Epoch 6/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.3859 - mae: 6.1533\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3587 - mae: 6.1406 - val_loss: 4.7709 - val_mae: 1.9277\n",
      "Epoch 6: early stopping\n",
      "Random Weights 52\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9466 - mae: 6.1250\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9374 - mae: 6.1103 - val_loss: 8.0361 - val_mae: 5.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.0152 - mae: 6.0268\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0045 - mae: 6.0075 - val_loss: 5.0482 - val_mae: 2.0852\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.2104 - mae: 6.1837\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2104 - mae: 6.1837 - val_loss: 5.0403 - val_mae: 2.3396\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.8523 - mae: 6.2120\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7952 - mae: 6.1668 - val_loss: 6.2424 - val_mae: 3.8622\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.5472 - mae: 6.0693\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5806 - mae: 6.0980 - val_loss: 6.1858 - val_mae: 3.7537\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7716 - mae: 6.0720\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8100 - mae: 6.1046 - val_loss: 4.2130 - val_mae: 1.6519\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.5324 - mae: 6.0496\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5061 - mae: 6.0263 - val_loss: 4.5520 - val_mae: 2.2877\n",
      "Epoch 8/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.4322 - mae: 6.1645\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3679 - mae: 6.0982 - val_loss: 5.1929 - val_mae: 3.1052\n",
      "Epoch 9/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.1527 - mae: 5.8870\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1033 - mae: 5.8438 - val_loss: 3.8112 - val_mae: 1.7750\n",
      "Epoch 10/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 7.8263 - mae: 5.7766\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 7.8100 - mae: 5.7592 - val_loss: 4.6281 - val_mae: 2.7410\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.1105 - mae: 6.0614\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1038 - mae: 6.0526 - val_loss: 3.8718 - val_mae: 1.9583\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 53\n",
      "Epoch 1/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.1112 - mae: 5.9819\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.1602 - mae: 5.9976 - val_loss: 5.5344 - val_mae: 2.0344\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.7178 - mae: 6.0392\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7979 - mae: 6.1141 - val_loss: 5.9654 - val_mae: 2.3929\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.2500 - mae: 5.8659\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2844 - mae: 5.9076 - val_loss: 5.1795 - val_mae: 2.0019\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.3938 - mae: 5.9622\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4083 - mae: 5.9707 - val_loss: 5.6796 - val_mae: 2.3040\n",
      "Epoch 5/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.6174 - mae: 5.9889\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6084 - mae: 5.9770 - val_loss: 6.1981 - val_mae: 2.6330\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.4284 - mae: 6.0260\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.4538 - mae: 6.0733 - val_loss: 4.6779 - val_mae: 1.6703\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.9769 - mae: 5.9089\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9903 - mae: 5.9147 - val_loss: 4.8277 - val_mae: 1.8364\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.9486 - mae: 5.8929\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9745 - mae: 5.9115 - val_loss: 4.6893 - val_mae: 1.6776\n",
      "Epoch 9/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.9612 - mae: 5.9855\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9948 - mae: 6.0387 - val_loss: 4.2982 - val_mae: 1.6632\n",
      "Epoch 10/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.8657 - mae: 6.2035\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8556 - mae: 6.1834 - val_loss: 4.8781 - val_mae: 2.2231\n",
      "Epoch 11/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9167 - mae: 6.0075\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8923 - mae: 5.9807 - val_loss: 4.6127 - val_mae: 1.7782\n",
      "Epoch 12/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.0179 - mae: 6.2123\n",
      "Epoch 12: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9609 - mae: 6.1746 - val_loss: 4.3902 - val_mae: 1.8557\n",
      "Epoch 13/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.8300 - mae: 6.1178\n",
      "Epoch 13: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8300 - mae: 6.1178 - val_loss: 4.5694 - val_mae: 1.9723\n",
      "Epoch 14/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.7387 - mae: 6.0746\n",
      "Epoch 14: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6767 - mae: 6.0152 - val_loss: 4.3833 - val_mae: 1.8846\n",
      "Epoch 14: early stopping\n",
      "Random Weights 54\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.3013 - mae: 5.7701\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3903 - mae: 5.8545 - val_loss: 4.1791 - val_mae: 1.7327\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.6499 - mae: 6.1622\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6352 - mae: 6.1577 - val_loss: 4.1225 - val_mae: 1.8908\n",
      "Epoch 3/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.1810 - mae: 5.9068\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2330 - mae: 5.9589 - val_loss: 3.9595 - val_mae: 1.8224\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.2835 - mae: 6.0710\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3288 - mae: 6.1114 - val_loss: 4.1564 - val_mae: 2.0141\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.4355 - mae: 6.1985\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4355 - mae: 6.1985 - val_loss: 4.1958 - val_mae: 2.0595\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.2183 - mae: 5.9698\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2183 - mae: 5.9698 - val_loss: 3.8145 - val_mae: 1.7513\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 55\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.1699 - mae: 5.9612\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2013 - mae: 5.9336 - val_loss: 6.1907 - val_mae: 2.4500\n",
      "Epoch 2/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 10.8028 - mae: 6.0947\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 10.8028 - mae: 6.0947 - val_loss: 7.2546 - val_mae: 1.9536\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 10.7503 - mae: 6.2268\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 10.5955 - mae: 6.1604 - val_loss: 5.2972 - val_mae: 1.6629\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.5676 - mae: 5.8279\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.6019 - mae: 5.8756 - val_loss: 5.2799 - val_mae: 1.8321\n",
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.5044 - mae: 6.0658\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4774 - mae: 6.0569 - val_loss: 6.0108 - val_mae: 2.8417\n",
      "Epoch 6/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.3730 - mae: 6.1861\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4051 - mae: 6.2197 - val_loss: 5.2827 - val_mae: 2.4313\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.8813 - mae: 5.9429\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8659 - mae: 5.9252 - val_loss: 6.8185 - val_mae: 3.9433\n",
      "Epoch 8/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.0001 - mae: 6.0663\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0582 - mae: 6.1246 - val_loss: 8.8044 - val_mae: 6.0080\n",
      "Epoch 8: early stopping\n",
      "Random Weights 56\n",
      "Epoch 1/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.0858 - mae: 6.0182\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0767 - mae: 6.0089 - val_loss: 6.3681 - val_mae: 3.5383\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.7490 - mae: 5.9851\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7411 - mae: 5.9811 - val_loss: 4.1692 - val_mae: 1.6840\n",
      "Epoch 3/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.4015 - mae: 5.9304\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3838 - mae: 5.9234 - val_loss: 7.4497 - val_mae: 5.2071\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.4761 - mae: 6.1129\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5318 - mae: 6.1598 - val_loss: 4.8130 - val_mae: 2.5222\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.4086 - mae: 6.0687\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4018 - mae: 6.0615 - val_loss: 11.3792 - val_mae: 9.2290\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.3018 - mae: 5.9944\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3145 - mae: 6.0014 - val_loss: 4.9382 - val_mae: 2.7462\n",
      "Epoch 7/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.0596 - mae: 5.7813\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.0596 - mae: 5.7813 - val_loss: 7.7093 - val_mae: 5.4265\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 57\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.5194 - mae: 6.2141\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.5010 - mae: 6.1379 - val_loss: 6.1444 - val_mae: 2.3421\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.9340 - mae: 6.0731 \n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.9626 - mae: 6.0912 - val_loss: 5.7350 - val_mae: 1.8765\n",
      "Epoch 3/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.8719 - mae: 6.1413\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.8719 - mae: 6.1413 - val_loss: 5.0327 - val_mae: 1.7191\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.5321 - mae: 6.0404\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.5321 - mae: 6.0404 - val_loss: 7.2654 - val_mae: 3.7270\n",
      "Epoch 5/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.7299 - mae: 6.0711\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.7590 - mae: 6.1015 - val_loss: 9.6577 - val_mae: 6.1695\n",
      "Epoch 6/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.6977 - mae: 6.0868\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.6808 - mae: 6.0602 - val_loss: 7.4416 - val_mae: 3.9131\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.3654 - mae: 6.1068\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.3156 - mae: 6.0667 - val_loss: 5.8022 - val_mae: 2.8702\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.0426 - mae: 6.1618\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0426 - mae: 6.1618 - val_loss: 4.6856 - val_mae: 1.9973\n",
      "Epoch 8: early stopping\n",
      "Random Weights 58\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.9482 - mae: 6.1466\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9482 - mae: 6.1466 - val_loss: 4.3422 - val_mae: 1.7294\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9253 - mae: 6.0909\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9303 - mae: 6.0938 - val_loss: 4.9550 - val_mae: 2.2703\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8393 - mae: 5.9906\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8384 - mae: 5.9843 - val_loss: 4.4450 - val_mae: 1.6780\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.6548 - mae: 5.9150\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6656 - mae: 5.9302 - val_loss: 4.0494 - val_mae: 1.6638\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5488 - mae: 5.9820\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5488 - mae: 5.9820 - val_loss: 5.1696 - val_mae: 2.5560\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.6924 - mae: 6.0363\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6924 - mae: 6.0363 - val_loss: 4.0036 - val_mae: 1.7036\n",
      "Epoch 7/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.2959 - mae: 5.9037\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.2777 - mae: 5.8810 - val_loss: 3.9222 - val_mae: 1.6475\n",
      "Epoch 8/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.5558 - mae: 6.1927\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5060 - mae: 6.1408 - val_loss: 4.0427 - val_mae: 1.7656\n",
      "Epoch 9/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.2474 - mae: 5.8700\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2359 - mae: 5.8705 - val_loss: 4.2139 - val_mae: 2.0618\n",
      "Epoch 10/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.3764 - mae: 6.1373\n",
      "Epoch 10: val_mae did not improve from 1.63616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3512 - mae: 6.1069 - val_loss: 3.7621 - val_mae: 1.6656\n",
      "Epoch 11/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.3261 - mae: 6.1440\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3240 - mae: 6.1333 - val_loss: 4.0045 - val_mae: 1.7672\n",
      "Epoch 12/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.3386 - mae: 5.9829\n",
      "Epoch 12: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3758 - mae: 6.0152 - val_loss: 3.9779 - val_mae: 1.7285\n",
      "Epoch 12: early stopping\n",
      "loaded Weights 59\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.6287 - mae: 6.3184\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6539 - mae: 6.3357 - val_loss: 7.7735 - val_mae: 4.2607\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.8445 - mae: 6.1365\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.8524 - mae: 6.1393 - val_loss: 5.5301 - val_mae: 1.7857\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.5571 - mae: 5.9192\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.5516 - mae: 5.9215 - val_loss: 4.8663 - val_mae: 1.6824\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.1851 - mae: 5.9282\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1551 - mae: 5.8984 - val_loss: 5.4209 - val_mae: 2.4201\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.1219 - mae: 6.0805\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1295 - mae: 6.0874 - val_loss: 5.8259 - val_mae: 2.9548\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.4398 - mae: 6.3279\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4302 - mae: 6.3104 - val_loss: 5.4836 - val_mae: 2.4505\n",
      "Epoch 6: early stopping\n",
      "Random Weights 60\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2572 - mae: 6.1459\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2236 - mae: 6.1134 - val_loss: 6.7236 - val_mae: 3.8685\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7734 - mae: 5.9613\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7830 - mae: 5.9697 - val_loss: 5.5080 - val_mae: 2.8822\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.5506 - mae: 5.7330\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5609 - mae: 5.7398 - val_loss: 9.2668 - val_mae: 6.4977\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9209 - mae: 6.1484\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9159 - mae: 6.1394 - val_loss: 7.2668 - val_mae: 4.6650\n",
      "Epoch 5/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.5705 - mae: 6.0044\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6022 - mae: 6.0349 - val_loss: 4.9237 - val_mae: 2.5378\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.5385 - mae: 6.0865\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5637 - mae: 6.1040 - val_loss: 6.3319 - val_mae: 3.9184\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.6359 - mae: 6.0681\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6501 - mae: 6.0728 - val_loss: 5.4058 - val_mae: 2.8084\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.8342 - mae: 6.1018\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8474 - mae: 6.1140 - val_loss: 4.6054 - val_mae: 2.0505\n",
      "Epoch 9/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.7786 - mae: 6.0908\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8111 - mae: 6.1306 - val_loss: 12.1220 - val_mae: 9.6751\n",
      "Epoch 10/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.7689 - mae: 6.2452\n",
      "Epoch 10: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7809 - mae: 6.2515 - val_loss: 12.8774 - val_mae: 10.4402\n",
      "Epoch 11/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.5923 - mae: 5.8809\n",
      "Epoch 11: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6003 - mae: 5.8730 - val_loss: 14.1323 - val_mae: 11.4265\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 61\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.3516 - mae: 6.1785\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3685 - mae: 6.1395 - val_loss: 5.0619 - val_mae: 1.6525\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.8109 - mae: 6.2070\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.7913 - mae: 6.1774 - val_loss: 6.3387 - val_mae: 2.6914\n",
      "Epoch 3/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.7998 - mae: 6.0384\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.8069 - mae: 6.0582 - val_loss: 5.5114 - val_mae: 2.1012\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.4827 - mae: 6.1189\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.4118 - mae: 6.0706 - val_loss: 6.2146 - val_mae: 3.2137\n",
      "Epoch 4: early stopping\n",
      "Random Weights 62\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.2898 - mae: 6.0343\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3346 - mae: 6.0681 - val_loss: 5.3429 - val_mae: 2.1901\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.1134 - mae: 5.9876\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1438 - mae: 6.0262 - val_loss: 4.7159 - val_mae: 1.9708\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.6294 - mae: 5.9529\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6514 - mae: 5.9732 - val_loss: 4.2089 - val_mae: 1.7109\n",
      "Epoch 4/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.6093 - mae: 6.0665\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5756 - mae: 6.0397 - val_loss: 4.4670 - val_mae: 2.1390\n",
      "Epoch 5/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.3512 - mae: 5.8777\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.3732 - mae: 5.8816 - val_loss: 4.6594 - val_mae: 2.1075\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.6902 - mae: 6.0412\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6493 - mae: 6.0129 - val_loss: 4.0277 - val_mae: 1.6700\n",
      "Epoch 7/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.4945 - mae: 6.0525\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4576 - mae: 6.0174 - val_loss: 5.3303 - val_mae: 3.1059\n",
      "Epoch 8/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.5787 - mae: 6.2151\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6384 - mae: 6.2620 - val_loss: 7.2707 - val_mae: 4.8575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.6955 - mae: 6.1381\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6926 - mae: 6.1377 - val_loss: 13.6402 - val_mae: 11.3194\n",
      "Epoch 9: early stopping\n",
      "loaded Weights 63\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.1006 - mae: 5.9385\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0660 - mae: 5.8981 - val_loss: 5.8669 - val_mae: 2.7547\n",
      "Epoch 2/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.3425 - mae: 5.9490\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.4000 - mae: 5.9813 - val_loss: 5.4262 - val_mae: 2.0411\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.4646 - mae: 6.2057\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4843 - mae: 6.2282 - val_loss: 5.0229 - val_mae: 2.1433\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0412 - mae: 6.1071\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0586 - mae: 6.1196 - val_loss: 5.9906 - val_mae: 3.0117\n",
      "Epoch 5/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.0805 - mae: 6.1052\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0298 - mae: 6.0613 - val_loss: 4.6195 - val_mae: 1.9838\n",
      "Epoch 6/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.5970 - mae: 5.9399\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6219 - mae: 5.9664 - val_loss: 4.2019 - val_mae: 1.7222\n",
      "Epoch 7/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.1361 - mae: 6.2298\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.1122 - mae: 6.1947 - val_loss: 6.7955 - val_mae: 3.8260\n",
      "Epoch 8/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9147 - mae: 5.9440\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9252 - mae: 5.9554 - val_loss: 5.4049 - val_mae: 2.7292\n",
      "Epoch 9/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8101 - mae: 6.0868\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8199 - mae: 6.0967 - val_loss: 4.5653 - val_mae: 2.1124\n",
      "Epoch 9: early stopping\n",
      "Random Weights 64\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.5048 - mae: 5.9583\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4981 - mae: 5.9412 - val_loss: 6.0339 - val_mae: 3.5659\n",
      "Epoch 2/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.6545 - mae: 6.0103\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6760 - mae: 6.0156 - val_loss: 6.5266 - val_mae: 3.6877\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.1840 - mae: 6.2256\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1916 - mae: 6.2375 - val_loss: 4.2320 - val_mae: 1.6408\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.6311 - mae: 6.0980\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6311 - mae: 6.0980 - val_loss: 3.9049 - val_mae: 1.6532\n",
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.3760 - mae: 6.0022\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4211 - mae: 6.0502 - val_loss: 5.8201 - val_mae: 3.6377\n",
      "Epoch 6/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.2010 - mae: 5.9601\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.1969 - mae: 5.9517 - val_loss: 8.5435 - val_mae: 6.4422\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 65\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8862 - mae: 5.8620\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 8.9094 - mae: 5.8688 - val_loss: 5.0070 - val_mae: 1.7437\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.3404 - mae: 6.0579\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3405 - mae: 6.0664 - val_loss: 5.2180 - val_mae: 2.1663\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.3731 - mae: 5.8931\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.4189 - mae: 5.9298 - val_loss: 5.1421 - val_mae: 1.7348\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.5975 - mae: 6.1197\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.5975 - mae: 6.1197 - val_loss: 5.1812 - val_mae: 1.8079\n",
      "Epoch 5/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.4095 - mae: 6.0268\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3918 - mae: 6.0170 - val_loss: 5.6206 - val_mae: 2.4790\n",
      "Epoch 6/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.2793 - mae: 6.0527\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3088 - mae: 6.0709 - val_loss: 4.8077 - val_mae: 1.6487\n",
      "Epoch 7/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2730 - mae: 5.9951\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2853 - mae: 6.0027 - val_loss: 6.8459 - val_mae: 3.5129\n",
      "Epoch 8/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.6811 - mae: 5.9374\n",
      "Epoch 8: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6954 - mae: 5.9499 - val_loss: 5.3765 - val_mae: 1.8830\n",
      "Epoch 9/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.3148 - mae: 5.9671\n",
      "Epoch 9: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.3378 - mae: 5.9887 - val_loss: 4.9649 - val_mae: 1.8051\n",
      "Epoch 9: early stopping\n",
      "Random Weights 66\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.1440 - mae: 5.9515\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2141 - mae: 6.0192 - val_loss: 5.4777 - val_mae: 2.4280\n",
      "Epoch 2/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.3863 - mae: 6.2638\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.3863 - mae: 6.2638 - val_loss: 4.5424 - val_mae: 1.6462\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.7281 - mae: 5.7787\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7331 - mae: 5.7852 - val_loss: 4.7437 - val_mae: 2.0765\n",
      "Epoch 4/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.7559 - mae: 5.8914\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7559 - mae: 5.8914 - val_loss: 5.0353 - val_mae: 2.3639\n",
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.7714 - mae: 6.1138\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7689 - mae: 6.1113 - val_loss: 4.6585 - val_mae: 2.1456\n",
      "Epoch 5: early stopping\n",
      "loaded Weights 67\n",
      "Epoch 1/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.3900 - mae: 6.1470\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.4356 - mae: 6.1807 - val_loss: 4.9564 - val_mae: 1.6628\n",
      "Epoch 2/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50 [===========================>..] - ETA: 0s - loss: 9.5822 - mae: 6.2774\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.5679 - mae: 6.2495 - val_loss: 5.7788 - val_mae: 2.3378\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.6687 - mae: 6.0052\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.6667 - mae: 6.0016 - val_loss: 5.1613 - val_mae: 1.6737\n",
      "Epoch 4/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2371 - mae: 5.9376\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2546 - mae: 5.9572 - val_loss: 4.6854 - val_mae: 1.7813\n",
      "Epoch 4: early stopping\n",
      "Random Weights 68\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.0604 - mae: 6.1660\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0276 - mae: 6.1262 - val_loss: 4.7118 - val_mae: 1.7945\n",
      "Epoch 2/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 8.9677 - mae: 5.9311\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9335 - mae: 5.8966 - val_loss: 4.7435 - val_mae: 1.9562\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8995 - mae: 6.0066\n",
      "Epoch 3: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9062 - mae: 6.0180 - val_loss: 4.3879 - val_mae: 1.8304\n",
      "Epoch 4/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.8228 - mae: 6.1590\n",
      "Epoch 4: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8845 - mae: 6.2079 - val_loss: 4.3002 - val_mae: 1.6930\n",
      "Epoch 5/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.6503 - mae: 6.0487\n",
      "Epoch 5: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6344 - mae: 6.0342 - val_loss: 4.1977 - val_mae: 1.7503\n",
      "Epoch 6/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.4851 - mae: 6.0478\n",
      "Epoch 6: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4925 - mae: 6.0692 - val_loss: 3.9886 - val_mae: 1.8784\n",
      "Epoch 7/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.3088 - mae: 6.0212\n",
      "Epoch 7: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.3038 - mae: 6.0020 - val_loss: 4.3141 - val_mae: 2.0033\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 69\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.2273 - mae: 6.1125\n",
      "Epoch 1: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.2191 - mae: 6.0529 - val_loss: 5.1164 - val_mae: 1.7217\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.5370 - mae: 5.7211\n",
      "Epoch 2: val_mae did not improve from 1.63616\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.5085 - mae: 5.7070 - val_loss: 5.2079 - val_mae: 1.7189\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 9.5972 - mae: 6.2549\n",
      "Epoch 3: val_mae improved from 1.63616 to 1.62800, saving model to best_weights.h5\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.5952 - mae: 6.2500 - val_loss: 4.8151 - val_mae: 1.6280\n",
      "Epoch 4/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.5671 - mae: 6.2219\n",
      "Epoch 4: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.5900 - mae: 6.2340 - val_loss: 6.0286 - val_mae: 2.7233\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.0762 - mae: 5.8031\n",
      "Epoch 5: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0762 - mae: 5.8031 - val_loss: 7.1030 - val_mae: 4.0019\n",
      "Epoch 6/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.1935 - mae: 5.9296\n",
      "Epoch 6: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2857 - mae: 6.0242 - val_loss: 9.1204 - val_mae: 6.0918\n",
      "Epoch 6: early stopping\n",
      "Random Weights 70\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.0967 - mae: 6.1583\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.0967 - mae: 6.1583 - val_loss: 5.6449 - val_mae: 2.9007\n",
      "Epoch 2/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.5287 - mae: 5.8033\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5505 - mae: 5.8407 - val_loss: 4.6361 - val_mae: 2.1775\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.5769 - mae: 6.0745\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5514 - mae: 6.0578 - val_loss: 4.3334 - val_mae: 2.0790\n",
      "Epoch 4/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.3451 - mae: 5.9795\n",
      "Epoch 4: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.4144 - mae: 6.0406 - val_loss: 4.3867 - val_mae: 2.0674\n",
      "Epoch 5/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5412 - mae: 6.0921\n",
      "Epoch 5: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5412 - mae: 6.0921 - val_loss: 6.6315 - val_mae: 4.3008\n",
      "Epoch 6/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.8151 - mae: 6.1884\n",
      "Epoch 6: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8151 - mae: 6.1884 - val_loss: 6.3798 - val_mae: 3.8931\n",
      "Epoch 7/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.4291 - mae: 5.9599\n",
      "Epoch 7: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.4291 - mae: 5.9599 - val_loss: 4.0079 - val_mae: 1.7565\n",
      "Epoch 8/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.6618 - mae: 6.3513\n",
      "Epoch 8: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.6618 - mae: 6.3513 - val_loss: 5.7931 - val_mae: 3.6172\n",
      "Epoch 9/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 8.4999 - mae: 6.1858\n",
      "Epoch 9: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5538 - mae: 6.2286 - val_loss: 6.8757 - val_mae: 4.6288\n",
      "Epoch 10/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.2548 - mae: 5.9321\n",
      "Epoch 10: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.2920 - mae: 5.9637 - val_loss: 6.2686 - val_mae: 4.0884\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 71\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.6751 - mae: 6.2050\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.6888 - mae: 6.2009 - val_loss: 5.5747 - val_mae: 2.1442\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 9.2973 - mae: 6.0564\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.3199 - mae: 6.0877 - val_loss: 6.2362 - val_mae: 3.3860\n",
      "Epoch 2: early stopping\n",
      "Random Weights 72\n",
      "Epoch 1/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.0144 - mae: 6.0453\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9843 - mae: 6.0213 - val_loss: 6.0556 - val_mae: 3.3314\n",
      "Epoch 2/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.9909 - mae: 6.2838\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9909 - mae: 6.2838 - val_loss: 5.1114 - val_mae: 2.7219\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.4561 - mae: 6.0124\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.5176 - mae: 6.0813 - val_loss: 5.5743 - val_mae: 3.3139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: early stopping\n",
      "loaded Weights 73\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.5711 - mae: 6.1245\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.5563 - mae: 6.1078 - val_loss: 5.2558 - val_mae: 1.9633\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 9.1278 - mae: 5.9997\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.1097 - mae: 5.9725 - val_loss: 4.8872 - val_mae: 1.7675\n",
      "Epoch 3/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.0745 - mae: 6.0311\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0894 - mae: 6.0477 - val_loss: 4.3790 - val_mae: 1.6654\n",
      "Epoch 4/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.9177 - mae: 6.0041\n",
      "Epoch 4: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9385 - mae: 6.0227 - val_loss: 7.4253 - val_mae: 4.6532\n",
      "Epoch 4: early stopping\n",
      "Random Weights 74\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.6290 - mae: 5.8710\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7636 - mae: 6.0074 - val_loss: 11.0333 - val_mae: 8.4385\n",
      "Epoch 2/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.9734 - mae: 6.1797\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9796 - mae: 6.1783 - val_loss: 6.7662 - val_mae: 4.0212\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.8649 - mae: 5.9086\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9684 - mae: 6.0183 - val_loss: 8.2319 - val_mae: 5.5593\n",
      "Epoch 3: early stopping\n",
      "loaded Weights 75\n",
      "Epoch 1/10000\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.2271 - mae: 6.1278\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.2031 - mae: 6.1071 - val_loss: 4.7601 - val_mae: 2.0198\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.9698 - mae: 5.9257\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0114 - mae: 5.9550 - val_loss: 4.8913 - val_mae: 1.9001\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.9431 - mae: 5.8498\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.8797 - mae: 5.7895 - val_loss: 4.8548 - val_mae: 2.0133\n",
      "Epoch 3: early stopping\n",
      "Random Weights 76\n",
      "Epoch 1/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.9673 - mae: 6.1428\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.9284 - mae: 6.0948 - val_loss: 4.7176 - val_mae: 1.9245\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 8.8179 - mae: 6.0319\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7500 - mae: 5.9604 - val_loss: 4.5190 - val_mae: 1.8099\n",
      "Epoch 3/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.9271 - mae: 6.0524\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.9087 - mae: 6.0314 - val_loss: 4.8278 - val_mae: 2.1873\n",
      "Epoch 3: early stopping\n",
      "loaded Weights 77\n",
      "Epoch 1/10000\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 9.2527 - mae: 6.1258\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.1902 - mae: 6.0663 - val_loss: 4.6665 - val_mae: 1.7155\n",
      "Epoch 2/10000\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 9.0391 - mae: 6.0831\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 9.0503 - mae: 6.0997 - val_loss: 4.4845 - val_mae: 1.8015\n",
      "Epoch 2: early stopping\n",
      "Random Weights 78\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.1406 - mae: 6.1370\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.1406 - mae: 6.1370 - val_loss: 4.8802 - val_mae: 1.7861\n",
      "Epoch 2/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 9.1723 - mae: 6.0584\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 9.1406 - mae: 6.0479 - val_loss: 4.4725 - val_mae: 1.7274\n",
      "Epoch 3/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.7552 - mae: 6.0772\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.7457 - mae: 6.0640 - val_loss: 4.2670 - val_mae: 1.6559\n",
      "Epoch 4/10000\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 8.8789 - mae: 6.1603\n",
      "Epoch 4: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8442 - mae: 6.1211 - val_loss: 4.3179 - val_mae: 1.8093\n",
      "Epoch 4: early stopping\n",
      "loaded Weights 79\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.3106 - mae: 6.1766\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 9.3106 - mae: 6.1766 - val_loss: 4.7938 - val_mae: 1.9898\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.8394 - mae: 6.0270\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 8.7960 - mae: 5.9828 - val_loss: 4.2104 - val_mae: 1.6571\n",
      "Epoch 3/10000\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 8.8173 - mae: 6.1524\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.7802 - mae: 6.1307 - val_loss: 4.3574 - val_mae: 2.0408\n",
      "Epoch 3: early stopping\n",
      "Random Weights 80\n",
      "Epoch 1/10000\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5948 - mae: 5.9983\n",
      "Epoch 1: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 8.5948 - mae: 5.9983 - val_loss: 4.2916 - val_mae: 1.8033\n",
      "Epoch 2/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.6482 - mae: 6.0602\n",
      "Epoch 2: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.6529 - mae: 6.0613 - val_loss: 4.1798 - val_mae: 1.7833\n",
      "Epoch 3/10000\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 8.5506 - mae: 6.0634\n",
      "Epoch 3: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.5912 - mae: 6.1009 - val_loss: 3.9482 - val_mae: 1.6587\n",
      "Epoch 4/10000\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 8.2286 - mae: 5.8212\n",
      "Epoch 4: val_mae did not improve from 1.62800\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 8.2659 - mae: 5.8592 - val_loss: 4.2014 - val_mae: 1.9204\n",
      "Epoch 4: early stopping\n",
      "loaded Weights 81\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(1,82):\n",
    "    if i >= 60 and i < 72:\n",
    "        early_stop = EarlyStopping(monitor='val_mae',patience = 3, verbose = 1)\n",
    "    elif i >= 72:\n",
    "        early_stop = EarlyStopping(monitor='val_mae',patience = 1, verbose = 1)\n",
    "    nn.fit(X_train_scaled,y_train,epochs=10000,validation_data=(X_test,y_test),callbacks=[checkpoint,early_stop])\n",
    "    if i % 2 != 0:\n",
    "        print(f\"loaded Weights {i}\")\n",
    "        nn.load_weights('best_weights.h5')\n",
    "    else:\n",
    "        print(f\"Random Weights {i}\")\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa80480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8151 - mae: 1.6280\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = nn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f8643a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307.1233699321747 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = end_time - start_time\n",
    "\n",
    "print(f'{total_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08595cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    number_input_features = len(X_train_scaled[0])\n",
    "    hidden_layers_1 = 750\n",
    "    hidden_layers_list = [250]\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=hidden_layers_1, input_dim=number_input_features, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    for i in hidden_layers_list:\n",
    "        model.add(tf.keras.layers.Dense(units=i, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='relu'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "497661f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8af1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.load_weights('best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1cb4212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.compile(loss = 'mae',optimizer ='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81d93f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8151 - mae: 1.6280\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model_best.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "905935da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ea4a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Predicted':y_pred.ravel(),\n",
    "       'Actual':y_test.ravel()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d9f1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a55fa819",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Predicted'] = result['Predicted'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a30f9a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>90.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>89.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>90.0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  Actual\n",
       "0         91.0      90\n",
       "1         89.0      89\n",
       "2         89.0      92\n",
       "3         90.0      86\n",
       "4         90.0      90\n",
       "..         ...     ...\n",
       "395       90.0      92\n",
       "396       90.0      90\n",
       "397       89.0      90\n",
       "398       90.0      91\n",
       "399       90.0      90\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "607b4c51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(len(result)):\n",
    "    if result['Predicted'].iloc[i] == result['Actual'].iloc[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe793057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 91.  89.  90.  92.  94. 101.]\n"
     ]
    }
   ],
   "source": [
    "unique_val = result['Predicted'].unique()\n",
    "print(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b591f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
